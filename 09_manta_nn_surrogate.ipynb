{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:04:11.457718Z",
     "start_time": "2020-10-27T21:04:09.617771Z"
    }
   },
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "# --- Must haves ---\n",
    "import os, sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from surrogates4sims.mantaflowDatasets import MantaFlowDataset, getSingleSim, createMantaFlowTrainTest\n",
    "\n",
    "from surrogates4sims.utils import create_opt, create_one_cycle, find_lr, printNumModelParams, \\\n",
    "                                    rmse, writeMessage, plotSampleWprediction, plotSampleWpredictionByChannel, \\\n",
    "                                    plotSample, curl, jacobian, stream2uv, create_movie, convertSimToImage\n",
    "\n",
    "from surrogates4sims.models import Generator, Encoder, AE_no_P, AE_xhat_z, AE_xhat_zV2\n",
    "\n",
    "from surrogates4sims.train import trainEpoch, validEpoch\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:04:11.474387Z",
     "start_time": "2020-10-27T21:04:11.461189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'end_to_end_plateau_train_GPUs23_latentDim16_filters128_bz40_numConv4_streamFalse_jacobianFalse_epochs1000_stackTrue'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data \n",
    "eval_only=False\n",
    "DEBUG = False\n",
    "# model name, for tensorboard recording and checkpointing purposes.\n",
    "versionName = \"end_to_end_plateau_train\"\n",
    "\n",
    "# GPU Numbers to use. Comma seprate them for multi-GPUs.\n",
    "gpu_ids = \"2,3\"\n",
    "versionName = versionName + '_GPUs{}'.format(gpu_ids.replace(',',''))\n",
    "# path to load model weights.\n",
    "pretrained_path = None\n",
    "\n",
    "# rate at which to record metrics. (number of batches to average over when recording metrics, e.g. \"every 5 batches\")\n",
    "tensorboard_rate = 5\n",
    "\n",
    "# number of epochs to train. This is defined here so we can use the OneCycle LR Scheduler.\n",
    "epochs = 1000\n",
    "\n",
    "# Data Directory\n",
    "dataDirec = '/data/mantaFlowSim/data/smoke_pos21_size5_f200/v'\n",
    "reverseXY = False \n",
    "\n",
    "# checkpoint directory\n",
    "cps = 'cps'\n",
    "tensorboard_direc = \"tb\"\n",
    "\n",
    "findLRs = False  \n",
    "\n",
    "# hyper-params\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "testSplit = .1\n",
    "bz = 40\n",
    "numSamplesToKeep = np.infty #if not debugging\n",
    "latentDim = 16\n",
    "window_size = 5\n",
    "filters = 128\n",
    "num_conv = 4 # breaks when less than 2\n",
    "simLen = 200\n",
    "stack = True\n",
    "simVizIndex = 0 # sim in the test set to visualize\n",
    "createStreamFcn = False\n",
    "doJacobian = False\n",
    "repeat = 0\n",
    "skip_connection = False\n",
    "patience = 2\n",
    "if DEBUG:\n",
    "    epochs = 10000\n",
    "    numSamplesToKeep = bz\n",
    "    \n",
    "versionName = versionName + '_latentDim{}_filters{}_bz{}_numConv{}_stream{}_jacobian{}_epochs{}_stack{}'.format(latentDim,filters,bz,num_conv,createStreamFcn,doJacobian,epochs,stack)\n",
    "versionName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:04:11.708269Z",
     "start_time": "2020-10-27T21:04:11.477653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "(19000, 2000)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "trainData, testData = createMantaFlowTrainTest(dataDirec,simLen,testSplit,seed)\n",
    "print((len(trainData),len(testData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:04:11.727660Z",
     "start_time": "2020-10-27T21:04:11.710275Z"
    }
   },
   "outputs": [],
   "source": [
    "class MantaFlowDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 dataDirec='/data/mantaFlowSim/data/smoke_pos21_size5_f200/v',\n",
    "                 numToKeep=np.infty,transform=None, reverseXY=False, preprocess=True, AE=False,\n",
    "                 w = 1, simLen = 200): \n",
    "        if type(dataDirec) == list:\n",
    "            self.files = dataDirec\n",
    "        else:\n",
    "            self.files = glob(os.path.join(dataDirec,'*.npz'))\n",
    "        self.dataDirec = dataDirec\n",
    "        self.numToKeep = numToKeep\n",
    "        self.transform = transform\n",
    "        self.reverseXY = reverseXY\n",
    "        self.AE = AE\n",
    "        self.w = w\n",
    "        self.simLen = simLen\n",
    "        self.data = []\n",
    " \n",
    "        if numToKeep < len(self.files):\n",
    "            self.files = self.files[:numToKeep]\n",
    "        for f in tqdm(self.files):\n",
    "            X,y = self.loadfile(f)\n",
    "            \n",
    "            if preprocess:\n",
    "                X,y = self.preprocessFcn(X,y)\n",
    "                \n",
    "            if reverseXY:\n",
    "                self.data.append((y,X))\n",
    "            else:\n",
    "                self.data.append((X,y))\n",
    "\n",
    "    def loadfile(self,fn):\n",
    "        A = np.load(fn)\n",
    "        X = A['x'].astype('float32')\n",
    "        X = np.rollaxis(X,-1)\n",
    "        y = A['y'].astype('float32')\n",
    "        return X,y\n",
    "\n",
    "    def preprocessFcn(self,X,y):\n",
    "        x_range = 11.953\n",
    "        X /= x_range\n",
    "        y_range = [[0.2, 0.8], [0.04, 0.12], [0.0, 199.0]]\n",
    "        for i, ri in enumerate(y_range):\n",
    "            y[i] = (y[i]-ri[0]) / (ri[1]-ri[0]) * 2 - 1\n",
    "        return X,y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def plot(self,idx,savefig=False):\n",
    "        X, label  = self.data[idx]\n",
    "        if self.reverseXY:\n",
    "            X = label\n",
    "            \n",
    "        plt.figure(figsize=(20,10))\n",
    "        \n",
    "        plt.subplot(211)\n",
    "        fn = self.files[idx].replace('.npz','')\n",
    "        title = '{} channel 0'.format(fn)\n",
    "        plt.title(title)\n",
    "        plt.imshow(X[0][::-1])\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.subplot(212)\n",
    "        title = '{} channel 1'.format(fn)\n",
    "        plt.title(title)\n",
    "        plt.imshow(X[1][::-1])\n",
    "        plt.colorbar()\n",
    "        \n",
    "        if savefig:\n",
    "            title = title.replace(' ','_') + '.png'\n",
    "            plt.savefig(title, dpi=300)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        q = idx // self.simLen\n",
    "        r_idx = np.random.randint(0,self.simLen-self.w)\n",
    "        x = self.data[q*simLen + r_idx : q*simLen + r_idx + 1]\n",
    "        y = self.data[q*simLen + r_idx + 1 : q*simLen + r_idx + 1 + self.w]\n",
    "        # to unpack this data into X (image) and p (cfg settings) arrays, use the following code\n",
    "        U_x, p_x = zip(*x)\n",
    "        U_y, p_y = zip(*y)\n",
    "        return np.array(U_x), np.array(U_y), np.array(p_x), np.array(p_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:14.227220Z",
     "start_time": "2020-10-27T21:04:11.729504Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:04<00:00, 496.02it/s]\n",
      "100%|██████████| 19000/19000 [00:56<00:00, 336.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([40, 1, 2, 128, 96]) torch.Size([40, 1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 2, 128, 96]),\n",
       " torch.Size([40, 5, 2, 128, 96]),\n",
       " torch.Size([40, 3]),\n",
       " torch.Size([40, 5, 3]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets may be smaller because: numSamplesToKeep \n",
    "testDataset = MantaFlowDataset(testData, reverseXY=reverseXY, numToKeep=numSamplesToKeep, AE=False,\n",
    "                               w=simLen-1, simLen=simLen)\n",
    "trainDataset = MantaFlowDataset(trainData, reverseXY=reverseXY,numToKeep=numSamplesToKeep, AE=False,\n",
    "                                w=window_size, simLen=simLen)\n",
    "len(trainDataset), len(testDataset)\n",
    "\n",
    "trainDataLoader = DataLoader(dataset=trainDataset, batch_size=bz, shuffle=True, drop_last=True, pin_memory = True)\n",
    "testDataLoader = DataLoader(dataset=testDataset, batch_size=bz, pin_memory=True)\n",
    "# only use the first frame of each simulation as the input (U_x) for the full simulation test dataloader, \n",
    "# the next 199 frames are stored in the targets (U_y).\n",
    "# added this on 10/27/2020\n",
    "first_frame_testDataset = torch.utils.data.Subset(testDataset, range(0, len(testDataset), simLen))\n",
    "simulation_testDataLoader = DataLoader(dataset= first_frame_testDataset, batch_size=2)\n",
    "\n",
    "U_x, U_y, p_x, p_y = next(iter(trainDataLoader))\n",
    "print(U_x.shape, p_x.shape)\n",
    "U_x = U_x.squeeze(1) # squeeze away the window dimension for inputs, not targets (e.g., not U_y)\n",
    "p_x = p_x.squeeze(1) # squeeze away the window dimension for inputs, not targets (e.g., not U_y)\n",
    "U_x.shape, U_y.shape, p_x.shape, p_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:14.241573Z",
     "start_time": "2020-10-27T21:05:14.231298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 65.0000,  66.0000,  67.0000,  68.0000,  69.0000],\n",
       "        [151.0000, 152.0000, 153.0000, 154.0000, 155.0000],\n",
       "        [185.0000, 186.0000, 187.0000, 188.0000, 189.0000],\n",
       "        [137.0000, 138.0000, 139.0000, 140.0000, 141.0000],\n",
       "        [173.0000, 174.0000, 175.0000, 176.0000, 177.0000],\n",
       "        [153.0000, 154.0000, 155.0000, 156.0000, 157.0000],\n",
       "        [ 16.0000,  17.0000,  18.0000,  19.0000,  20.0000],\n",
       "        [ 73.0000,  74.0000,  75.0000,  76.0000,  77.0000],\n",
       "        [131.0000, 132.0000, 133.0000, 134.0000, 135.0000],\n",
       "        [145.0000, 146.0000, 147.0000, 148.0000, 149.0000]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that timestep number in p_y is contiguous within a window\n",
    "((p_y[:,:,2]+1)/2 * 199)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:14.485041Z",
     "start_time": "2020-10-27T21:05:14.244079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 10\n",
      "tensor([  1.0000,   2.0000,   3.0000,   4.0000,   5.0000,   6.0000,   7.0000,\n",
      "          8.0000,   9.0000,  10.0000,  11.0000,  12.0000,  13.0000,  14.0000,\n",
      "         15.0000,  16.0000,  17.0000,  18.0000,  19.0000,  20.0000,  21.0000,\n",
      "         22.0000,  23.0000,  24.0000,  25.0000,  26.0000,  27.0000,  28.0000,\n",
      "         29.0000,  30.0000,  31.0000,  32.0000,  33.0000,  34.0000,  35.0000,\n",
      "         36.0000,  37.0000,  38.0000,  39.0000,  40.0000,  41.0000,  42.0000,\n",
      "         43.0000,  44.0000,  45.0000,  46.0000,  47.0000,  48.0000,  49.0000,\n",
      "         50.0000,  51.0000,  52.0000,  53.0000,  54.0000,  55.0000,  56.0000,\n",
      "         57.0000,  58.0000,  59.0000,  60.0000,  61.0000,  62.0000,  63.0000,\n",
      "         64.0000,  65.0000,  66.0000,  67.0000,  68.0000,  69.0000,  70.0000,\n",
      "         71.0000,  72.0000,  73.0000,  74.0000,  75.0000,  76.0000,  77.0000,\n",
      "         78.0000,  79.0000,  80.0000,  81.0000,  82.0000,  83.0000,  84.0000,\n",
      "         85.0000,  86.0000,  87.0000,  88.0000,  89.0000,  90.0000,  91.0000,\n",
      "         92.0000,  93.0000,  94.0000,  95.0000,  96.0000,  97.0000,  98.0000,\n",
      "         99.0000, 100.0000, 101.0000, 102.0000, 103.0000, 104.0000, 105.0000,\n",
      "        106.0000, 107.0000, 108.0000, 109.0000, 110.0000, 111.0000, 112.0000,\n",
      "        113.0000, 114.0000, 115.0000, 116.0000, 117.0000, 118.0000, 119.0000,\n",
      "        120.0000, 121.0000, 122.0000, 123.0000, 124.0000, 125.0000, 126.0000,\n",
      "        127.0000, 128.0000, 129.0000, 130.0000, 131.0000, 132.0000, 133.0000,\n",
      "        134.0000, 135.0000, 136.0000, 137.0000, 138.0000, 139.0000, 140.0000,\n",
      "        141.0000, 142.0000, 143.0000, 144.0000, 145.0000, 146.0000, 147.0000,\n",
      "        148.0000, 149.0000, 150.0000, 151.0000, 152.0000, 153.0000, 154.0000,\n",
      "        155.0000, 156.0000, 157.0000, 158.0000, 159.0000, 160.0000, 161.0000,\n",
      "        162.0000, 163.0000, 164.0000, 165.0000, 166.0000, 167.0000, 168.0000,\n",
      "        169.0000, 170.0000, 171.0000, 172.0000, 173.0000, 174.0000, 175.0000,\n",
      "        176.0000, 177.0000, 178.0000, 179.0000, 180.0000, 181.0000, 182.0000,\n",
      "        183.0000, 184.0000, 185.0000, 186.0000, 187.0000, 188.0000, 189.0000,\n",
      "        190.0000, 191.0000, 192.0000, 193.0000, 194.0000, 195.0000, 196.0000,\n",
      "        197.0000, 198.0000, 199.0000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 2, 128, 96]),\n",
       " torch.Size([2, 199, 2, 128, 96]),\n",
       " torch.Size([2, 1, 3]),\n",
       " torch.Size([2, 199, 3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are now subsetting this data to only include the first frame in each sim, p_y and U_y include next 199 frames\n",
    "print(len(simulation_testDataLoader), len(simulation_testDataLoader.dataset))\n",
    "for batch in simulation_testDataLoader:\n",
    "    test_U_x, test_U_y, test_p_x, test_p_y = batch\n",
    "    assert (test_p_x[0,:,2]+1)/2 * 199 == 0\n",
    "    assert (test_p_x[1,:,2]+1)/2 * 199 == 0\n",
    "\n",
    "print(((test_p_y[0,:,2]+1)/2 * 199))\n",
    "test_U_x.shape, test_U_y.shape, test_p_x.shape, test_p_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:21.419955Z",
     "start_time": "2020-10-27T21:05:14.486520Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartoldson1/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 8, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 2, 128, 96]), torch.Size([40, 16]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoder \n",
    "\n",
    "AE_model = AE_xhat_zV2(U_x, filters, latentDim, num_conv, repeat, \n",
    "                 skip_connection, stack, conv_k=3, last_k=3, \n",
    "                 act=nn.LeakyReLU(), return_z=True, stream=createStreamFcn, device='cpu')\n",
    "\n",
    "'''\n",
    "if len(gpu_ids.split(',')) > 1:\n",
    "    AE_model = nn.DataParallel(AE_model)\n",
    "    \n",
    "'''\n",
    "Xhat,z = AE_model(U_x)\n",
    "Xhat.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:21.423738Z",
     "start_time": "2020-10-27T21:05:21.421222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'end_to_end_plateau_train_GPUs23_latentDim16_filters128_bz40_numConv4_streamFalse_jacobianFalse_epochs1000_stackTrue'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "versionName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:21.521933Z",
     "start_time": "2020-10-27T21:05:21.424649Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AE_model.load_state_dict(torch.load(os.path.join('/home/widemann1/surrogates4sims/cps',\n",
    "'plateau_train_GPUs2_latentDim16_filters128_bz16_numConv4_streamFalse_jacobianFalse_epochs1000_stackTrue_lr0.0001')))\n",
    "# for 512 dim ? :\n",
    "#plateau_train_GPUs0_latentDim512_filters128_bz16_numConv4_streamFalse_jacobianFalse_epochs10000_stackTrue_lr0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:21.540592Z",
     "start_time": "2020-10-27T21:05:21.524445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nif len(gpu_ids.split(',')) > 1:\\n    LIN_model = nn.DataParallel(LIN_model)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LIN Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, X, hiddenLayerSizes = [1024], activation=nn.ELU()):\n",
    "        super(MLP,self).__init__()\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.inputSize = X.shape[1:]\n",
    "        self.modules = []\n",
    "        self.modules.append(nn.Linear(np.prod(self.inputSize),hiddenLayerSizes[0]))\n",
    "        self.modules.append(self.activation)\n",
    "        for idx,sz in enumerate(hiddenLayerSizes[:-1]):\n",
    "            self.modules.append(nn.Linear(hiddenLayerSizes[idx],hiddenLayerSizes[idx+1]))\n",
    "            self.modules.append(self.activation)\n",
    "                               \n",
    "        self.modules.append(nn.Linear(hiddenLayerSizes[-1],np.prod(self.inputSize)))\n",
    "        self.layers = nn.Sequential(*self.modules)\n",
    "                                \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "    \n",
    "hiddenLayers = [128,128]\n",
    "LIN_model = MLP(z, hiddenLayerSizes=hiddenLayers, activation=nn.ELU())\n",
    "'''\n",
    "if len(gpu_ids.split(',')) > 1:\n",
    "    LIN_model = nn.DataParallel(LIN_model)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:21.550090Z",
     "start_time": "2020-10-27T21:05:21.542109Z"
    }
   },
   "outputs": [],
   "source": [
    "# surrogate class\n",
    "\n",
    "class Surrogate(nn.Module):\n",
    "    \n",
    "    def __init__(self, window,\n",
    "                 z_size, p_size,\n",
    "                LIN, encoder, decoder):\n",
    "        super(Surrogate, self).__init__()\n",
    "        self.window = window\n",
    "        self.z_size = z_size # this does not include the size of p\n",
    "        self.p_size = p_size\n",
    "        self.c_size = z_size + p_size # this does include the size of p\n",
    "        self.LIN = LIN\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def encode(self, U):\n",
    "        \n",
    "        return self.encoder(U)\n",
    "        \n",
    "    def decode(self, encoding):\n",
    "        \n",
    "        return self.decoder(encoding)\n",
    "        \n",
    "    def predict_next_w_encodings(self, encoding, p_y, window):\n",
    "        '''\n",
    "        use the LIN to predict the next w encodings for each \n",
    "        encoded U in the batch\n",
    "        '''\n",
    "            \n",
    "        predicted_encodings = []\n",
    "            \n",
    "        # given a batch of encodings, advance each encoding window time steps.\n",
    "        # save the result at each time step\n",
    "        for i in range(window):\n",
    "            encoding = self.LIN(encoding) + encoding # use LIN to predict delta in encoding\n",
    "            # this was encoding[:,:,-self.p_size:] in 09_manta..., why the extra dimension?\n",
    "            encoding[:,-self.p_size:] = p_y[:, i]\n",
    "            predicted_encodings.append(encoding)\n",
    "            \n",
    "            \n",
    "        return torch.stack(predicted_encodings)\n",
    "    \n",
    "    def forward(self, U, p_x, p_y, window = None):\n",
    "        \n",
    "        if window == None:\n",
    "            window = self.window\n",
    "        assert p_y.size(1) == window\n",
    "            \n",
    "        encoding = self.encode(U)\n",
    "        encoding[:,-self.p_size:] = p_x # added this on 10/27/2020\n",
    "        encoding_w = self.predict_next_w_encodings(encoding, p_y, window)\n",
    "        # want to have this agree with U_y, which is [batch_size, window_size, channels, nx, ny]\n",
    "        # right now, it's [window_size, batch_size, c_size], so transpose dimensions 0 and 1\n",
    "        # print(encoding_w.shape)\n",
    "        U = torch.stack([self.decode(encoding_i) for encoding_i in encoding_w])\n",
    "        \n",
    "        return U.transpose(0,1)\n",
    "    \n",
    "    \n",
    "surrogate = Surrogate(window_size, latentDim - 3, 3, LIN_model, AE_model.encoder, AE_model.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:21.556185Z",
     "start_time": "2020-10-27T21:05:21.551426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1],\n",
       "         [2, 2],\n",
       "         [3, 3]]),\n",
       " tensor([[1, 1, 2],\n",
       "         [2, 3, 3]]),\n",
       " tensor([[1, 2, 3],\n",
       "         [1, 2, 3]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note the important difference here\n",
    "foo = torch.tensor([[1,1],[2,2],[3,3]])\n",
    "foo, foo.reshape(2,3), foo.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:26.437852Z",
     "start_time": "2020-10-27T21:05:21.557630Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "encoding = surrogate.encode(U_x)\n",
    "decoding = surrogate.decode(encoding)\n",
    "assert surrogate.c_size == latentDim\n",
    "assert surrogate.p_size == len(p_x[0])\n",
    "assert encoding.shape[-1] == surrogate.c_size\n",
    "assert decoding.shape == U_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:41.453900Z",
     "start_time": "2020-10-27T21:05:26.440314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 5, 2, 128, 96]),\n",
       " torch.Size([40, 5, 2, 128, 96]),\n",
       " tensor(395.5565, grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_hat = surrogate.forward(U_x, p_x, p_y)\n",
    "U_hat.shape, U_y.shape, torch.norm(U_hat-U_y,p=1)/torch.norm(U_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:41.525346Z",
     "start_time": "2020-10-27T21:05:41.455377Z"
    }
   },
   "outputs": [],
   "source": [
    "del surrogate, encoding, decoding, U_hat\n",
    "\n",
    "surrogate = Surrogate(window_size, latentDim - 3, 3, LIN_model, AE_model.encoder, AE_model.generator).to(device)\n",
    "\n",
    "if len(gpu_ids.split(',')) > 1:\n",
    "    surrogate = nn.DataParallel(surrogate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:41.533097Z",
     "start_time": "2020-10-27T21:05:41.526870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0615,  0.2370,  0.0193],\n",
       "         [-0.1209, -0.1067,  0.1109],\n",
       "         [-0.0105,  0.0456, -0.2153]],\n",
       "\n",
       "        [[-0.0179,  0.2263, -0.1354],\n",
       "         [ 0.0473, -0.0644, -0.1862],\n",
       "         [-0.0807,  0.0856,  0.0642]]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surrogate.module.encoder.conv1.weight[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:41.538803Z",
     "start_time": "2020-10-27T21:05:41.535635Z"
    }
   },
   "outputs": [],
   "source": [
    "max_lr = .0001\n",
    "start_lr = 5*max_lr/10\n",
    "#opt = create_opt(max_lr,model)\n",
    "#lr_scheduler = create_one_cycle(opt,max_lr,epochs,trainDataLoader)\n",
    "opt = torch.optim.Adam(surrogate.parameters(),lr=max_lr,betas=(.5,.999))\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt,patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:41.547006Z",
     "start_time": "2020-10-27T21:05:41.540083Z"
    }
   },
   "outputs": [],
   "source": [
    "def L1_loss(pred, target):\n",
    "    return torch.mean(torch.abs(pred - target))\n",
    "\n",
    "\n",
    "def jacobian_loss(pred, target, device='cpu'):\n",
    "    return L1_loss(jacobian(pred, device), jacobian(target, device))\n",
    "\n",
    "\n",
    "def curl_loss(pred, target, device):\n",
    "    return L1_loss(curl(pred, device), curl(target, device))\n",
    "\n",
    "\n",
    "L = nn.MSELoss()\n",
    "\n",
    "\n",
    "def p_loss(pred, target):\n",
    "    return L(pred[:, -target.shape[1]:], target)\n",
    "\n",
    "\n",
    "def loss(pred, target, device):\n",
    "    \n",
    "    if createStreamFcn:\n",
    "        pred = stream2uv(pred, device)\n",
    "        \n",
    "    L1 = L1_loss(pred, target)\n",
    "    Lj = 0\n",
    "    if doJacobian:\n",
    "        Lj = jacobian_loss(pred, target, device)\n",
    "        \n",
    "    return L1 + Lj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:41.556025Z",
     "start_time": "2020-10-27T21:05:41.548343Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainEpoch(myDataLoader, tensorboard_writer, model, opt, p_loss, loss,\n",
    "               metric, lr_scheduler, tensorboard_rate, device,\n",
    "               tensorboard_recorder_step, total_steps):\n",
    "    running_loss = 0.0\n",
    "    running_rmse = 0.0\n",
    "    total_loss = 0.0\n",
    "    running_ploss = 0.0\n",
    "    for i, sampleBatch in enumerate(myDataLoader, start=1):\n",
    "\n",
    "        # --- Main Training ---\n",
    "        \n",
    "        # gpu\n",
    "        U_x, U_y, p_x, p_y = sampleBatch\n",
    "        U_x = U_x.squeeze(1).to(device)\n",
    "        p_x = p_x.squeeze(1).to(device)\n",
    "        U_y = U_y.to(device)\n",
    "        p_y = p_y.to(device)\n",
    "            \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        opt.zero_grad()\n",
    "\n",
    "        U_hat = model(U_x, p_x, p_y)\n",
    "        pl = 0\n",
    "        ll = loss(U_hat, U_y, device)\n",
    "        combined_loss = pl + ll\n",
    "        combined_loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        # loss\n",
    "        batch_loss = combined_loss.item()\n",
    "        running_loss += batch_loss\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        batch_ploss = pl\n",
    "        running_ploss += batch_ploss\n",
    "\n",
    "        # --- Metrics Recording ---\n",
    "\n",
    "        # metrics\n",
    "        r = metric(U_hat, U_y)\n",
    "        running_rmse += r\n",
    "\n",
    "        # record lr change\n",
    "        total_steps += 1\n",
    "        tensorboard_writer.add_scalar(tag=\"LR\", scalar_value=opt.param_groups[0]['lr'], global_step=total_steps)\n",
    "        #lr_scheduler.step()\n",
    "\n",
    "        # tensorboard writes\n",
    "        if (i % tensorboard_rate == 0):\n",
    "            tensorboard_recorder_step += 1\n",
    "            avg_running_loss = running_loss/tensorboard_rate\n",
    "            avg_running_rmse = running_rmse/tensorboard_rate\n",
    "            avg_running_ploss = running_ploss/tensorboard_rate\n",
    "            tensorboard_writer.add_scalar(tag=\"Loss\", scalar_value=avg_running_loss, global_step=tensorboard_recorder_step)\n",
    "            tensorboard_writer.add_scalar(tag=\"p_loss\", scalar_value=avg_running_ploss, global_step=tensorboard_recorder_step)\n",
    "            tensorboard_writer.add_scalar(tag=metric.__name__, scalar_value=avg_running_rmse, global_step=tensorboard_recorder_step)\n",
    "            # reset running_loss for the next set of batches. (tensorboard_rate number of batches)\n",
    "            running_loss = 0.0\n",
    "            running_rmse = 0.0\n",
    "            running_ploss = 0.0\n",
    "            tensorboard_writer.flush()\n",
    "\n",
    "    return total_loss/len(myDataLoader), tensorboard_recorder_step, total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:41.563110Z",
     "start_time": "2020-10-27T21:05:41.557409Z"
    }
   },
   "outputs": [],
   "source": [
    "def validEpoch(myDataLoader, tensorboard_writer, model, p_loss, loss, metric,\n",
    "               device, tensorboard_recorder_step):\n",
    "    running_loss = 0.0\n",
    "    running_rmse = 0.0\n",
    "    for i, sampleBatch in enumerate(myDataLoader, start=1):\n",
    "\n",
    "        # --- Metrics Recording ---\n",
    "\n",
    "        # gpu\n",
    "        U_x, U_y, p_x, p_y = sampleBatch\n",
    "        U_x = U_x.squeeze(1).to(device) # only squeeze away the window dimension (because batch size = 1)\n",
    "        p_x = p_x.squeeze(1).to(device) # only squeeze away the window dimension (because batch size = 1)\n",
    "        U_y = U_y.to(device)\n",
    "        p_y = p_y.to(device)\n",
    "        \n",
    "        perc = len(U_x)/len(myDataLoader.dataset)\n",
    "\n",
    "        # forward, no gradient calculations\n",
    "        with torch.no_grad():\n",
    "            U_hat = model(U_x, p_x, p_y, window = simLen-1)\n",
    "\n",
    "        # loss\n",
    "        combined_loss = loss(U_hat, U_y, device)\n",
    "        \n",
    "        running_loss += perc*(combined_loss.item())\n",
    "\n",
    "        # metrics\n",
    "        r = metric(U_hat, U_y)\n",
    "        running_rmse += perc*r\n",
    "\n",
    "    avg_running_loss = running_loss\n",
    "    avg_running_rmse = running_rmse\n",
    "    tensorboard_writer.add_scalar(tag=\"Loss\", scalar_value=avg_running_loss, global_step=tensorboard_recorder_step)\n",
    "    tensorboard_writer.add_scalar(tag=metric.__name__, scalar_value=avg_running_rmse, global_step=tensorboard_recorder_step)\n",
    "    tensorboard_writer.flush()\n",
    "    \n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T21:05:44.779922Z",
     "start_time": "2020-10-27T21:05:41.564421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints directory already exists :)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(cps)\n",
    "except:\n",
    "    print(\"checkpoints directory already exists :)\")\n",
    "    \n",
    "# create a summary writer.\n",
    "train_writer = SummaryWriter(os.path.join(tensorboard_direc, versionName,'train'))\n",
    "test_writer = SummaryWriter(os.path.join(tensorboard_direc, versionName,'valid'))\n",
    "tensorboard_recorder_step = 0\n",
    "total_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-27T21:04:11.120Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Started Training ----------\n",
      "--- Epoch 1/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartoldson1/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.4681e-02\n",
      "LR: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "writeMessage('---------- Started Training ----------', versionName)\n",
    "bestLoss = np.infty\n",
    "\n",
    "if not eval_only:\n",
    "    for epoch in tqdm(range(1, epochs+1)):  # loop over the dataset multiple times\n",
    "\n",
    "        writeMessage(\"--- Epoch {0}/{1} ---\".format(epoch, epochs), versionName)\n",
    "\n",
    "        surrogate.train()\n",
    "        trainLoss, tensorboard_recorder_step, total_steps = trainEpoch(trainDataLoader, \n",
    "                                                                       train_writer, surrogate,\n",
    "                                                                       opt, p_loss, loss,\n",
    "                                                                       rmse, lr_scheduler, \n",
    "                                                                       tensorboard_rate, device,\n",
    "                                                                       tensorboard_recorder_step, total_steps)\n",
    "\n",
    "        writeMessage(\"trainLoss: {:.4e}\".format(trainLoss),versionName)\n",
    "        writeMessage(\"LR: {:.4e}\".format(opt.param_groups[0]['lr']),versionName)\n",
    "#         if trainLoss < bestLoss:\n",
    "#             bestLoss = trainLoss\n",
    "#             writeMessage(\"Better trainLoss: {:.4e}, Saving models...\".format(bestLoss),versionName)\n",
    "#             torch.save(surrogate.state_dict(), os.path.join(cps,versionName))\n",
    "\n",
    "        surrogate.eval()\n",
    "        valLoss = validEpoch(testDataLoader, test_writer, surrogate, p_loss, loss, rmse, device, tensorboard_recorder_step)\n",
    "        writeMessage(\"valLoss: {:.4e}\".format(valLoss),versionName)\n",
    "\n",
    "        # checkpoint progress\n",
    "        if valLoss < bestLoss:\n",
    "            bestLoss = valLoss\n",
    "            writeMessage(\"Better valLoss: {:.4e}, Saving models...\".format(bestLoss),versionName)\n",
    "            torch.save(surrogate.state_dict(), os.path.join(cps,versionName))\n",
    "\n",
    "        lr_scheduler.step(trainLoss)\n",
    "\n",
    "        if opt.param_groups[0]['lr'] < 5e-8:\n",
    "            break\n",
    "    writeMessage('---------- Finished Training ----------', versionName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-27T21:04:11.130Z"
    }
   },
   "outputs": [],
   "source": [
    "surrogate.load_state_dict(torch.load(os.path.join(cps,versionName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-27T21:04:11.142Z"
    }
   },
   "outputs": [],
   "source": [
    "surrogate.eval()\n",
    "U_hats = []\n",
    "Us = []\n",
    "for i, sampleBatch in enumerate(simulation_testDataLoader, start=1):\n",
    "\n",
    "    # gpu\n",
    "    U_x, U_y, p_x, p_y = sampleBatch\n",
    "    U_x = U_x.squeeze(1).to(device)\n",
    "    p_x = p_x.squeeze(1).to(device)\n",
    "    U_y = U_y.to(device)\n",
    "    p_y = p_y.to(device)\n",
    "    with torch.no_grad():\n",
    "        Us.append(U_y.detach().cpu())\n",
    "        \n",
    "        U_hat = surrogate(U_x, p_x, p_y, window=simLen-1)\n",
    "                    \n",
    "        U_hats.append(U_hat.detach().cpu())\n",
    "        \n",
    "        \n",
    "Real_U = torch.stack(Us)\n",
    "#Real_X_img = convertSimToImage(Real_X)\n",
    "\n",
    "Surr_U = torch.stack(U_hats)\n",
    "#Surr_X_img = convertSimToImage(Surr_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-27T21:04:11.154Z"
    }
   },
   "outputs": [],
   "source": [
    "rel_error = torch.norm(Real_U - Surr_U)/torch.norm(Real_U)\n",
    "writeMessage(\"Relative_Error: {:.4e}\".format(rel_error),versionName)\n",
    "test_writer.add_scalar(tag=\"Relative_Error\", scalar_value=rel_error, global_step=tensorboard_recorder_step)\n",
    "test_writer.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
