{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:17.779080Z",
     "start_time": "2020-10-27T00:19:16.157488Z"
    }
   },
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "# --- Must haves ---\n",
    "import os, sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from surrogates4sims.mantaflowDatasets import MantaFlowDataset, getSingleSim, createMantaFlowTrainTest\n",
    "\n",
    "from surrogates4sims.utils import create_opt, create_one_cycle, find_lr, printNumModelParams, \\\n",
    "                                    rmse, writeMessage, plotSampleWprediction, plotSampleWpredictionByChannel, \\\n",
    "                                    plotSample, curl, jacobian, stream2uv, create_movie, convertSimToImage\n",
    "\n",
    "from surrogates4sims.models import Generator, Encoder, AE_no_P, AE_xhat_z, AE_xhat_zV2\n",
    "\n",
    "from surrogates4sims.train import trainEpoch, validEpoch\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:17.888803Z",
     "start_time": "2020-10-27T00:19:17.781976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "(19000, 2000)\n"
     ]
    }
   ],
   "source": [
    "# data \n",
    "eval_only=True\n",
    "DEBUG = False\n",
    "# model name, for tensorboard recording and checkpointing purposes.\n",
    "versionName = \"plateau_train\"\n",
    "\n",
    "# GPU Numbers to use. Comma seprate them for multi-GPUs.\n",
    "gpu_ids = \"1,2\"\n",
    "versionName = versionName + '_GPUs{}'.format(gpu_ids.replace(',',''))\n",
    "# path to load model weights.\n",
    "pretrained_path = None\n",
    "\n",
    "# rate at which to record metrics. (number of batches to average over when recording metrics, e.g. \"every 5 batches\")\n",
    "tensorboard_rate = 5\n",
    "\n",
    "# number of epochs to train. This is defined here so we can use the OneCycle LR Scheduler.\n",
    "epochs = 1000\n",
    "\n",
    "# Data Directory\n",
    "dataDirec = '/data/mantaFlowSim/data/smoke_pos21_size5_f200/v'\n",
    "reverseXY = False \n",
    "\n",
    "# checkpoint directory\n",
    "cps = 'cps'\n",
    "tensorboard_direc = \"tb\"\n",
    "\n",
    "findLRs = False  \n",
    "\n",
    "# hyper-params\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "testSplit = .1\n",
    "bz = 20\n",
    "numSamplesToKeep = 400 #if not debugging\n",
    "latentDim = 16\n",
    "window_size = 5\n",
    "filters = 128\n",
    "num_conv = 4 # breaks when less than 2\n",
    "simLen = 200\n",
    "stack = True\n",
    "simVizIndex = 0 # sim in the test set to visualize\n",
    "createStreamFcn = False\n",
    "doJacobian = False\n",
    "repeat = 0\n",
    "skip_connection = False\n",
    "patience = 2\n",
    "if DEBUG:\n",
    "    epochs = 10000\n",
    "    numSamplesToKeep = bz\n",
    "    \n",
    "versionName = versionName + '_latentDim{}_filters{}_bz{}_numConv{}_stream{}_jacobian{}_epochs{}_stack{}'.format(latentDim,filters,bz,num_conv,createStreamFcn,doJacobian,epochs,stack)\n",
    "versionName\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "trainData, testData = createMantaFlowTrainTest(dataDirec,simLen,testSplit,seed)\n",
    "print((len(trainData),len(testData)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:17.905420Z",
     "start_time": "2020-10-27T00:19:17.891083Z"
    }
   },
   "outputs": [],
   "source": [
    "class MantaFlowDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 dataDirec='/home/widemann1/carbon_capture/surrogate_nn_for_pde/deep-fluids/data/smoke_pos21_size5_f200/v',\n",
    "                 numToKeep=np.infty,transform=None, reverseXY=False, preprocess=True, AE=False,\n",
    "                 w = 1, simLen = 200): \n",
    "        if type(dataDirec) == list:\n",
    "            self.files = dataDirec\n",
    "        else:\n",
    "            self.files = glob(os.path.join(dataDirec,'*.npz'))\n",
    "        self.dataDirec = dataDirec\n",
    "        self.numToKeep = numToKeep\n",
    "        self.transform = transform\n",
    "        self.reverseXY = reverseXY\n",
    "        self.AE = AE\n",
    "        self.w = w\n",
    "        self.simLen = simLen\n",
    "        self.data = []\n",
    " \n",
    "        if numToKeep < len(self.files):\n",
    "            self.files = self.files[:numToKeep]\n",
    "        for f in tqdm(self.files):\n",
    "            X,y = self.loadfile(f)\n",
    "            \n",
    "            if preprocess:\n",
    "                X,y = self.preprocessFcn(X,y)\n",
    "                \n",
    "            if reverseXY:\n",
    "                self.data.append((y,X))\n",
    "            else:\n",
    "                self.data.append((X,y))\n",
    "\n",
    "    def loadfile(self,fn):\n",
    "        A = np.load(fn)\n",
    "        X = A['x'].astype('float32')\n",
    "        X = np.rollaxis(X,-1)\n",
    "        y = A['y'].astype('float32')\n",
    "        return X,y\n",
    "\n",
    "    def preprocessFcn(self,X,y):\n",
    "        x_range = 11.953\n",
    "        X /= x_range\n",
    "        y_range = [[0.2, 0.8], [0.04, 0.12], [0.0, 199.0]]\n",
    "        for i, ri in enumerate(y_range):\n",
    "            y[i] = (y[i]-ri[0]) / (ri[1]-ri[0]) * 2 - 1\n",
    "        return X,y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def plot(self,idx,savefig=False):\n",
    "        X, label  = self.data[idx]\n",
    "        if self.reverseXY:\n",
    "            X = label\n",
    "            \n",
    "        plt.figure(figsize=(20,10))\n",
    "        \n",
    "        plt.subplot(211)\n",
    "        fn = self.files[idx].replace('.npz','')\n",
    "        title = '{} channel 0'.format(fn)\n",
    "        plt.title(title)\n",
    "        plt.imshow(X[0][::-1])\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.subplot(212)\n",
    "        title = '{} channel 1'.format(fn)\n",
    "        plt.title(title)\n",
    "        plt.imshow(X[1][::-1])\n",
    "        plt.colorbar()\n",
    "        \n",
    "        if savefig:\n",
    "            title = title.replace(' ','_') + '.png'\n",
    "            plt.savefig(title, dpi=300)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        q = idx // self.simLen\n",
    "        r_idx = np.random.randint(0,self.simLen-self.w)\n",
    "        x = self.data[q*simLen + r_idx : q*simLen + r_idx + 1]\n",
    "        y = self.data[q*simLen + r_idx + 1 : q*simLen + r_idx + 1 + self.w]\n",
    "        # to unpack this data into X (image) and p (cfg settings) arrays, use the following code\n",
    "        U_x, p_x = zip(*x)\n",
    "        U_y, p_y = zip(*y)\n",
    "        return np.array(U_x), np.array(U_y), np.array(p_x), np.array(p_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:19.333409Z",
     "start_time": "2020-10-27T00:19:17.907271Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:00<00:00, 573.01it/s]\n",
      "100%|██████████| 400/400 [00:00<00:00, 574.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 2, 128, 96]) torch.Size([20, 1, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 2, 128, 96]),\n",
       " torch.Size([20, 5, 2, 128, 96]),\n",
       " torch.Size([20, 3]),\n",
       " torch.Size([20, 5, 3]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets may be smaller because: numSamplesToKeep \n",
    "testDataset = MantaFlowDataset(testData, reverseXY=reverseXY, numToKeep=numSamplesToKeep, AE=False,\n",
    "                               w=window_size, simLen=200)\n",
    "trainDataset = MantaFlowDataset(trainData, reverseXY=reverseXY,numToKeep=numSamplesToKeep, AE=False,\n",
    "                                w=window_size, simLen=200)\n",
    "len(trainDataset), len(testDataset)\n",
    "\n",
    "trainDataLoader = DataLoader(dataset=trainDataset, batch_size=bz, shuffle=True, drop_last=True)\n",
    "testDataLoader = DataLoader(dataset=testDataset, batch_size=bz)\n",
    "\n",
    "U_x, U_y, p_x, p_y = next(iter(trainDataLoader))\n",
    "print(U_x.shape, p_x.shape)\n",
    "U_x = U_x.squeeze()\n",
    "p_x = p_x.squeeze()\n",
    "U_x.shape, U_y.shape, p_x.shape, p_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:22.923185Z",
     "start_time": "2020-10-27T00:19:19.335251Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartoldson1/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 8, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 2, 128, 96]), torch.Size([20, 16]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoder \n",
    "\n",
    "AE_model = AE_xhat_zV2(U_x, filters, latentDim, num_conv, repeat, \n",
    "                 skip_connection, stack, conv_k=3, last_k=3, \n",
    "                 act=nn.LeakyReLU(), return_z=True, stream=createStreamFcn, device='cpu')\n",
    "\n",
    "'''\n",
    "if len(gpu_ids.split(',')) > 1:\n",
    "    AE_model = nn.DataParallel(AE_model)\n",
    "    \n",
    "'''\n",
    "Xhat,z = AE_model(U_x)\n",
    "Xhat.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:23.075714Z",
     "start_time": "2020-10-27T00:19:22.925324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allinOneModel_batchnorm_GPUs0_latentDim16_filters128_bz16_numConv4_streamTrue_jacobianTrue_epochs2_stackTrue_lr0.0001\r\n",
      "allinOneModel_latentDim16_filters128_bz16_numConv4_streamTrue_jacobianTrue_epochs100_stackFalse\r\n",
      "allinOneModel_latentDim16_filters128_bz32_numConv4_streamFalse_jacobianTrue_epochs100_stackFalse\r\n",
      "allinOneModel_latentDim16_filters128_bz32_numConv4_streamFalse_jacobianTrue_epochs100_stackTrue\r\n",
      "allinOneModel_latentDim16_filters128_bz32_numConv4_streamTrue_jacobianTrue_epochs100_stackFalse\r\n",
      "allinOneModel_latentDim16_filters128_bz64_numConv2_streamTrue_jacobianTrue_epochs100_stackFalse\r\n",
      "allinOneModel_latentDim16_filters128_bz64_numConv4_streamTrue_jacobianTrue_epochs2_stackFalse\r\n",
      "allinOneModel_latentDim16_filters128_bz8_numConv4_streamFalse_jacobianTrue_epochs100_stackFalse\r\n",
      "allinOneModel_latentDim16_filters128_bz8_numConv4_streamFalse_jacobianTrue_epochs100_stackTrue\r\n",
      "allinOneModel_latentDim16_filters32_bz128_numConv2_streamFalse_jacobianFalse_epochs100_stackTrue\r\n",
      "allinOneModel_latentDim16_filters32_bz128_numConv2_streamFalse_jacobianTrue_epochs100_stackTrue\r\n",
      "allinOneModel_parallel_batchnorm_latentDim16_filters128_bz16_numConv4_streamTrue_jacobianTrue_epochs100_stackTrue_lr1e-05\r\n",
      "allinOneModel_parallel_latentDim16_filters128_bz16_numConv4_streamFalse_jacobianFalse_epochs100_stackFalse_lr0.0001\r\n",
      "allinOneModel_parallel_latentDim16_filters128_bz16_numConv4_streamTrue_jacobianTrue_epochs100_stackTrue_lr1e-05\r\n",
      "allinOneModel_parallel_latentDim16_filters128_bz32_numConv4_streamTrue_jacobianTrue_epochs100_stackFalse_lr0.0001\r\n",
      "allinOneModel_parallel_latentDim16_filters128_bz64_numConv4_streamFalse_jacobianFalse_epochs100_stackFalse_lr0.0001\r\n",
      "allinOneModel_parallel_latentDim16_filters16_bz128_numConv2_streamTrue_jacobianTrue_epochs100_stackFalse\r\n",
      "allinOneModel_parallel_latentDim16_filters16_bz128_numConv2_streamTrue_jacobianTrue_epochs100_stackFalse_lr0.0001\r\n",
      "allinOneModel_parallel_latentDim16_filters16_bz128_numConv2_streamTrue_jacobianTrue_epochs2_stackFalse\r\n",
      "debug_two_step_training_latentDim16_filters16_bz8_numConv4_streamFalse_jacobianTrue_epochs10_Encoder\r\n",
      "debug_two_step_training_latentDim16_filters16_bz8_numConv4_streamFalse_jacobianTrue_epochs10_Generator\r\n",
      "EandG_as_oneModel_latentDim16_filters128_bz8_numConv4_streamFalse_jacobianTrue_epochs100\r\n",
      "EandG_as_oneModel_latentDim16_filters16_bz8_numConv4_streamFalse_jacobianTrue_epochs10\r\n",
      "EandG_as_oneModel_latentDim16_filters16_bz8_numConv4_streamFalse_jacobianTrue_epochs100\r\n",
      "EandG_as_oneModel_latentDim16_filters16_bz8_numConv4_streamFalse_jacobianTrue_epochs100_stackFalse\r\n",
      "EandG_as_oneModel_ReduceOnPlateau_latentDim16_filters16_bz8_numConv4_streamFalse_jacobianTrue_epochs100\r\n",
      "EandG_as_oneModel_ReduceOnPlateau_latentDim16_filters64_bz8_numConv4_streamFalse_jacobianTrue_epochs100\r\n",
      "elu_GPUs1_latentDim512_filters128_bz8_numConv4_streamFalse_jacobianFalse_epochs25_stackTrue_lr0.0001\r\n",
      "elu_GPUs2_latentDim512_filters128_bz8_numConv4_streamFalse_jacobianFalse_epochs25_stackFalse_lr0.0001\r\n",
      "extra_train_GPUs0123_latentDim512_filters128_bz100_numConv4_streamFalse_jacobianFalse_epochs25_stackFalse_lr0.0001\r\n",
      "extra_train_GPUs123_latentDim512_filters128_bz50_numConv4_streamFalse_jacobianFalse_epochs25_stackFalse_lr0.0001_lr0.0001\r\n",
      "full_svd_manta_MLP_GPUs0_w30_latentDim16_hd128_128_bz64_epochs1000_lr0.001\r\n",
      "full_svd_manta_MLP_GPUs0_w30_latentDim16_hd128_128_bz64_epochs1000_lr0.001_lr0.001\r\n",
      "full_svd_manta_MLP_GPUs0_w30_latentDim64_hd128_128_bz64_epochs1000_lr0.001\r\n",
      "full_svd_manta_MLP_GPUs1_w100_latentDim16_hd128_128_bz32_epochs1000_lr0.001\r\n",
      "full_svd_manta_MLP_GPUs1_w100_latentDim64_hd128_128_bz32_epochs1000_lr0.001\r\n",
      "full_svd_manta_MLP_GPUs1_w30_latentDim512_hd128_128_bz64_epochs1000_lr0.001\r\n",
      "full_svd_manta_MLP_GPUs2_w175_latentDim16_hd128_128_bz32_epochs1000_lr0.001\r\n",
      "full_svd_manta_MLP_GPUs2_w175_latentDim64_hd128_128_bz32_epochs1000_lr0.001\r\n",
      "full_svd_manta_MLP_GPUs2_w50_latentDim16_hd128_128_bz32_epochs1000_lr0.001\r\n",
      "full_svd_manta_MLP_GPUs3_w150_latentDim16_hd128_128_bz32_epochs1000_lr0.001\r\n",
      "full_svd_manta_MLP_GPUs3_w150_latentDim64_hd128_128_bz32_epochs1000_lr0.001\r\n",
      "gangam_style_training_latentDim16_filters16_bz8_numConv4_streamFalse_jacobianTrue_epochs100_Encoder\r\n",
      "gangam_style_training_latentDim16_filters16_bz8_numConv4_streamFalse_jacobianTrue_epochs100_Generator\r\n",
      "Generator_only_latentDim3_filters128_bz8_numConv4_streamFalse_jacobianTrue_epochs100\r\n",
      "LIN_manta_SVD_MLP_GPUs0_w100_latentDim16_hd16_bz64_epochs1000_lr0.01\r\n",
      "LIN_manta_SVD_MLP_GPUs0_w1_latentDim16_hd16_bz64_epochs1000_lr0.01\r\n",
      "LIN_manta_SVD_MLP_GPUs0_w30_latentDim16_hd128_128_bz64_epochs1000_lr0.001\r\n",
      "LIN_manta_SVD_MLP_GPUs0_w30_latentDim16_hd128_128_bz64_epochs1000_lr0.001_lr0.001\r\n",
      "LIN_manta_SVD_MLP_GPUs0_w30_latentDim16_hd16_bz64_epochs1000_lr0.01\r\n",
      "LIN_manta_SVD_MLP_GPUs1_w10_latentDim16_hd128_128_bz64_epochs1000_lr0.01\r\n",
      "LIN_manta_SVD_MLP_GPUs2_w10_latentDim16_hd8_bz4_epochs2_lr0.001\r\n",
      "LIN_manta_SVD_MLP_GPUs2_w30_latentDim16_hd128_128_bz4_epochs1000_lr0.001\r\n",
      "LIN_SVD_GPUs0_latentDim512_bz50_epochs1000_lr0.01\r\n",
      "LIN_SVD_GPUs0_latentDim512_bz50_epochs100_lr0.01\r\n",
      "LIN_SVD_GPUs0_latentDim512_bz50_epochs25_lr0.01\r\n",
      "LIN_SVD_GPUs0_latentDim512_bz50_epochs2_lr0.01\r\n",
      "LIN_SVD_GPUs0_latentDim512_bz50_epochs2_lr0.01_lr0.01\r\n",
      "LIN_SVD_MLP_manta_w10_latentDim16_hd128_128_bz64_epochs1000_lr0.005\r\n",
      "LIN_SVD_MLP_manta_w10_latentDim512_hd128_128_bz64_epochs1000_lr0.001\r\n",
      "LIN_SVD_one_cycle_GPUs0_latentDim512_bz50_epochs100_lr0.005\r\n",
      "LIN_SVD_one_cycle_GPUs0_latentDim512_bz50_epochs2_lr0.005\r\n",
      "LIN_SVD_only_p_LSTM_bidirec_GPUs1_latentDim512_bz1_epochs1000_lr0.01\r\n",
      "LIN_SVD_only_p_LSTM_bidirec_GPUs1_latentDim512_bz1_epochs1000_lr0.01_lr0.01\r\n",
      "LIN_SVD_only_p_LSTM_GPUs1_latentDim512_bz1_epochs1000_lr0.01\r\n",
      "LIN_SVD_only_p_LSTM_GPUs1_latentDim512_bz1_epochs1000_lr0.01_lr0.01\r\n",
      "LIN_SVD_only_p_LSTM_GPUs1_latentDim512_bz1_epochs2_lr0.01\r\n",
      "LIN_SVD_only_z_and_p_LSTM_bidirec_GPUs2_latentDim512_bz4_epochs1000_lr0.001\r\n",
      "LIN_SVD_only_z_and_p_LSTM_bidirec_GPUs2_latentDim512_bz4_transformTrue_epochs1000_lr0.001\r\n",
      "LIN_SVD_only_z_and_p_LSTM_bidirec_GPUs2_latentDim512_bz4_transformTrue_epochs1000_lr0.001_lr0.001\r\n",
      "LIN_SVD_plateau_GPUs0_latentDim512_bz50_epochs1000_lr0.005\r\n",
      "LIN_SVD_plateau_GPUs0_latentDim512_bz50_hiddenLayer1024_epochs10000_lr0.01\r\n",
      "LIN_SVD_plateau_GPUs0_latentDim512_bz50_hiddenLayer1024_epochs1000_lr0.01_lr0.01\r\n",
      "LIN_SVD_plateau_GPUs0_latentDim512_bz50_hiddenLayer1024_epochs5000_lr0.01\r\n",
      "LIN_SVD_plateau_GPUs2_latentDim512_bz50_hiddenLayer1024_epochs1000_lr0.005_lr0.01\r\n",
      "model_333_plateau_full_GPUs0123_latentDim512_filters128_bz50_numConv4_streamFalse_jacobianFalse_epochs1000_stackFalse_lr0.0001\r\n",
      "oneModel_latentDim16_filters16_bz32_numConv2_streamFalse_jacobianTrue_epochs2_stackTrue\r\n",
      "oneModel_latentDim16_filters16_bz32_numConv4_streamFalse_jacobianTrue_epochs2_stackTrue\r\n",
      "overfit_batch_GPUs0123_latentDim512_filters128_bz512_numConv4_streamFalse_jacobianFalse_epochs1000_stackFalse_lr0.0001\r\n",
      "overfit_batch_GPUs0123_latentDim512_filters128_bz512_numConv4_streamFalse_jacobianFalse_epochs100_stackFalse_lr0.0001\r\n",
      "overfit_batch_GPUs0123_latentDim512_filters128_bz64_numConv4_streamFalse_jacobianFalse_epochs50000_stackFalse_lr0.0001\r\n",
      "plateau_32_GPUs0_latentDim512_filters128_bz8_numConv4_streamFalse_jacobianFalse_epochs200_stackFalse_lr0.0001\r\n",
      "plateau_full_GPUs0123_latentDim512_filters128_bz50_numConv4_streamFalse_jacobianFalse_epochs1000_stackFalse_lr0.0001\r\n",
      "plateau_full_GPUs0_latentDim512_filters128_bz8_numConv4_streamFalse_jacobianFalse_epochs1000_stackFalse_lr0.001\r\n",
      "plateau_train_GPUs0123_latentDim512_filters128_bz32_numConv4_streamFalse_jacobianFalse_epochs1000_stackTrue_lr0.0001\r\n",
      "plateau_train_GPUs0123_latentDim512_filters128_bz50_numConv4_streamFalse_jacobianFalse_epochs1000_stackTrue_lr0.0001\r\n",
      "plateau_train_GPUs0123_latentDim512_filters128_bz75_numConv4_streamFalse_jacobianFalse_epochs1000_stackTrue_lr0.0001\r\n",
      "plateau_train_GPUs0_latentDim512_filters128_bz16_numConv4_streamFalse_jacobianFalse_epochs10000_stackTrue_lr0.0001\r\n",
      "plateau_train_GPUs0_latentDim512_filters128_bz16_numConv4_streamFalse_jacobianFalse_epochs1000_stackTrue_lr0.0001\r\n",
      "plateau_train_GPUs0_latentDim512_filters128_bz8_numConv4_streamFalse_jacobianFalse_epochs1000_stackTrue_lr0.0001\r\n",
      "plateau_train_GPUs2_latentDim16_filters128_bz16_numConv4_streamFalse_jacobianFalse_epochs1000_stackTrue_lr0.0001\r\n",
      "pnnl_plateau_train_GPUs0_channel1_gridSize128_latentDim1000_filters128_bz16_numConv4_jacobianFalse_epochs1000_stackTrue_lr0.0001\r\n",
      "pnnl_plateau_train_GPUs0_channel1_gridsize128_latentDim16_filters128_bz16_numConv4_jacobianFalse_epochs1000_stackTrue_lr0.0001\r\n",
      "pnnl_plateau_train_GPUs0_channel1_gridsize128_latentDim16_filters128_bz16_numConv4_jacobianFalse_epochs2_stackTrue_lr0.0001\r\n",
      "pnnl_plateau_train_GPUs1_channel0_gridSize128_latentDim1000_filters128_bz16_numConv4_jacobianFalse_epochs1000_stackTrue_lr0.0001\r\n",
      "pnnl_plateau_train_GPUs1_channel1_gridSize128_latentDim1000_filters128_bz16_numConv2_jacobianFalse_epochs1000_stackTrue_lr0.0001\r\n",
      "pnnl_plateau_train_GPUs2_channel1_gridSize128_latentDim1000_filters128_bz16_numConv4_jacobianFalse_epochs1000_stackTrue_lr0.0001\r\n",
      "pnnl_plateau_train_GPUs2_channel1_gridSize128_latentDim1000_filters128_bz16_numConv4_jacobianFalse_epochs2_stackTrue_lr0.0001\r\n",
      "pnnl_plateau_train_GPUs3_channel2_gridSize128_latentDim1000_filters128_bz16_numConv4_jacobianFalse_epochs1000_stackTrue_lr0.0001\r\n",
      "pnnl_plateau_train_MLP_GPUs0_channel1_gridSize128_latentDim1000_bz16_jacobianFalse_epochs2_lr0.0001\r\n",
      "silu_GPUs0123_latentDim512_filters128_bz50_numConv4_streamFalse_jacobianFalse_epochs25_stackFalse_lr0.0001\r\n",
      "silu_GPUs0_latentDim512_filters128_bz8_numConv4_streamFalse_jacobianFalse_epochs25_stackTrue_lr0.0001\r\n",
      "silu_GPUs3_latentDim512_filters128_bz8_numConv4_streamFalse_jacobianFalse_epochs25_stackFalse_lr0.0001\r\n",
      "training_template_example_latentDim16_initFilters32_bz32_numConv0_numGconv8\r\n",
      "train_master_GPUs0123_latentDim128_filters128_bz50_numConv4_streamFalse_jacobianFalse_epochs10_stackTrue_lr0.0001\r\n",
      "train_master_GPUs0123_latentDim16_filters128_bz50_numConv4_streamFalse_jacobianTrue_epochs10_stackTrue_lr0.0001\r\n",
      "train_master_GPUs0123_latentDim512_filters128_bz128_numConv2_streamTrue_jacobianFalse_epochs25_stackFalse_lr0.0001\r\n",
      "train_master_GPUs0123_latentDim512_filters128_bz50_numConv2_streamFalse_jacobianFalse_epochs1_stackFalse_lr0.0001\r\n",
      "train_master_GPUs0123_latentDim512_filters128_bz50_numConv2_streamFalse_jacobianFalse_epochs25_stackFalse_lr0.0001\r\n",
      "train_master_GPUs0123_latentDim512_filters128_bz50_numConv4_streamFalse_jacobianFalse_epochs25_stackFalse_lr0.0001\r\n",
      "train_master_GPUs0123_latentDim512_filters128_bz8_numConv4_streamFalse_jacobianFalse_epochs200_stackFalse_lr1e-05\r\n",
      "train_master_GPUs0123_latentDim512_filters128_bz8_numConv4_streamFalse_jacobianFalse_epochs2_stackFalse_lr1e-05\r\n",
      "train_master_GPUs0_latentDim16_filters128_bz16_numConv4_streamFalse_jacobianTrue_epochs100_stackTrue_lr0.0001\r\n",
      "train_master_GPUs2_latentDim512_filters128_bz8_numConv2_streamFalse_jacobianFalse_epochs100_stackFalse_lr1e-05\r\n",
      "train_master_LK_bn_GPUs0123_latentDim16_filters128_bz50_numConv2_streamFalse_jacobianFalse_epochs25_stackFalse_lr0.001\r\n",
      "train_master_LK_GPUs0123_latentDim16_filters128_bz50_numConv2_streamFalse_jacobianFalse_epochs25_stackFalse_lr0.0001\r\n",
      "train_master_LK_GPUs0_latentDim16_filters128_bz50_numConv2_streamFalse_jacobianFalse_epochs2_stackFalse\r\n",
      "train_template_encoder_only_latentDim16_filters128_bz32_numConv4_curlTrue_jacobianTrue\r\n",
      "train_template_encoder_only_latentDim16_filters128_bz32_numConv4_streamFalse_jacobianTrue_Encoder\r\n",
      "train_template_encoder_only_latentDim16_filters128_bz32_numConv4_streamFalse_jacobianTrue_Generator\r\n",
      "train_template_encoder_only_latentDim16_filters128_bz8_numConv4_streamFalse_jacobianTrue_Encoder\r\n",
      "train_template_encoder_only_latentDim16_filters128_bz8_numConv4_streamFalse_jacobianTrue_Generator\r\n",
      "train_template_encoder_only_latentDim16_filters16_bz32_numConv4_streamFalse_jacobianTrue_Encoder\r\n",
      "train_template_encoder_only_latentDim16_filters16_bz32_numConv4_streamFalse_jacobianTrue_Generator\r\n",
      "train_template_encoder_only_latentDim16_filters16_bz8_numConv4_streamFalse_jacobianTrue_Encoder\r\n",
      "train_template_encoder_only_latentDim16_filters16_bz8_numConv4_streamFalse_jacobianTrue_Generator\r\n",
      "train_template_encoder_only_latentDim16_filters32_bz32_numConv4_streamFalse_jacobianTrue_Encoder\r\n",
      "train_template_encoder_only_latentDim16_filters32_bz32_numConv4_streamFalse_jacobianTrue_Generator\r\n",
      "train_template_encoder_only_latentDim16_filters32_bz8_numConv4_streamFalse_jacobianTrue_Encoder\r\n",
      "train_template_encoder_only_latentDim16_filters32_bz8_numConv4_streamFalse_jacobianTrue_Generator\r\n",
      "train_template_encoder_only_latentDim16_filters64_bz32_numConv4_streamFalse_jacobianTrue_Encoder\r\n",
      "train_template_encoder_only_latentDim16_filters64_bz32_numConv4_streamFalse_jacobianTrue_Generator\r\n",
      "train_template_encoder_only_latentDim16_filters64_bz8_numConv4_streamFalse_jacobianTrue_Encoder\r\n",
      "train_template_encoder_only_latentDim16_filters64_bz8_numConv4_streamFalse_jacobianTrue_Generator\r\n",
      "train_template_latentDim16_filters128_bz32_numConv4\r\n",
      "train_test_025_pnnl_plateau_train_GPUs3_channel1_gridSize128_latentDim1000_filters128_bz16_numConv2_jacobianFalse_epochs1000_stackTrue_lr0.0001\r\n",
      "two_step_training_latentDim16_filters16_bz8_numConv4_streamFalse_jacobianTrue_Encoder\r\n",
      "two_step_training_latentDim16_filters16_bz8_numConv4_streamFalse_jacobianTrue_epochs100_Encoder\r\n",
      "two_step_training_latentDim16_filters16_bz8_numConv4_streamFalse_jacobianTrue_epochs100_Generator\r\n",
      "two_step_training_latentDim16_filters16_bz8_numConv4_streamFalse_jacobianTrue_Generator\r\n",
      "wave_master_GPUs0_latentDim16_filters16_bz32_numConv2_streamFalse_jacobianFalse_epochs1_stackFalse_lr0.001\r\n",
      "wave_master_GPUs0_latentDim16_filters16_bz32_numConv2_streamFalse_jacobianFalse_epochs1_stackFalse_lr0.001_lr0.001_lr0.001\r\n",
      "wave_master_GPUs0_latentDim16_filters16_bz32_numConv2_streamFalse_jacobianFalse_epochs2_stackFalse_lr0.001\r\n"
     ]
    }
   ],
   "source": [
    "!ls '/home/widemann1/surrogates4sims/cps/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:23.085283Z",
     "start_time": "2020-10-27T00:19:23.079147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plateau_train_GPUs12_latentDim16_filters128_bz20_numConv4_streamFalse_jacobianFalse_epochs1000_stackTrue'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "versionName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:24.938995Z",
     "start_time": "2020-10-27T00:19:23.090218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AE_model.load_state_dict(torch.load(os.path.join('/home/widemann1/surrogates4sims/cps',\n",
    "'plateau_train_GPUs2_latentDim16_filters128_bz16_numConv4_streamFalse_jacobianFalse_epochs1000_stackTrue_lr0.0001')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:25.017895Z",
     "start_time": "2020-10-27T00:19:24.940796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nif len(gpu_ids.split(',')) > 1:\\n    LIN_model = nn.DataParallel(LIN_model)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LIN Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, X, hiddenLayerSizes = [1024], activation=nn.ELU()):\n",
    "        super(MLP,self).__init__()\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.inputSize = X.shape[1:]\n",
    "        self.modules = []\n",
    "        self.modules.append(nn.Linear(np.prod(self.inputSize),hiddenLayerSizes[0]))\n",
    "        self.modules.append(self.activation)\n",
    "        for idx,sz in enumerate(hiddenLayerSizes[:-1]):\n",
    "            self.modules.append(nn.Linear(hiddenLayerSizes[idx],hiddenLayerSizes[idx+1]))\n",
    "            self.modules.append(self.activation)\n",
    "                               \n",
    "        self.modules.append(nn.Linear(hiddenLayerSizes[-1],np.prod(self.inputSize)))\n",
    "        self.layers = nn.Sequential(*self.modules)\n",
    "                                \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "    \n",
    "hiddenLayers = [128,128]\n",
    "LIN_model = MLP(z, hiddenLayerSizes=hiddenLayers, activation=nn.ELU())\n",
    "'''\n",
    "if len(gpu_ids.split(',')) > 1:\n",
    "    LIN_model = nn.DataParallel(LIN_model)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:25.021938Z",
     "start_time": "2020-10-27T00:19:25.019528Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# LIN_model(torch.ones((1,16),device=device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:25.031494Z",
     "start_time": "2020-10-27T00:19:25.023509Z"
    }
   },
   "outputs": [],
   "source": [
    "# surrogate class\n",
    "\n",
    "class Surrogate(nn.Module):\n",
    "    \n",
    "    def __init__(self, window,\n",
    "                 z_size, p_size,\n",
    "                LIN, encoder, decoder):\n",
    "        super(Surrogate, self).__init__()\n",
    "        self.window = window\n",
    "        self.z_size = z_size # this does not include the size of p\n",
    "        self.p_size = p_size\n",
    "        self.c_size = z_size + p_size # this does include the size of p\n",
    "        self.LIN = LIN\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def encode(self, U):\n",
    "        \n",
    "        return self.encoder(U)\n",
    "        \n",
    "    def decode(self, encoding):\n",
    "        \n",
    "        return self.decoder(encoding)\n",
    "        \n",
    "    def predict_next_w_encodings(self, encoding, p_y, window = None):\n",
    "        '''\n",
    "        use the LIN to predict the next w encodings for each \n",
    "        encoded U in the batch\n",
    "        '''\n",
    "        \n",
    "        if window == None:\n",
    "            window = self.window\n",
    "            \n",
    "        predicted_encodings = []\n",
    "            \n",
    "        # given a batch of encodings, advance each encoding window time steps.\n",
    "        # save the result at each time step\n",
    "        for i in range(window):\n",
    "            encoding = self.LIN(encoding) + encoding # use LIN to predict delta in encoding\n",
    "            # this was encoding[:,:,-self.p_size:] in 09_manta..., why the extra dimension?\n",
    "            encoding[:,-self.p_size:] = p_y[:, i]\n",
    "            predicted_encodings.append(encoding)\n",
    "            \n",
    "            \n",
    "        return torch.stack(predicted_encodings)\n",
    "    \n",
    "    def forward(self, U, p_y):\n",
    "        \n",
    "        encoding = self.encode(U)\n",
    "        encoding_w = self.predict_next_w_encodings(encoding, p_y)\n",
    "        # want to have this agree with U_y, which is [batch_size, window_size, channels, nx, ny]\n",
    "        # right now, it's [window_size, batch_size, c_size], so transpose dimensions 0 and 1\n",
    "        # print(encoding_w.shape)\n",
    "        U = torch.stack([self.decode(encoding_i) for encoding_i in encoding_w])\n",
    "        \n",
    "        return U.transpose(0,1)\n",
    "    \n",
    "    \n",
    "surrogate = Surrogate(window_size, latentDim - 3, 3, LIN_model, AE_model.encoder, AE_model.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:25.038266Z",
     "start_time": "2020-10-27T00:19:25.033161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1],\n",
       "         [2, 2],\n",
       "         [3, 3]]),\n",
       " tensor([[1, 1, 2],\n",
       "         [2, 3, 3]]),\n",
       " tensor([[1, 2, 3],\n",
       "         [1, 2, 3]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note the important difference here\n",
    "foo = torch.tensor([[1,1],[2,2],[3,3]])\n",
    "foo, foo.reshape(2,3), foo.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:27.598822Z",
     "start_time": "2020-10-27T00:19:25.039415Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "encoding = surrogate.encode(U_x)\n",
    "decoding = surrogate.decode(encoding)\n",
    "assert surrogate.c_size == 16\n",
    "assert surrogate.p_size == len(p_x[0])\n",
    "assert encoding.shape[-1] == surrogate.c_size\n",
    "assert decoding.shape == U_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:35.240971Z",
     "start_time": "2020-10-27T00:19:27.600489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 5, 2, 128, 96]),\n",
       " torch.Size([20, 5, 2, 128, 96]),\n",
       " tensor(367.6299, grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_hat = surrogate.forward(U_x, p_y)\n",
    "U_hat.shape, U_y.shape, torch.norm(U_hat-U_y,p=1)/torch.norm(U_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:35.280381Z",
     "start_time": "2020-10-27T00:19:35.242395Z"
    }
   },
   "outputs": [],
   "source": [
    "del surrogate, encoding, decoding, U_hat\n",
    "surrogate = Surrogate(window_size, latentDim - 3, 3, LIN_model, AE_model.encoder, AE_model.generator).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:35.286448Z",
     "start_time": "2020-10-27T00:19:35.281771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0615,  0.2370,  0.0193],\n",
       "         [-0.1209, -0.1067,  0.1109],\n",
       "         [-0.0105,  0.0456, -0.2153]],\n",
       "\n",
       "        [[-0.0179,  0.2263, -0.1354],\n",
       "         [ 0.0473, -0.0644, -0.1862],\n",
       "         [-0.0807,  0.0856,  0.0642]]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surrogate.encoder.conv1.weight[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:35.290749Z",
     "start_time": "2020-10-27T00:19:35.287466Z"
    }
   },
   "outputs": [],
   "source": [
    "max_lr = .0001\n",
    "start_lr = 5*max_lr/10\n",
    "#opt = create_opt(max_lr,model)\n",
    "#lr_scheduler = create_one_cycle(opt,max_lr,epochs,trainDataLoader)\n",
    "opt = torch.optim.Adam(surrogate.parameters(),lr=max_lr,betas=(.5,.999))\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt,patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:35.296565Z",
     "start_time": "2020-10-27T00:19:35.291839Z"
    }
   },
   "outputs": [],
   "source": [
    "def L1_loss(pred, target):\n",
    "    return torch.mean(torch.abs(pred - target))\n",
    "\n",
    "\n",
    "def jacobian_loss(pred, target, device='cpu'):\n",
    "    return L1_loss(jacobian(pred, device), jacobian(target, device))\n",
    "\n",
    "\n",
    "def curl_loss(pred, target, device):\n",
    "    return L1_loss(curl(pred, device), curl(target, device))\n",
    "\n",
    "\n",
    "L = nn.MSELoss()\n",
    "\n",
    "\n",
    "def p_loss(pred, target):\n",
    "    return L(pred[:, -target.shape[1]:], target)\n",
    "\n",
    "\n",
    "def loss(pred, target, device):\n",
    "    \n",
    "    if createStreamFcn:\n",
    "        pred = stream2uv(pred, device)\n",
    "        \n",
    "    L1 = L1_loss(pred, target)\n",
    "    Lj = 0\n",
    "    if doJacobian:\n",
    "        Lj = jacobian_loss(pred, target, device)\n",
    "        \n",
    "    return L1 + Lj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:35.304492Z",
     "start_time": "2020-10-27T00:19:35.297587Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainEpoch(myDataLoader, tensorboard_writer, model, opt, p_loss, loss,\n",
    "               metric, lr_scheduler, tensorboard_rate, device,\n",
    "               tensorboard_recorder_step, total_steps):\n",
    "    running_loss = 0.0\n",
    "    running_rmse = 0.0\n",
    "    total_loss = 0.0\n",
    "    running_ploss = 0.0\n",
    "    for i, sampleBatch in enumerate(myDataLoader, start=1):\n",
    "\n",
    "        # --- Main Training ---\n",
    "        \n",
    "        # gpu\n",
    "        U_x, U_y, p_x, p_y = sampleBatch\n",
    "        U_x = U_x.squeeze().to(device)\n",
    "        p_x = p_x.squeeze().to(device)\n",
    "        U_y = U_y.to(device)\n",
    "        p_y = p_y.to(device)\n",
    "            \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        opt.zero_grad()\n",
    "\n",
    "        U_hat = model(U_x, p_y)\n",
    "        pl = 0\n",
    "        ll = loss(U_hat, U_y, device)\n",
    "        combined_loss = pl + ll\n",
    "        combined_loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        # loss\n",
    "        batch_loss = combined_loss.item()\n",
    "        running_loss += batch_loss\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        batch_ploss = pl\n",
    "        running_ploss += batch_ploss\n",
    "\n",
    "        # --- Metrics Recording ---\n",
    "\n",
    "        # metrics\n",
    "        r = metric(U_hat, U_y)\n",
    "        running_rmse += r\n",
    "\n",
    "        # record lr change\n",
    "        total_steps += 1\n",
    "        tensorboard_writer.add_scalar(tag=\"LR\", scalar_value=opt.param_groups[0]['lr'], global_step=total_steps)\n",
    "        #lr_scheduler.step()\n",
    "\n",
    "        # tensorboard writes\n",
    "        if (i % tensorboard_rate == 0):\n",
    "            tensorboard_recorder_step += 1\n",
    "            avg_running_loss = running_loss/tensorboard_rate\n",
    "            avg_running_rmse = running_rmse/tensorboard_rate\n",
    "            avg_running_ploss = running_ploss/tensorboard_rate\n",
    "            tensorboard_writer.add_scalar(tag=\"Loss\", scalar_value=avg_running_loss, global_step=tensorboard_recorder_step)\n",
    "            tensorboard_writer.add_scalar(tag=\"p_loss\", scalar_value=avg_running_ploss, global_step=tensorboard_recorder_step)\n",
    "            tensorboard_writer.add_scalar(tag=metric.__name__, scalar_value=avg_running_rmse, global_step=tensorboard_recorder_step)\n",
    "            # reset running_loss for the next set of batches. (tensorboard_rate number of batches)\n",
    "            running_loss = 0.0\n",
    "            running_rmse = 0.0\n",
    "            running_ploss = 0.0\n",
    "\n",
    "    return total_loss, tensorboard_recorder_step, total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:19:37.792322Z",
     "start_time": "2020-10-27T00:19:35.305459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints directory already exists :)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(cps)\n",
    "except:\n",
    "    print(\"checkpoints directory already exists :)\")\n",
    "    \n",
    "# create a summary writer.\n",
    "train_writer = SummaryWriter(os.path.join(tensorboard_direc, versionName,'train'))\n",
    "test_writer = SummaryWriter(os.path.join(tensorboard_direc, versionName,'valid'))\n",
    "tensorboard_recorder_step = 0\n",
    "total_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:56:40.590582Z",
     "start_time": "2020-10-27T00:19:37.795054Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Started Training ----------\n",
      "--- Epoch 1/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartoldson1/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 4.0941e-01\n",
      "LR: 1.0000e-04\n",
      "Better trainLoss: 4.0941e-01, Saving models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/1000 [00:14<3:57:36, 14.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 2/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/1000 [00:27<3:53:14, 14.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 3.5289e-01\n",
      "LR: 1.0000e-04\n",
      "Better trainLoss: 3.5289e-01, Saving models...\n",
      "--- Epoch 3/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/1000 [00:41<3:50:11, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 3.2235e-01\n",
      "LR: 1.0000e-04\n",
      "Better trainLoss: 3.2235e-01, Saving models...\n",
      "--- Epoch 4/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/1000 [00:54<3:48:08, 13.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 2.9835e-01\n",
      "LR: 1.0000e-04\n",
      "Better trainLoss: 2.9835e-01, Saving models...\n",
      "--- Epoch 5/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/1000 [01:08<3:48:08, 13.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 2.9435e-01\n",
      "LR: 1.0000e-04\n",
      "Better trainLoss: 2.9435e-01, Saving models...\n",
      "--- Epoch 6/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 6/1000 [01:22<3:47:05, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 2.8774e-01\n",
      "LR: 1.0000e-04\n",
      "Better trainLoss: 2.8774e-01, Saving models...\n",
      "--- Epoch 7/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 7/1000 [01:35<3:46:15, 13.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 2.8256e-01\n",
      "LR: 1.0000e-04\n",
      "Better trainLoss: 2.8256e-01, Saving models...\n",
      "--- Epoch 8/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 8/1000 [01:49<3:45:45, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 2.5913e-01\n",
      "LR: 1.0000e-04\n",
      "Better trainLoss: 2.5913e-01, Saving models...\n",
      "--- Epoch 9/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 9/1000 [02:02<3:45:14, 13.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 2.3177e-01\n",
      "LR: 1.0000e-04\n",
      "Better trainLoss: 2.3177e-01, Saving models...\n",
      "--- Epoch 10/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 10/1000 [02:16<3:44:11, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 2.3583e-01\n",
      "LR: 1.0000e-04\n",
      "--- Epoch 11/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 11/1000 [02:29<3:43:26, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 2.3752e-01\n",
      "LR: 1.0000e-04\n",
      "--- Epoch 12/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 12/1000 [02:43<3:43:30, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 2.1520e-01\n",
      "LR: 1.0000e-04\n",
      "Better trainLoss: 2.1520e-01, Saving models...\n",
      "--- Epoch 13/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 13/1000 [02:56<3:42:40, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 2.3048e-01\n",
      "LR: 1.0000e-04\n",
      "--- Epoch 14/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 14/1000 [03:10<3:42:02, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 2.4872e-01\n",
      "LR: 1.0000e-04\n",
      "--- Epoch 15/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 15/1000 [03:23<3:41:38, 13.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 2.2120e-01\n",
      "LR: 1.0000e-04\n",
      "--- Epoch 16/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 16/1000 [03:37<3:41:55, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.5677e-01\n",
      "LR: 1.0000e-05\n",
      "Better trainLoss: 1.5677e-01, Saving models...\n",
      "--- Epoch 17/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 17/1000 [03:51<3:42:05, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.3463e-01\n",
      "LR: 1.0000e-05\n",
      "Better trainLoss: 1.3463e-01, Saving models...\n",
      "--- Epoch 18/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 18/1000 [04:04<3:42:00, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.3152e-01\n",
      "LR: 1.0000e-05\n",
      "Better trainLoss: 1.3152e-01, Saving models...\n",
      "--- Epoch 19/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 19/1000 [04:18<3:42:00, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.2823e-01\n",
      "LR: 1.0000e-05\n",
      "Better trainLoss: 1.2823e-01, Saving models...\n",
      "--- Epoch 20/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 20/1000 [04:31<3:42:26, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.2785e-01\n",
      "LR: 1.0000e-05\n",
      "Better trainLoss: 1.2785e-01, Saving models...\n",
      "--- Epoch 21/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 21/1000 [04:45<3:42:24, 13.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.2889e-01\n",
      "LR: 1.0000e-05\n",
      "--- Epoch 22/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 22/1000 [04:59<3:42:29, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.2525e-01\n",
      "LR: 1.0000e-05\n",
      "Better trainLoss: 1.2525e-01, Saving models...\n",
      "--- Epoch 23/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 23/1000 [05:12<3:41:35, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.2537e-01\n",
      "LR: 1.0000e-05\n",
      "--- Epoch 24/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 24/1000 [05:26<3:40:55, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.2615e-01\n",
      "LR: 1.0000e-05\n",
      "--- Epoch 25/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 25/1000 [05:39<3:40:58, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.2214e-01\n",
      "LR: 1.0000e-05\n",
      "Better trainLoss: 1.2214e-01, Saving models...\n",
      "--- Epoch 26/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 26/1000 [05:53<3:41:05, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.2121e-01\n",
      "LR: 1.0000e-05\n",
      "Better trainLoss: 1.2121e-01, Saving models...\n",
      "--- Epoch 27/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 27/1000 [06:07<3:40:29, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.2324e-01\n",
      "LR: 1.0000e-05\n",
      "--- Epoch 28/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 28/1000 [06:20<3:40:34, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.2010e-01\n",
      "LR: 1.0000e-05\n",
      "Better trainLoss: 1.2010e-01, Saving models...\n",
      "--- Epoch 29/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 29/1000 [06:34<3:40:27, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1935e-01\n",
      "LR: 1.0000e-05\n",
      "Better trainLoss: 1.1935e-01, Saving models...\n",
      "--- Epoch 30/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 30/1000 [06:48<3:40:27, 13.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1895e-01\n",
      "LR: 1.0000e-05\n",
      "Better trainLoss: 1.1895e-01, Saving models...\n",
      "--- Epoch 31/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 31/1000 [07:01<3:39:46, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1992e-01\n",
      "LR: 1.0000e-05\n",
      "--- Epoch 32/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 32/1000 [07:15<3:39:07, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1975e-01\n",
      "LR: 1.0000e-05\n",
      "--- Epoch 33/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 33/1000 [07:28<3:39:23, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1614e-01\n",
      "LR: 1.0000e-05\n",
      "Better trainLoss: 1.1614e-01, Saving models...\n",
      "--- Epoch 34/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 34/1000 [07:42<3:40:16, 13.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1505e-01\n",
      "LR: 1.0000e-05\n",
      "Better trainLoss: 1.1505e-01, Saving models...\n",
      "--- Epoch 35/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 35/1000 [07:56<3:39:41, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1646e-01\n",
      "LR: 1.0000e-05\n",
      "--- Epoch 36/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 36/1000 [08:09<3:38:54, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1742e-01\n",
      "LR: 1.0000e-05\n",
      "--- Epoch 37/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 37/1000 [08:23<3:38:14, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1747e-01\n",
      "LR: 1.0000e-05\n",
      "--- Epoch 38/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 38/1000 [08:37<3:38:27, 13.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1264e-01\n",
      "LR: 1.0000e-06\n",
      "Better trainLoss: 1.1264e-01, Saving models...\n",
      "--- Epoch 39/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 39/1000 [08:50<3:38:29, 13.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1112e-01\n",
      "LR: 1.0000e-06\n",
      "Better trainLoss: 1.1112e-01, Saving models...\n",
      "--- Epoch 40/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 40/1000 [09:04<3:37:48, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1286e-01\n",
      "LR: 1.0000e-06\n",
      "--- Epoch 41/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 41/1000 [09:17<3:37:05, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1304e-01\n",
      "LR: 1.0000e-06\n",
      "--- Epoch 42/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 42/1000 [09:31<3:36:37, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1739e-01\n",
      "LR: 1.0000e-06\n",
      "--- Epoch 43/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 43/1000 [09:44<3:36:04, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1546e-01\n",
      "LR: 1.0000e-07\n",
      "--- Epoch 44/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 44/1000 [09:58<3:36:16, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0560e-01\n",
      "LR: 1.0000e-07\n",
      "Better trainLoss: 1.0560e-01, Saving models...\n",
      "--- Epoch 45/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 45/1000 [10:12<3:36:05, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0742e-01\n",
      "LR: 1.0000e-07\n",
      "--- Epoch 46/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 46/1000 [10:25<3:36:02, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0842e-01\n",
      "LR: 1.0000e-07\n",
      "--- Epoch 47/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 47/1000 [10:39<3:35:31, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1227e-01\n",
      "LR: 1.0000e-07\n",
      "--- Epoch 48/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 48/1000 [10:52<3:35:10, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1495e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 49/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 49/1000 [11:06<3:35:32, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0987e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 50/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 50/1000 [11:20<3:35:17, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1391e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 51/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 51/1000 [11:33<3:34:43, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0849e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 52/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 52/1000 [11:47<3:34:15, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0655e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 53/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 53/1000 [12:00<3:34:23, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0518e-01\n",
      "LR: 1.0000e-08\n",
      "Better trainLoss: 1.0518e-01, Saving models...\n",
      "--- Epoch 54/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 54/1000 [12:14<3:34:06, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1470e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 55/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 55/1000 [12:27<3:33:45, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0843e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 56/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 56/1000 [12:41<3:33:28, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0648e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 57/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 57/1000 [12:54<3:33:06, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0774e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 58/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 58/1000 [13:08<3:32:48, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1304e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 59/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 59/1000 [13:21<3:32:20, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0606e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 60/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 60/1000 [13:35<3:32:09, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0799e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 61/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 61/1000 [13:49<3:31:49, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0649e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 62/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 62/1000 [14:02<3:31:21, 13.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0958e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 63/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 63/1000 [14:16<3:31:16, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1143e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 64/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 64/1000 [14:29<3:31:02, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.2240e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 65/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 65/1000 [14:43<3:31:35, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0455e-01\n",
      "LR: 1.0000e-08\n",
      "Better trainLoss: 1.0455e-01, Saving models...\n",
      "--- Epoch 66/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 66/1000 [14:56<3:31:10, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1187e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 67/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 67/1000 [15:10<3:30:52, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1736e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 68/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 68/1000 [15:23<3:30:33, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0769e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 69/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 69/1000 [15:37<3:30:24, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0676e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 70/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 70/1000 [15:51<3:30:01, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1484e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 71/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 71/1000 [16:04<3:29:43, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0693e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 72/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 72/1000 [16:18<3:29:27, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0625e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 73/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 73/1000 [16:31<3:29:13, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1084e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 74/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 74/1000 [16:45<3:28:55, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0985e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 75/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 75/1000 [16:59<3:30:11, 13.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0894e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 76/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 76/1000 [17:12<3:29:35, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1577e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 77/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 77/1000 [17:26<3:29:02, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0686e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 78/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 78/1000 [17:39<3:28:28, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1093e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 79/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 79/1000 [17:53<3:28:05, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0714e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 80/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 80/1000 [18:06<3:27:39, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1065e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 81/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 81/1000 [18:20<3:27:21, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1577e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 82/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 82/1000 [18:33<3:27:09, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0693e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 83/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 83/1000 [18:47<3:26:48, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0563e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 84/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 84/1000 [19:00<3:26:28, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1657e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 85/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 85/1000 [19:14<3:26:17, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1302e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 86/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▊         | 86/1000 [19:27<3:26:03, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1198e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 87/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▊         | 87/1000 [19:41<3:25:50, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1197e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 88/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 88/1000 [19:54<3:25:35, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0777e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 89/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 89/1000 [20:08<3:25:24, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1139e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 90/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 90/1000 [20:21<3:25:08, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0851e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 91/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 91/1000 [20:35<3:24:58, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1160e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 92/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 92/1000 [20:49<3:24:46, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1299e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 93/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 93/1000 [21:02<3:24:25, 13.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1194e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 94/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 94/1000 [21:16<3:24:18, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1791e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 95/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 95/1000 [21:29<3:24:04, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0781e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 96/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 96/1000 [21:43<3:23:53, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1153e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 97/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 97/1000 [21:56<3:23:35, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0481e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 98/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 98/1000 [22:10<3:23:25, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0939e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 99/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|▉         | 99/1000 [22:23<3:23:09, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1621e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 100/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 100/1000 [22:37<3:22:50, 13.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0943e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 101/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 101/1000 [22:50<3:22:48, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1363e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 102/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 102/1000 [23:04<3:22:30, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1007e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 103/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 103/1000 [23:17<3:22:55, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1018e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 104/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 104/1000 [23:31<3:22:33, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1189e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 105/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 105/1000 [23:45<3:22:15, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1167e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 106/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 106/1000 [23:58<3:21:57, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0857e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 107/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 107/1000 [24:12<3:21:33, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0987e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 108/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 108/1000 [24:25<3:21:23, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1050e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 109/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 109/1000 [24:39<3:22:29, 13.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1201e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 110/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 110/1000 [24:53<3:22:18, 13.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1667e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 111/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 111/1000 [25:06<3:21:47, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0538e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 112/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 112/1000 [25:20<3:21:10, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0458e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 113/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 113/1000 [25:33<3:20:42, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1149e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 114/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█▏        | 114/1000 [25:47<3:20:21, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1037e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 115/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 115/1000 [26:00<3:19:59, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0935e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 116/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 116/1000 [26:14<3:19:37, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1392e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 117/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 117/1000 [26:27<3:19:22, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0785e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 118/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 118/1000 [26:41<3:19:06, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1535e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 119/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 119/1000 [26:55<3:18:49, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0964e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 120/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 120/1000 [27:08<3:19:02, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0964e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 121/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 121/1000 [27:22<3:19:41, 13.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1108e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 122/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 122/1000 [27:36<3:19:41, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1158e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 123/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 123/1000 [27:49<3:19:06, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1609e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 124/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 124/1000 [28:03<3:18:34, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0838e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 125/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 125/1000 [28:16<3:18:17, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0633e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 126/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 126/1000 [28:30<3:18:03, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1077e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 127/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 127/1000 [28:44<3:17:44, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0788e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 128/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 128/1000 [28:57<3:17:26, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0669e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 129/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 129/1000 [29:11<3:17:12, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0609e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 130/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 130/1000 [29:24<3:17:03, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0981e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 131/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 131/1000 [29:38<3:16:45, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1074e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 132/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 132/1000 [29:52<3:17:05, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 9.9201e-02\n",
      "LR: 1.0000e-08\n",
      "Better trainLoss: 9.9201e-02, Saving models...\n",
      "--- Epoch 133/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 133/1000 [30:05<3:16:37, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1440e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 134/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 134/1000 [30:19<3:16:18, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1169e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 135/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▎        | 135/1000 [30:32<3:15:58, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0809e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 136/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▎        | 136/1000 [30:46<3:16:36, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1376e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 137/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▎        | 137/1000 [31:00<3:15:52, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0874e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 138/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 138/1000 [31:13<3:15:26, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1162e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 139/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 139/1000 [31:27<3:14:58, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1169e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 140/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 140/1000 [31:40<3:14:45, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0864e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 141/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 141/1000 [31:54<3:14:29, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1013e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 142/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 142/1000 [32:07<3:14:14, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0900e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 143/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 143/1000 [32:21<3:13:49, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0433e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 144/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 144/1000 [32:35<3:13:41, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1481e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 145/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 145/1000 [32:48<3:13:20, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1806e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 146/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 146/1000 [33:02<3:13:01, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1352e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 147/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 147/1000 [33:15<3:12:46, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0595e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 148/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 148/1000 [33:29<3:12:25, 13.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1570e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 149/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 149/1000 [33:42<3:12:18, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0769e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 150/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 150/1000 [33:56<3:12:04, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1212e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 151/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 151/1000 [34:10<3:12:51, 13.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0840e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 152/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 152/1000 [34:23<3:12:30, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0961e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 153/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 153/1000 [34:37<3:12:05, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1439e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 154/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 154/1000 [34:50<3:11:40, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1293e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 155/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 155/1000 [35:04<3:11:19, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1247e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 156/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 156/1000 [35:18<3:11:00, 13.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1498e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 157/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 157/1000 [35:31<3:10:41, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1024e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 158/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 158/1000 [35:45<3:10:26, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0838e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 159/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 159/1000 [35:58<3:10:06, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0857e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 160/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 160/1000 [36:12<3:09:52, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1273e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 161/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 161/1000 [36:25<3:09:40, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1456e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 162/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 162/1000 [36:39<3:09:26, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.0871e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 163/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▋        | 163/1000 [36:53<3:09:05, 13.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 1.1386e-01\n",
      "LR: 1.0000e-08\n",
      "--- Epoch 164/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 163/1000 [37:01<3:10:08, 13.63s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5bdb8c04a60a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msurrogate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     trainLoss, tensorboard_recorder_step, total_steps = trainEpoch(trainDataLoader, \n\u001b[0m\u001b[1;32m     10\u001b[0m                                                                    \u001b[0mtrain_writer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurrogate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                                    \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-8a8b75cb9c27>\u001b[0m in \u001b[0;36mtrainEpoch\u001b[0;34m(myDataLoader, tensorboard_writer, model, opt, p_loss, loss, metric, lr_scheduler, tensorboard_rate, device, tensorboard_recorder_step, total_steps)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcombined_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mcombined_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writeMessage('---------- Started Training ----------', versionName)\n",
    "bestLoss = np.infty\n",
    "\n",
    "if not eval_only:\n",
    "    for epoch in tqdm(range(1, epochs+1)):  # loop over the dataset multiple times\n",
    "\n",
    "        writeMessage(\"--- Epoch {0}/{1} ---\".format(epoch, epochs), versionName)\n",
    "\n",
    "        surrogate.train()\n",
    "        trainLoss, tensorboard_recorder_step, total_steps = trainEpoch(trainDataLoader, \n",
    "                                                                       train_writer, surrogate,\n",
    "                                                                       opt, p_loss, loss,\n",
    "                                                                       rmse, lr_scheduler, \n",
    "                                                                       tensorboard_rate, device,\n",
    "                                                                       tensorboard_recorder_step, total_steps)\n",
    "\n",
    "        writeMessage(\"trainLoss: {:.4e}\".format(trainLoss),versionName)\n",
    "        writeMessage(\"LR: {:.4e}\".format(opt.param_groups[0]['lr']),versionName)\n",
    "        if trainLoss < bestLoss:\n",
    "            bestLoss = trainLoss\n",
    "            writeMessage(\"Better trainLoss: {:.4e}, Saving models...\".format(bestLoss),versionName)\n",
    "            torch.save(surrogate.state_dict(), os.path.join(cps,versionName))\n",
    "\n",
    "    #     model.eval()\n",
    "    #     valLoss = validEpoch(testDataLoader, test_writer, model, p_loss, loss, rmse, device, tensorboard_recorder_step)\n",
    "    #     writeMessage(\"valLoss: {:.4e}\".format(valLoss),versionName)\n",
    "\n",
    "        # checkpoint progress\n",
    "    #     if valLoss < bestLoss:\n",
    "    #         bestLoss = valLoss\n",
    "    #         writeMessage(\"Better valLoss: {:.4e}, Saving models...\".format(bestLoss),versionName)\n",
    "    #         torch.save(model.state_dict(), os.path.join(cps,versionName))\n",
    "\n",
    "        lr_scheduler.step(trainLoss)\n",
    "\n",
    "        if opt.param_groups[0]['lr'] < 1e-8:\n",
    "            break\n",
    "    writeMessage('---------- Finished Training ----------', versionName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T00:57:18.106563Z",
     "start_time": "2020-10-27T00:57:17.989327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surrogate.load_state_dict(torch.load(os.path.join(cps,versionName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T01:11:08.116485Z",
     "start_time": "2020-10-27T01:11:03.153307Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartoldson1/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    }
   ],
   "source": [
    "surrogate.eval()\n",
    "U_hats = []\n",
    "Us = []\n",
    "for i, sampleBatch in enumerate(testDataLoader, start=1):\n",
    "\n",
    "    # gpu\n",
    "    U_x, U_y, p_x, p_y = sampleBatch\n",
    "    U_x = U_x.squeeze().to(device)\n",
    "    p_x = p_x.squeeze().to(device)\n",
    "    U_y = U_y.to(device)\n",
    "    p_y = p_y.to(device)\n",
    "    with torch.no_grad():\n",
    "        Us.append(U_y.detach().cpu())\n",
    "        \n",
    "        U_hat = surrogate(U_x, p_y)\n",
    "                    \n",
    "        U_hats.append(U_hat.detach().cpu())\n",
    "        \n",
    "        \n",
    "Real_U = torch.stack(Us)\n",
    "#Real_X_img = convertSimToImage(Real_X)\n",
    "\n",
    "Surr_U = torch.stack(U_hats)\n",
    "#Surr_X_img = convertSimToImage(Surr_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T01:13:07.244977Z",
     "start_time": "2020-10-27T01:13:07.157878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5263)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_error = torch.norm(Real_U - Surr_U)/torch.norm(Real_U)\n",
    "rel_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
