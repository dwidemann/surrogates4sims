{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code trains an encoder/decoder for 1 channel of the pnnl datasets.\n",
    "\n",
    "Make sure the channel is set:\n",
    "\n",
    "channel = 1,2 = velocity_y, volume_frac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "# --- Must haves ---\n",
    "import os, sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from surrogates4sims.pnnlDatasets import CCSI_2D\n",
    "\n",
    "from surrogates4sims.utils import create_opt, create_one_cycle, find_lr, printNumModelParams, \\\n",
    "                                    rmse, writeMessage, plotSampleWprediction, plotSampleWpredictionByChannel, \\\n",
    "                                    plotSample, curl, jacobian, stream2uv, convertSimToImage, pkl_save, pkl_load, \\\n",
    "                                    create_1_channel_movie\n",
    "\n",
    "from surrogates4sims.models import Generator, Encoder, AE_no_P, AE_xhat_z, AE_xhat_zV2\n",
    "\n",
    "from surrogates4sims.train import trainEpoch, validEpoch\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pnnl_plateau_train_GPUs1_channel1_gridsize128_latentDim16_filters128_bz16_numConv4_jacobianFalse_epochs1000_stackTrue'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEBUG = False\n",
    "# model name, for tensorboard recording and checkpointing purposes.\n",
    "versionName = \"pnnl_plateau_train\"\n",
    "\n",
    "# GPU Numbers to use. Comma seprate them for multi-GPUs.\n",
    "gpu_ids = \"1\"\n",
    "versionName = versionName + '_GPUs{}'.format(gpu_ids.replace(',',''))\n",
    "# path to load model weights.\n",
    "pretrained_path = None\n",
    "\n",
    "# rate at which to record metrics. (number of batches to average over when recording metrics, e.g. \"every 5 batches\")\n",
    "tensorboard_rate = 5\n",
    "\n",
    "# number of epochs to train. This is defined here so we can use the OneCycle LR Scheduler.\n",
    "epochs = 1000\n",
    "\n",
    "# Data Directory\n",
    "channel = 1\n",
    "gridsize = 128\n",
    "dataDirec = '/data/ccsi/pnnl_liquid_inlet/channel_{}/gridsize_{}'.format(channel,gridsize)\n",
    "preprocess = False # keep this as false until using the long runtime loader\n",
    "testSplit = .2\n",
    "AE = True\n",
    "numWorkers = 2\n",
    "\n",
    "# checkpoint directory\n",
    "cps = 'cps'\n",
    "tensorboard_direc = \"tb\"\n",
    "\n",
    "findLRs = True  \n",
    "\n",
    "# hyper-params\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "bz = 16\n",
    "numSamplesToKeep = np.infty #if not debugging\n",
    "latentDim = 16\n",
    "filters = 128\n",
    "num_conv = 4 # breaks when less than 2\n",
    "simLen = 500\n",
    "stack = True\n",
    "doJacobian = False\n",
    "createStreamFcn = False\n",
    "repeat = 0\n",
    "skip_connection = False\n",
    "patience = 2\n",
    "if DEBUG:\n",
    "    epochs = 2\n",
    "    numSamplesToKeep = 2\n",
    "    \n",
    "versionName = versionName + '_channel{}_gridsize{}_latentDim{}_filters{}_bz{}_numConv{}_jacobian{}_epochs{}_stack{}'.format(channel,gridsize,latentDim,filters,bz,num_conv,doJacobian,epochs,stack)\n",
    "versionName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Personal GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 27 14:08:45 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 23%   20C    P8     8W / 250W |      1MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            On   | 00000000:03:00.0 Off |                  N/A |\n",
      "| 23%   21C    P8     8W / 250W |      1MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN Xp            On   | 00000000:81:00.0 Off |                  N/A |\n",
      "| 51%   83C    P2   253W / 250W |  11669MiB / 12196MiB |     84%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN Xp            On   | 00000000:82:00.0 Off |                  N/A |\n",
      "| 47%   77C    P2   226W / 250W |  10891MiB / 12196MiB |     80%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    2     19582      C   /home/bartoldson1/anaconda3/bin/python     11657MiB |\n",
      "|    3     19582      C   /home/bartoldson1/anaconda3/bin/python     10879MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "if device.type == 'cuda':\n",
    "    print(cuda.is_available())\n",
    "    print(cuda.device_count())\n",
    "    print(cuda.current_device())\n",
    "    print(cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 27 14:09:06 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 23%   20C    P8     8W / 250W |      1MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            On   | 00000000:03:00.0 Off |                  N/A |\n",
      "| 23%   28C    P2    59W / 250W |    511MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN Xp            On   | 00000000:81:00.0 Off |                  N/A |\n",
      "| 52%   83C    P2   257W / 250W |  11669MiB / 12196MiB |     99%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN Xp            On   | 00000000:82:00.0 Off |                  N/A |\n",
      "| 48%   78C    P2   242W / 250W |  10891MiB / 12196MiB |     99%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    1      5973      C   ...emann1/anaconda3/envs/torch2/bin/python   499MiB |\n",
      "|    2     19582      C   /home/bartoldson1/anaconda3/bin/python     11657MiB |\n",
      "|    3     19582      C   /home/bartoldson1/anaconda3/bin/python     10879MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(5, device=device.type)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets & Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 38)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = glob(os.path.join(dataDirec,'*.pkl'))\n",
    "removeMe = ['041.pkl', '040.pkl', '029.pkl']\n",
    "for r in removeMe:\n",
    "    sims.remove(os.path.join(dataDirec,r)) # fix later\n",
    "numSims = len(sims)\n",
    "perm = np.random.permutation(numSims)\n",
    "idx = int(testSplit*numSims)\n",
    "testInds = perm[:idx]\n",
    "trainInds = perm[idx:]\n",
    "testSimFiles = [sims[idx] for idx in testInds]\n",
    "trainSimFiles = [sims[idx] for idx in trainInds]\n",
    "len(testSimFiles), len(trainSimFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = CCSI_2D(testSimFiles,doPreprocess=preprocess,numToKeep=numSamplesToKeep,channel=channel,AE=AE)\n",
    "trainDataset = CCSI_2D(trainSimFiles,doPreprocess=preprocess,numToKeep=numSamplesToKeep,channel=channel,AE=AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1187, 282)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataLoader = DataLoader(dataset=trainDataset, batch_size=bz, shuffle=True, drop_last=True, num_workers=numWorkers)\n",
    "testDataLoader = DataLoader(dataset=testDataset, batch_size=bz, num_workers=numWorkers)\n",
    "len(trainDataLoader), len(testDataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the models need to take data to be built. It's kinda weird. I may look into fix this later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 128, 128])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,X = next(iter(trainDataLoader))\n",
    "X = X.to(device)\n",
    "X.shape\n",
    "#X[0].shape, X[1], X[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "model = AE_xhat_zV2(X, filters, latentDim, num_conv, repeat, \n",
    "                 skip_connection, stack, conv_k=3, last_k=3, \n",
    "                 act=nn.LeakyReLU(), return_z=True, stream=createStreamFcn, device=device)\n",
    "\n",
    "if len(gpu_ids.split(',')) > 1:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 layers require gradients (unfrozen) out of 154 layers\n",
      "8,761,361 parameters require gradients (unfrozen) out of 8,761,361 parameters\n"
     ]
    }
   ],
   "source": [
    "printNumModelParams(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 128, 128]), torch.Size([16, 16]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xhat,z = model(X)\n",
    "Xhat.shape, z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_loss(pred, target):\n",
    "    return torch.mean(torch.abs(pred - target))\n",
    "\n",
    "\n",
    "def jacobian_loss(pred, target, device='cpu'):\n",
    "    return L1_loss(jacobian(pred, device), jacobian(target, device))\n",
    "\n",
    "\n",
    "def curl_loss(pred, target, device):\n",
    "    return L1_loss(curl(pred, device), curl(target, device))\n",
    "\n",
    "\n",
    "L = nn.MSELoss()\n",
    "\n",
    "\n",
    "def p_loss(pred, target):\n",
    "    return L(pred[:, -target.shape[1]:], target)\n",
    "\n",
    "\n",
    "def loss(pred, target, device):\n",
    "    \n",
    "    if createStreamFcn:\n",
    "        pred = stream2uv(pred, device)\n",
    "        \n",
    "    L1 = L1_loss(pred, target)\n",
    "    Lj = 0\n",
    "    if doJacobian:\n",
    "        Lj = jacobian_loss(pred, target, device)\n",
    "        \n",
    "    return L1 + Lj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2, 128, 128])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = stream2uv(Xhat,device)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0970, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(pred,X,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24896066d49c457b86a2facba54c10f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if findLRs and (len(gpu_ids.split(','))==1): # doesn't work for multigpu???\n",
    "    model.return_z = False\n",
    "    opt = create_opt(1e-7,model)\n",
    "    find_lr(model,opt,L,device,trainDataLoader)\n",
    "    model.return_z = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = .0001\n",
    "start_lr = 5*max_lr/10\n",
    "#opt = create_opt(max_lr,model)\n",
    "#lr_scheduler = create_one_cycle(opt,max_lr,epochs,trainDataLoader)\n",
    "opt = torch.optim.Adam(model.parameters(),lr=max_lr,betas=(.5,.999))\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt,patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versionName = versionName + '_lr{}'.format(str(max_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpoch(myDataLoader, tensorboard_writer, model, opt, p_loss, loss,\n",
    "               metric, lr_scheduler, tensorboard_rate, device,\n",
    "               tensorboard_recorder_step, total_steps):\n",
    "    running_loss = 0.0\n",
    "    running_rmse = 0.0\n",
    "    total_loss = 0.0\n",
    "    running_ploss = 0.0\n",
    "    for i, sampleBatch in enumerate(myDataLoader, start=1):\n",
    "\n",
    "        # --- Main Training ---\n",
    "        \n",
    "        # gpu\n",
    "        #X,p = sampleBatch[0],sampleBatch[1]\n",
    "        X = sampleBatch[0]\n",
    "        X = X.to(device)\n",
    "        #p = p.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        opt.zero_grad()\n",
    "\n",
    "        X_hat, z = model(X)\n",
    "        #pl = p_loss(z,p)\n",
    "        ll = loss(X_hat,X,device)\n",
    "        combined_loss = ll #pl + ll\n",
    "        combined_loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        # loss\n",
    "        batch_loss = combined_loss.item()\n",
    "        running_loss += batch_loss\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        #batch_ploss = pl.item()\n",
    "        #running_ploss += batch_ploss\n",
    "\n",
    "        # --- Metrics Recording ---\n",
    "\n",
    "        # metrics\n",
    "        r = metric(X_hat, X)\n",
    "        running_rmse += r\n",
    "\n",
    "        # record lr change\n",
    "        total_steps += 1\n",
    "        tensorboard_writer.add_scalar(tag=\"LR\", scalar_value=opt.param_groups[0]['lr'], global_step=total_steps)\n",
    "        #lr_scheduler.step()\n",
    "\n",
    "        # tensorboard writes\n",
    "        if (i % tensorboard_rate == 0):\n",
    "            tensorboard_recorder_step += 1\n",
    "            avg_running_loss = running_loss/tensorboard_rate\n",
    "            avg_running_rmse = running_rmse/tensorboard_rate\n",
    "            #avg_running_ploss = running_ploss/tensorboard_rate\n",
    "            tensorboard_writer.add_scalar(tag=\"Loss\", scalar_value=avg_running_loss, global_step=tensorboard_recorder_step)\n",
    "            #tensorboard_writer.add_scalar(tag=\"p_loss\", scalar_value=avg_running_ploss, global_step=tensorboard_recorder_step)\n",
    "            tensorboard_writer.add_scalar(tag=metric.__name__, scalar_value=avg_running_rmse, global_step=tensorboard_recorder_step)\n",
    "            # reset running_loss for the next set of batches. (tensorboard_rate number of batches)\n",
    "            running_loss = 0.0\n",
    "            running_rmse = 0.0\n",
    "            #running_ploss = 0.0\n",
    "\n",
    "    return total_loss, tensorboard_recorder_step, total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "def validEpoch(myDataLoader, tensorboard_writer, model, p_loss, loss, metric,\n",
    "               device, tensorboard_recorder_step):\n",
    "    running_loss = 0.0\n",
    "    running_rmse = 0.0\n",
    "    for i, sampleBatch in enumerate(myDataLoader, start=1):\n",
    "\n",
    "        # --- Metrics Recording ---\n",
    "\n",
    "        # gpu\n",
    "        #X,p = sampleBatch[0],sampleBatch[1]\n",
    "        X = sampleBatch[0]\n",
    "        X = X.to(device)\n",
    "        #p = p.to(device)\n",
    "        \n",
    "        perc = len(X)/len(myDataLoader.dataset)\n",
    "\n",
    "        # forward, no gradient calculations\n",
    "        with torch.no_grad():\n",
    "            X_hat, z = model(X)\n",
    "\n",
    "        # loss\n",
    "        #combined_loss = p_loss(z,p) + loss(X_hat,X,device)\n",
    "        combined_loss = loss(X_hat,X,device)\n",
    "        \n",
    "        running_loss += perc*(combined_loss.item())\n",
    "\n",
    "        # metrics\n",
    "        r = metric(X_hat, X)\n",
    "        running_rmse += perc*r\n",
    "\n",
    "    avg_running_loss = running_loss\n",
    "    avg_running_rmse = running_rmse\n",
    "    tensorboard_writer.add_scalar(tag=\"Loss\", scalar_value=avg_running_loss, global_step=tensorboard_recorder_step)\n",
    "    tensorboard_writer.add_scalar(tag=metric.__name__, scalar_value=avg_running_rmse, global_step=tensorboard_recorder_step)\n",
    "\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints directory already exists :)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(cps)\n",
    "except:\n",
    "    print(\"checkpoints directory already exists :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a summary writer.\n",
    "train_writer = SummaryWriter(os.path.join(tensorboard_direc, versionName,'train'))\n",
    "test_writer = SummaryWriter(os.path.join(tensorboard_direc, versionName,'valid'))\n",
    "tensorboard_recorder_step = 0\n",
    "total_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Started Training ----------\n",
      "--- Epoch 1/1000 ---\n",
      "trainLoss: 7.8603e+01\n",
      "LR: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/1000 [05:00<83:30:25, 300.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.6055e-02\n",
      "Better valLoss: 6.6055e-02, Saving models...\n",
      "--- Epoch 2/1000 ---\n",
      "trainLoss: 7.0519e+01\n",
      "LR: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/1000 [10:05<83:42:36, 301.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.3062e-02\n",
      "Better valLoss: 6.3062e-02, Saving models...\n",
      "--- Epoch 3/1000 ---\n",
      "trainLoss: 6.8813e+01\n",
      "LR: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/1000 [15:09<83:49:49, 302.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.2635e-02\n",
      "Better valLoss: 6.2635e-02, Saving models...\n",
      "--- Epoch 4/1000 ---\n",
      "trainLoss: 6.7701e+01\n",
      "LR: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/1000 [20:13<83:51:18, 303.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.4453e-02\n",
      "--- Epoch 5/1000 ---\n",
      "trainLoss: 6.9335e+01\n",
      "LR: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/1000 [25:18<83:56:51, 303.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.2370e-02\n",
      "Better valLoss: 6.2370e-02, Saving models...\n",
      "--- Epoch 6/1000 ---\n",
      "trainLoss: 7.6626e+01\n",
      "LR: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 6/1000 [30:23<83:56:11, 304.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.2244e-02\n",
      "Better valLoss: 6.2244e-02, Saving models...\n",
      "--- Epoch 7/1000 ---\n",
      "trainLoss: 6.7112e+01\n",
      "LR: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 7/1000 [35:28<83:53:53, 304.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.2701e-02\n",
      "--- Epoch 8/1000 ---\n"
     ]
    }
   ],
   "source": [
    "writeMessage('---------- Started Training ----------', versionName)\n",
    "bestLoss = np.infty\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):  # loop over the dataset multiple times\n",
    "    \n",
    "    writeMessage(\"--- Epoch {0}/{1} ---\".format(epoch, epochs), versionName)\n",
    "    \n",
    "    model.train()\n",
    "    trainLoss, tensorboard_recorder_step, total_steps = trainEpoch(trainDataLoader, \n",
    "                                                                   train_writer, model, opt, p_loss, loss,\n",
    "                                                                   rmse, lr_scheduler, \n",
    "                                                                   tensorboard_rate, device,\n",
    "                                                                   tensorboard_recorder_step, total_steps)\n",
    "    \n",
    "    writeMessage(\"trainLoss: {:.4e}\".format(trainLoss),versionName)\n",
    "    writeMessage(\"LR: {:.4e}\".format(opt.param_groups[0]['lr']),versionName)\n",
    "#     if trainLoss < bestLoss:\n",
    "#         bestLoss = trainLoss\n",
    "#         writeMessage(\"Better trainLoss: {:.4e}, Saving models...\".format(bestLoss),versionName)\n",
    "#         torch.save(model.state_dict(), os.path.join(cps,versionName))\n",
    "        \n",
    "    model.eval()\n",
    "    valLoss = validEpoch(testDataLoader, test_writer, model, p_loss, loss, rmse, device, tensorboard_recorder_step)\n",
    "    writeMessage(\"valLoss: {:.4e}\".format(valLoss),versionName)\n",
    "    \n",
    "    # checkpoint progress\n",
    "    if valLoss < bestLoss:\n",
    "        bestLoss = valLoss\n",
    "        writeMessage(\"Better valLoss: {:.4e}, Saving models...\".format(bestLoss),versionName)\n",
    "        torch.save(model.state_dict(), os.path.join(cps,versionName))\n",
    "\n",
    "    lr_scheduler.step(trainLoss)\n",
    "    \n",
    "    if opt.param_groups[0]['lr'] < 5e-8:\n",
    "        break\n",
    "writeMessage('---------- Finished Training ----------', versionName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare: Generated vs. Simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(cps,versionName)))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "sampleBatch = next(iter(testDataLoader))\n",
    "X,p = sampleBatch\n",
    "X = X.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_hat, p = model(X)\n",
    "\n",
    "if createStreamFcn:\n",
    "    X_hat = stream2uv(X_hat,device)\n",
    "    \n",
    "X.shape, p.shape, X_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = []\n",
    "relErr = []\n",
    "frameRe = []\n",
    "print('RMSE \\t Rel Err')\n",
    "for idx in range(len(testSimFiles)):\n",
    "    # testDataset = CCSI_2D([testSimFiles[idx]],doPreprocess=preprocess,channel=channel,AE=False)\n",
    "    # simDataLoader = DataLoader(dataset=testDataset, batch_size=1)\n",
    "    # for X,Y in simDataLoader:\n",
    "    #     p = X[1]\n",
    "    #     t = X[2]\n",
    "    #     print(X[0].shape, p, t)\n",
    "\n",
    "    testDataset = CCSI_2D([testSimFiles[idx]],doPreprocess=preprocess,channel=channel,AE=AE)\n",
    "    simDataLoader = DataLoader(dataset=testDataset, batch_size=1)\n",
    "    XX = []\n",
    "    Real_X = []\n",
    "    model.eval()\n",
    "    for i, sampleBatch in enumerate(simDataLoader,start=1):\n",
    "        with torch.no_grad():\n",
    "            X,p = sampleBatch\n",
    "            X = X.to(device)\n",
    "            p = p.to(device)\n",
    "            Real_X.append(X)\n",
    "\n",
    "            X_hat,_ = model(X)\n",
    "\n",
    "            if createStreamFcn:\n",
    "                X_hat = stream2uv(X_hat,device)\n",
    "\n",
    "            XX.append(X_hat)\n",
    "\n",
    "            #X = X.detach().cpu().squeeze()\n",
    "            #X_hat = X_hat.detach().cpu().squeeze()\n",
    "            #plotSampleWprediction(X, X_hat)\n",
    "\n",
    "    Real_X = torch.cat(Real_X,axis=0).to('cpu')\n",
    "    Real_X_img = torch.rot90(convertSimToImage(Real_X),1,dims=[2,3])\n",
    "\n",
    "    Surr_X = torch.cat(XX,axis=0).to('cpu')\n",
    "    Surr_X_img = torch.rot90(convertSimToImage(Surr_X),1,dims=[2,3])\n",
    "    Real_X_img.shape, Surr_X_img.shape\n",
    "    \n",
    "    r = rmse(Real_X,Surr_X)\n",
    "    RMSE.append(r)\n",
    "    \n",
    "    rel_error = torch.norm(Real_X - Surr_X)/torch.norm(Real_X)\n",
    "    print('{}\\t{}'.format(r, rel_error))\n",
    "    relErr.append(rel_error)\n",
    "    \n",
    "    re = []\n",
    "    for x,y in zip(Real_X, Surr_X):\n",
    "        x = x.squeeze()\n",
    "        y = y.squeeze()\n",
    "        e = torch.norm(x - y)/torch.norm(x)\n",
    "        re.append(e)\n",
    "    frameRe.append(re)\n",
    "    #plt.plot(re)\n",
    "    \n",
    "np.mean(relErr)\n",
    "frameRe = np.vstack(frameRe)\n",
    "plt.plot(frameRe.T)\n",
    "plt.legend([i for i in range(len(testSimFiles))])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.animation as manimati\n",
    "from matplotlib import animation, rc\n",
    "def create_1_channel_movie(im,outfile='sim.mp4',title='surrogate            simulation'):\n",
    "    ti = 0\n",
    "    u_mx = 255 #np.max(np.abs(Xrgb))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.title(title)\n",
    "    cmap = plt.cm.ocean\n",
    "    img = ax.imshow(im[0].squeeze(), cmap=cmap, vmin=0, vmax=u_mx)\n",
    "    #plt.show()\n",
    "    \n",
    "    # initialization function: plot the background of each frame\n",
    "    def init():\n",
    "        img = ax.imshow(im[0].squeeze(), cmap=cmap, vmin=0, vmax=u_mx)\n",
    "        return (fig,)\n",
    "\n",
    "    # animation function. This is called sequentially\n",
    "    def animate(i):\n",
    "        img = ax.imshow(im[i].squeeze(), cmap=cmap, vmin=0, vmax=u_mx)\n",
    "        return (fig,)\n",
    "\n",
    "\n",
    "    # call the animator. blit=True means only re-draw the parts that have changed.\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                   frames=len(im), interval=20, blit=True)\n",
    "    anim.save(outfile, fps=30, extra_args=['-vcodec', 'libx264'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xrgb = torch.cat([Surr_X_img, Real_X_img], dim=3)\n",
    "Xrgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    gif = True\n",
    "    outGif = '{}.gif'.format(versionName)\n",
    "    create_1_channel_movie(Xrgb.detach().numpy(),outfile=outGif)\n",
    "except:\n",
    "    gif = False\n",
    "    outGif = '{}.mp4'.format(versionName)\n",
    "    create_1_channel_movie(Xrgb.detach().numpy(),outfile=outGif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, Video\n",
    "if gif:\n",
    "    Image(filename=outGif)\n",
    "else:\n",
    "    Video(filename=outGif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versionName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
