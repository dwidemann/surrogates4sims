{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Integration Network (LIN)\n",
    "This notebook gives an example of how to train a LIN on SVD vectors. Note: 05_experiment_SVD.ipynb created and saved the SVD Decomposition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:12.779046Z",
     "start_time": "2021-01-25T05:48:11.046067Z"
    }
   },
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "# --- Must haves ---\n",
    "import os, sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from surrogates4sims.pnnlDatasets import CCSI_2D\n",
    "\n",
    "from surrogates4sims.utils import create_opt, create_one_cycle, find_lr, printNumModelParams, \\\n",
    "                                    rmse, writeMessage, plotSampleWprediction, plotSampleWpredictionByChannel, \\\n",
    "                                    plotSample, curl, jacobian, stream2uv, convertSimToImage, pkl_save, pkl_load, \\\n",
    "                                    create_1_channel_movie\n",
    "\n",
    "from surrogates4sims.models import Generator, Encoder, ConvDeconvFactor2\n",
    "\n",
    "from surrogates4sims.train import trainEpoch, validEpoch\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:12.906110Z",
     "start_time": "2021-01-25T05:48:12.780729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gridsize_128  gridsize_512  svd_channel1_gridsize128.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls /work/pnnl_liquid_inlet/channel_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:12.925043Z",
     "start_time": "2021-01-25T05:48:12.909009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LIN_SVD_PNNL_MLP_GPUs3_w499_latentDim64_hd128_128_bz1_epochs1000_memory1_WD0_reconLossFalse'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEBUG = False\n",
    "# model name, for tensorboard recording and checkpointing purposes.\n",
    "versionName = \"LIN_SVD_PNNL_MLP\"\n",
    "\n",
    "# GPU Numbers to use. Comma seprate them for multi-GPUs.\n",
    "gpu_ids = \"3\"#,1,2,3\"\n",
    "versionName = versionName + '_GPUs{}'.format(gpu_ids.replace(',',''))\n",
    "# path to load model weights.\n",
    "pretrained_path = None\n",
    "\n",
    "# rate at which to record metrics. (number of batches to average over when recording metrics, e.g. \"every 5 batches\")\n",
    "tensorboard_rate = 5\n",
    "\n",
    "# number of epochs to train. This is defined here so we can use the OneCycle LR Scheduler.\n",
    "epochs = 1000\n",
    "\n",
    "# Data Directory\n",
    "channel = 2\n",
    "gridsize = 128\n",
    "dataDirec = '/work/pnnl_liquid_inlet/channel_{}/gridsize_{}'.format(channel,gridsize)\n",
    "build_vecs = True \n",
    "SVDFn = '/work/pnnl_liquid_inlet/channel_2/svd_channel2_gridsize128.pkl'\n",
    "preprocess = False\n",
    "AE = True\n",
    "\n",
    "# checkpoint directory\n",
    "cps = 'cps'\n",
    "tensorboard_direc = \"tb\"\n",
    "\n",
    "findLRs = True  \n",
    "patience = 1\n",
    "\n",
    "# hyper-params\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "testSplit = .2\n",
    "bz = 1\n",
    "numSamplesToKeep = np.infty #if not debugging\n",
    "latentDim = 64\n",
    "simLen = 500\n",
    "\n",
    "w = 499\n",
    "memory_length = 1\n",
    "weight_decay = 0\n",
    "hiddenLayers =  [128, 128]\n",
    "hd ='_'.join(map(str,hiddenLayers))\n",
    "activation = nn.ELU()\n",
    "reconLoss = False\n",
    "\n",
    "if DEBUG:\n",
    "    epochs = 2\n",
    "    numSamplesToKeep = 200\n",
    "    createDebugData = True\n",
    "    \n",
    "\n",
    "versionName = versionName + '_w{}_latentDim{}_hd{}_bz{}_epochs{}_memory{}_WD{}_reconLoss{}'.format(w,latentDim,hd,bz,epochs,\n",
    "                                                             memory_length,weight_decay,reconLoss)\n",
    "versionName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Personal GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:13.117531Z",
     "start_time": "2021-01-25T05:48:12.926905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 24 21:48:12 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 23%   17C    P8     8W / 250W |     12MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            On   | 00000000:03:00.0 Off |                  N/A |\n",
      "| 23%   17C    P8     8W / 250W |     12MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN Xp            On   | 00000000:81:00.0 Off |                  N/A |\n",
      "| 23%   19C    P8     8W / 250W |   8759MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN Xp            On   | 00000000:82:00.0 Off |                  N/A |\n",
      "| 23%   37C    P2    61W / 250W |   1267MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    2      5231      C   /home/bartoldson1/anaconda3/bin/python      6775MiB |\n",
      "|    2     11605      C   /home/bartoldson1/anaconda3/bin/python       685MiB |\n",
      "|    2     26541      C   /home/bartoldson1/anaconda3/bin/python      1287MiB |\n",
      "|    3      5231      C   /home/bartoldson1/anaconda3/bin/python      1255MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:13.123712Z",
     "start_time": "2021-01-25T05:48:13.119820Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:13.154812Z",
     "start_time": "2021-01-25T05:48:13.126648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:13.167584Z",
     "start_time": "2021-01-25T05:48:13.159554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "if device.type == 'cuda':\n",
    "    print(cuda.is_available())\n",
    "    print(cuda.device_count())\n",
    "    print(cuda.current_device())\n",
    "    print(cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:15.283769Z",
     "start_time": "2021-01-25T05:48:13.170343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 24 21:48:15 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 23%   18C    P8    11W / 250W |     12MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            On   | 00000000:03:00.0 Off |                  N/A |\n",
      "| 23%   17C    P8     9W / 250W |     12MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN Xp            On   | 00000000:81:00.0 Off |                  N/A |\n",
      "| 23%   19C    P8     9W / 250W |   8759MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN Xp            On   | 00000000:82:00.0 Off |                  N/A |\n",
      "| 23%   36C    P2    61W / 250W |   1828MiB / 12196MiB |      2%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    2      5231      C   /home/bartoldson1/anaconda3/bin/python      6775MiB |\n",
      "|    2     11605      C   /home/bartoldson1/anaconda3/bin/python       685MiB |\n",
      "|    2     26541      C   /home/bartoldson1/anaconda3/bin/python      1287MiB |\n",
      "|    3      5231      C   /home/bartoldson1/anaconda3/bin/python      1255MiB |\n",
      "|    3     28080      C   /home/bartoldson1/anaconda3/bin/python       561MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(5, device=device.type)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Latent Vectors (Warning....)\n",
    "The computation of building the latent vectors takes a loooong time. \n",
    "This codes checks to see if svd_vec_file has been saved. If it has, \n",
    "it will reload them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:15.305806Z",
     "start_time": "2021-01-25T05:48:15.287115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = glob(os.path.join(dataDirec,'*.pkl'))\n",
    "sims = sorted(sims)\n",
    "numSims = len(sims)\n",
    "idx = int(testSplit*numSims)\n",
    "testInds = np.linspace(1,numSims-2,idx).astype('int')\n",
    "trainInds = list(set(np.arange(0,numSims)).difference(set(testInds)))\n",
    "# perm = np.random.permutation(numSims)\n",
    "# testInds = perm[:idx]\n",
    "# trainInds = perm[idx:]\n",
    "testSimFiles = [sims[idx] for idx in testInds]\n",
    "trainSimFiles = [sims[idx] for idx in trainInds]\n",
    "len(testSimFiles), len(trainSimFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:15.312362Z",
     "start_time": "2021-01-25T05:48:15.309054Z"
    }
   },
   "outputs": [],
   "source": [
    "trainSimFiles=[trainSimFiles[0]]\n",
    "testSimFiles=trainSimFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:15.337213Z",
     "start_time": "2021-01-25T05:48:15.314720Z"
    }
   },
   "outputs": [],
   "source": [
    "class CCSI_2D_one_of_each_getitem(Dataset):\n",
    "    def __init__(self, \n",
    "                 dataFiles,\n",
    "                 txtFile = '/data/ccsi/pnnl_liquid_inlet/liquid_inlet_velocity.txt',\n",
    "                 channel=1,\n",
    "                 gridSize=128,\n",
    "                 simLen = 500,\n",
    "                 w = 10, # this is the length of the Y output to predict\n",
    "                 AE = False, # this only return x,x, i.e. no y.\n",
    "                 numToKeep=np.infty,doPreprocess=False): \n",
    "        \n",
    "        self.dataFiles = dataFiles\n",
    "        if numToKeep < len(self.dataFiles):\n",
    "            self.dataFiles = self.dataFiles[:numToKeep]\n",
    "\n",
    "        self.channel = channel\n",
    "        self.gridSize = gridSize\n",
    "        self.numToKeep = numToKeep\n",
    "        self.simLen = simLen\n",
    "        self.t = np.linspace(0,1,simLen).astype('float32')\n",
    "        self.w = w\n",
    "        self.AE = AE\n",
    "        self.doPreprocess = doPreprocess\n",
    "        \n",
    "        # Get the inlet velocity\n",
    "        with open(txtFile) as fid:\n",
    "            txt = fid.read().splitlines()\n",
    "        inletVelocity = np.array(list(map(float,txt[1:]))).astype('float32')\n",
    "        self.inletMx = np.max(inletVelocity)\n",
    "        self.inletMn = np.min(inletVelocity)\n",
    "        \n",
    "        data = []\n",
    "        for fn in self.dataFiles:\n",
    "            idx = int(fn.split('/')[-1].replace('.pkl','')) - 1\n",
    "            D = pkl_load(fn)\n",
    "            data.append((D,inletVelocity[idx]))\n",
    "               \n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.simLen*self.data)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        q,r = np.divmod(idx,self.simLen)\n",
    "        r_idx = r\n",
    "            \n",
    "        X,p = self.data[q]\n",
    "        x = X[r_idx:r_idx+1]\n",
    "        #print(x.shape)\n",
    "        y = X[r_idx+1:r_idx+self.w+1]\n",
    "        #print(y.shape)\n",
    "        if self.doPreprocess:\n",
    "            x = self.preprocessFcn(x)\n",
    "            y = self.preprocessFcn(y)\n",
    "        \n",
    "        y = np.expand_dims(y,1)\n",
    "        p_x = np.hstack([p,self.t[r_idx]])\n",
    "        p_y = np.vstack([p*np.ones((self.w,)),self.t[r_idx+1:r_idx+self.w+1]]).T\n",
    "        X = x.astype('float32')\n",
    "        Y = y.astype('float32')\n",
    "        if self.AE:\n",
    "            return X,X # this allows LR_finder to work\n",
    "        else:\n",
    "            return X, Y, p_x, p_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:15.395385Z",
     "start_time": "2021-01-25T05:48:15.339369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataset = CCSI_2D_one_of_each_getitem(testSimFiles,doPreprocess=preprocess,\n",
    "                                          numToKeep=numSamplesToKeep,channel=channel,w=0,AE=False)\n",
    "trainDataset = CCSI_2D_one_of_each_getitem(trainSimFiles,doPreprocess=preprocess,\n",
    "                                           numToKeep=numSamplesToKeep,channel=channel,w=0,AE=False)\n",
    "len(trainDataset),len(testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:15.402040Z",
     "start_time": "2021-01-25T05:48:15.397183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.002]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is this inlet velocity supposed to be monotonic?\n",
    "[i for x,i in trainDataset.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:16.198990Z",
     "start_time": "2021-01-25T05:48:15.404773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['spatialVecs', 'S', 'timeVecs_transpose'])\n",
      "(16384, 64)\n"
     ]
    }
   ],
   "source": [
    "svd_data = pkl_load(SVDFn)\n",
    "print(svd_data.keys())\n",
    "\n",
    "svd_vecs = svd_data['spatialVecs'][:,:latentDim]\n",
    "print(svd_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:16.218519Z",
     "start_time": "2021-01-25T05:48:16.201089Z"
    }
   },
   "outputs": [],
   "source": [
    "class SVD_Encoder(nn.Module):\n",
    "    def __init__(self, U):\n",
    "        super(SVD_Encoder,self).__init__()\n",
    "        self.U = U\n",
    "\n",
    "    def forward(self, frames):\n",
    "        # u is from u,s,vh = svd(data)\n",
    "        # frames = batch_size x channels x height x width\n",
    "        assert len(frames.shape)==4\n",
    "        x = frames.reshape(len(frames), -1)\n",
    "        coeffs = x.matmul(self.U)\n",
    "        # coeffs is now batch_size x numComp\n",
    "        return coeffs    \n",
    "    \n",
    "class SVD_Decoder(nn.Module):\n",
    "    def __init__(self, U):\n",
    "        super(SVD_Decoder,self).__init__()\n",
    "        self.U = U\n",
    "\n",
    "    def forward(self, coeffs, orig_shape):\n",
    "        # coeffs is now batch_size x numComp\n",
    "        R = self.U.matmul(coeffs.T)\n",
    "        R = R.T.reshape(orig_shape)\n",
    "        return R\n",
    "    \n",
    "class SVD_Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self, svd_vectors, latentDim, allow_updates_to_U):\n",
    "        super(SVD_Autoencoder,self).__init__()\n",
    "        self.U = nn.Parameter(torch.tensor(svd_vectors[:,:latentDim]), requires_grad = allow_updates_to_U)\n",
    "        self.encoder=SVD_Encoder(self.U)\n",
    "        self.decoder=SVD_Decoder(self.U)\n",
    "        \n",
    "    def forward(self, frames):\n",
    "        return self.decoder(self.encoder(frames))\n",
    "\n",
    "SVD_autoencoder = SVD_Autoencoder(svd_vecs, latentDim, False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.447108Z",
     "start_time": "2021-01-25T05:48:16.220381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 1, 128, 128]) torch.Size([500, 0, 1, 128, 128]) torch.Size([500, 2]) torch.Size([500, 0, 2])\n",
      "num_sims 1\n",
      "torch.Size([500, 1, 128, 128]) torch.Size([500, 0, 1, 128, 128]) torch.Size([500, 2]) torch.Size([500, 0, 2])\n",
      "num_sims 1\n"
     ]
    }
   ],
   "source": [
    "def createSVDdataset(Dataset, latentDim):\n",
    "\n",
    "    # datasets may be smaller because: numSamplesToKeep \n",
    "    # Be careful the default is for the data to be preprocessed. Therefore, we have to invPrecprocess if \n",
    "    # we are looking at relative errors. \n",
    "    loader = DataLoader(dataset=Dataset, batch_size=simLen, shuffle=False, num_workers=4)\n",
    "    X, Y, p_x, p_y = next(iter(loader))\n",
    "    print(X.shape, Y.shape, p_x.shape, p_y.shape)\n",
    "    z = []\n",
    "    p = []\n",
    "    x = []\n",
    "    for batch in loader:\n",
    "        X, Y, p_x, p_y = batch\n",
    "        x.append(X)\n",
    "        z.append(SVD_autoencoder.encoder(X.to(device)).cpu())\n",
    "        p.append(p_x.cpu())\n",
    "        \n",
    "    z = torch.stack(z).reshape(-1, latentDim)\n",
    "    p = torch.stack(p).reshape(-1, p_x.size(1))\n",
    "    \n",
    "\n",
    "    v = np.arange(0, len(z), simLen)\n",
    "\n",
    "    sims = []\n",
    "    for idx in v:\n",
    "        sims.append((z[idx:idx+simLen],p[idx:idx+simLen]))\n",
    "    print('num_sims {}'.format(len(sims)))\n",
    "    return sims\n",
    "\n",
    "train_data = createSVDdataset(trainDataset, latentDim)\n",
    "test_data = createSVDdataset(testDataset, latentDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.456637Z",
     "start_time": "2021-01-25T05:48:18.449834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([500, 64]), torch.Size([500, 2]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].shape, train_data[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.464997Z",
     "start_time": "2021-01-25T05:48:18.459263Z"
    }
   },
   "outputs": [],
   "source": [
    "# reduce the dimensions of z down to the latentDim \n",
    "for idx,d in enumerate(train_data):\n",
    "    X = d[0][:,:latentDim]\n",
    "    p = d[1]\n",
    "    train_data[idx] = (X,p)\n",
    "    \n",
    "for idx,d in enumerate(test_data):\n",
    "    X = d[0][:,:latentDim]\n",
    "    p = d[1]\n",
    "    test_data[idx] = (X,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.499541Z",
     "start_time": "2021-01-25T05:48:18.467694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0020, 0.0000],\n",
      "        [0.0020, 0.0020],\n",
      "        [0.0020, 0.0040],\n",
      "        [0.0020, 0.0060],\n",
      "        [0.0020, 0.0080],\n",
      "        [0.0020, 0.0100],\n",
      "        [0.0020, 0.0120],\n",
      "        [0.0020, 0.0140],\n",
      "        [0.0020, 0.0160],\n",
      "        [0.0020, 0.0180],\n",
      "        [0.0020, 0.0200],\n",
      "        [0.0020, 0.0220],\n",
      "        [0.0020, 0.0240],\n",
      "        [0.0020, 0.0261],\n",
      "        [0.0020, 0.0281],\n",
      "        [0.0020, 0.0301],\n",
      "        [0.0020, 0.0321],\n",
      "        [0.0020, 0.0341],\n",
      "        [0.0020, 0.0361],\n",
      "        [0.0020, 0.0381],\n",
      "        [0.0020, 0.0401],\n",
      "        [0.0020, 0.0421],\n",
      "        [0.0020, 0.0441],\n",
      "        [0.0020, 0.0461],\n",
      "        [0.0020, 0.0481],\n",
      "        [0.0020, 0.0501],\n",
      "        [0.0020, 0.0521],\n",
      "        [0.0020, 0.0541],\n",
      "        [0.0020, 0.0561],\n",
      "        [0.0020, 0.0581],\n",
      "        [0.0020, 0.0601],\n",
      "        [0.0020, 0.0621],\n",
      "        [0.0020, 0.0641],\n",
      "        [0.0020, 0.0661],\n",
      "        [0.0020, 0.0681],\n",
      "        [0.0020, 0.0701],\n",
      "        [0.0020, 0.0721],\n",
      "        [0.0020, 0.0741],\n",
      "        [0.0020, 0.0762],\n",
      "        [0.0020, 0.0782],\n",
      "        [0.0020, 0.0802],\n",
      "        [0.0020, 0.0822],\n",
      "        [0.0020, 0.0842],\n",
      "        [0.0020, 0.0862],\n",
      "        [0.0020, 0.0882],\n",
      "        [0.0020, 0.0902],\n",
      "        [0.0020, 0.0922],\n",
      "        [0.0020, 0.0942],\n",
      "        [0.0020, 0.0962],\n",
      "        [0.0020, 0.0982],\n",
      "        [0.0020, 0.1002],\n",
      "        [0.0020, 0.1022],\n",
      "        [0.0020, 0.1042],\n",
      "        [0.0020, 0.1062],\n",
      "        [0.0020, 0.1082],\n",
      "        [0.0020, 0.1102],\n",
      "        [0.0020, 0.1122],\n",
      "        [0.0020, 0.1142],\n",
      "        [0.0020, 0.1162],\n",
      "        [0.0020, 0.1182],\n",
      "        [0.0020, 0.1202],\n",
      "        [0.0020, 0.1222],\n",
      "        [0.0020, 0.1242],\n",
      "        [0.0020, 0.1263],\n",
      "        [0.0020, 0.1283],\n",
      "        [0.0020, 0.1303],\n",
      "        [0.0020, 0.1323],\n",
      "        [0.0020, 0.1343],\n",
      "        [0.0020, 0.1363],\n",
      "        [0.0020, 0.1383],\n",
      "        [0.0020, 0.1403],\n",
      "        [0.0020, 0.1423],\n",
      "        [0.0020, 0.1443],\n",
      "        [0.0020, 0.1463],\n",
      "        [0.0020, 0.1483],\n",
      "        [0.0020, 0.1503],\n",
      "        [0.0020, 0.1523],\n",
      "        [0.0020, 0.1543],\n",
      "        [0.0020, 0.1563],\n",
      "        [0.0020, 0.1583],\n",
      "        [0.0020, 0.1603],\n",
      "        [0.0020, 0.1623],\n",
      "        [0.0020, 0.1643],\n",
      "        [0.0020, 0.1663],\n",
      "        [0.0020, 0.1683],\n",
      "        [0.0020, 0.1703],\n",
      "        [0.0020, 0.1723],\n",
      "        [0.0020, 0.1743],\n",
      "        [0.0020, 0.1764],\n",
      "        [0.0020, 0.1784],\n",
      "        [0.0020, 0.1804],\n",
      "        [0.0020, 0.1824],\n",
      "        [0.0020, 0.1844],\n",
      "        [0.0020, 0.1864],\n",
      "        [0.0020, 0.1884],\n",
      "        [0.0020, 0.1904],\n",
      "        [0.0020, 0.1924],\n",
      "        [0.0020, 0.1944],\n",
      "        [0.0020, 0.1964],\n",
      "        [0.0020, 0.1984],\n",
      "        [0.0020, 0.2004],\n",
      "        [0.0020, 0.2024],\n",
      "        [0.0020, 0.2044],\n",
      "        [0.0020, 0.2064],\n",
      "        [0.0020, 0.2084],\n",
      "        [0.0020, 0.2104],\n",
      "        [0.0020, 0.2124],\n",
      "        [0.0020, 0.2144],\n",
      "        [0.0020, 0.2164],\n",
      "        [0.0020, 0.2184],\n",
      "        [0.0020, 0.2204],\n",
      "        [0.0020, 0.2224],\n",
      "        [0.0020, 0.2244],\n",
      "        [0.0020, 0.2265],\n",
      "        [0.0020, 0.2285],\n",
      "        [0.0020, 0.2305],\n",
      "        [0.0020, 0.2325],\n",
      "        [0.0020, 0.2345],\n",
      "        [0.0020, 0.2365],\n",
      "        [0.0020, 0.2385],\n",
      "        [0.0020, 0.2405],\n",
      "        [0.0020, 0.2425],\n",
      "        [0.0020, 0.2445],\n",
      "        [0.0020, 0.2465],\n",
      "        [0.0020, 0.2485],\n",
      "        [0.0020, 0.2505],\n",
      "        [0.0020, 0.2525],\n",
      "        [0.0020, 0.2545],\n",
      "        [0.0020, 0.2565],\n",
      "        [0.0020, 0.2585],\n",
      "        [0.0020, 0.2605],\n",
      "        [0.0020, 0.2625],\n",
      "        [0.0020, 0.2645],\n",
      "        [0.0020, 0.2665],\n",
      "        [0.0020, 0.2685],\n",
      "        [0.0020, 0.2705],\n",
      "        [0.0020, 0.2725],\n",
      "        [0.0020, 0.2745],\n",
      "        [0.0020, 0.2766],\n",
      "        [0.0020, 0.2786],\n",
      "        [0.0020, 0.2806],\n",
      "        [0.0020, 0.2826],\n",
      "        [0.0020, 0.2846],\n",
      "        [0.0020, 0.2866],\n",
      "        [0.0020, 0.2886],\n",
      "        [0.0020, 0.2906],\n",
      "        [0.0020, 0.2926],\n",
      "        [0.0020, 0.2946],\n",
      "        [0.0020, 0.2966],\n",
      "        [0.0020, 0.2986],\n",
      "        [0.0020, 0.3006],\n",
      "        [0.0020, 0.3026],\n",
      "        [0.0020, 0.3046],\n",
      "        [0.0020, 0.3066],\n",
      "        [0.0020, 0.3086],\n",
      "        [0.0020, 0.3106],\n",
      "        [0.0020, 0.3126],\n",
      "        [0.0020, 0.3146],\n",
      "        [0.0020, 0.3166],\n",
      "        [0.0020, 0.3186],\n",
      "        [0.0020, 0.3206],\n",
      "        [0.0020, 0.3226],\n",
      "        [0.0020, 0.3246],\n",
      "        [0.0020, 0.3267],\n",
      "        [0.0020, 0.3287],\n",
      "        [0.0020, 0.3307],\n",
      "        [0.0020, 0.3327],\n",
      "        [0.0020, 0.3347],\n",
      "        [0.0020, 0.3367],\n",
      "        [0.0020, 0.3387],\n",
      "        [0.0020, 0.3407],\n",
      "        [0.0020, 0.3427],\n",
      "        [0.0020, 0.3447],\n",
      "        [0.0020, 0.3467],\n",
      "        [0.0020, 0.3487],\n",
      "        [0.0020, 0.3507],\n",
      "        [0.0020, 0.3527],\n",
      "        [0.0020, 0.3547],\n",
      "        [0.0020, 0.3567],\n",
      "        [0.0020, 0.3587],\n",
      "        [0.0020, 0.3607],\n",
      "        [0.0020, 0.3627],\n",
      "        [0.0020, 0.3647],\n",
      "        [0.0020, 0.3667],\n",
      "        [0.0020, 0.3687],\n",
      "        [0.0020, 0.3707],\n",
      "        [0.0020, 0.3727],\n",
      "        [0.0020, 0.3747],\n",
      "        [0.0020, 0.3768],\n",
      "        [0.0020, 0.3788],\n",
      "        [0.0020, 0.3808],\n",
      "        [0.0020, 0.3828],\n",
      "        [0.0020, 0.3848],\n",
      "        [0.0020, 0.3868],\n",
      "        [0.0020, 0.3888],\n",
      "        [0.0020, 0.3908],\n",
      "        [0.0020, 0.3928],\n",
      "        [0.0020, 0.3948],\n",
      "        [0.0020, 0.3968],\n",
      "        [0.0020, 0.3988],\n",
      "        [0.0020, 0.4008],\n",
      "        [0.0020, 0.4028],\n",
      "        [0.0020, 0.4048],\n",
      "        [0.0020, 0.4068],\n",
      "        [0.0020, 0.4088],\n",
      "        [0.0020, 0.4108],\n",
      "        [0.0020, 0.4128],\n",
      "        [0.0020, 0.4148],\n",
      "        [0.0020, 0.4168],\n",
      "        [0.0020, 0.4188],\n",
      "        [0.0020, 0.4208],\n",
      "        [0.0020, 0.4228],\n",
      "        [0.0020, 0.4248],\n",
      "        [0.0020, 0.4269],\n",
      "        [0.0020, 0.4289],\n",
      "        [0.0020, 0.4309],\n",
      "        [0.0020, 0.4329],\n",
      "        [0.0020, 0.4349],\n",
      "        [0.0020, 0.4369],\n",
      "        [0.0020, 0.4389],\n",
      "        [0.0020, 0.4409],\n",
      "        [0.0020, 0.4429],\n",
      "        [0.0020, 0.4449],\n",
      "        [0.0020, 0.4469],\n",
      "        [0.0020, 0.4489],\n",
      "        [0.0020, 0.4509],\n",
      "        [0.0020, 0.4529],\n",
      "        [0.0020, 0.4549],\n",
      "        [0.0020, 0.4569],\n",
      "        [0.0020, 0.4589],\n",
      "        [0.0020, 0.4609],\n",
      "        [0.0020, 0.4629],\n",
      "        [0.0020, 0.4649],\n",
      "        [0.0020, 0.4669],\n",
      "        [0.0020, 0.4689],\n",
      "        [0.0020, 0.4709],\n",
      "        [0.0020, 0.4729],\n",
      "        [0.0020, 0.4749],\n",
      "        [0.0020, 0.4770],\n",
      "        [0.0020, 0.4790],\n",
      "        [0.0020, 0.4810],\n",
      "        [0.0020, 0.4830],\n",
      "        [0.0020, 0.4850],\n",
      "        [0.0020, 0.4870],\n",
      "        [0.0020, 0.4890],\n",
      "        [0.0020, 0.4910],\n",
      "        [0.0020, 0.4930],\n",
      "        [0.0020, 0.4950],\n",
      "        [0.0020, 0.4970],\n",
      "        [0.0020, 0.4990],\n",
      "        [0.0020, 0.5010],\n",
      "        [0.0020, 0.5030],\n",
      "        [0.0020, 0.5050],\n",
      "        [0.0020, 0.5070],\n",
      "        [0.0020, 0.5090],\n",
      "        [0.0020, 0.5110],\n",
      "        [0.0020, 0.5130],\n",
      "        [0.0020, 0.5150],\n",
      "        [0.0020, 0.5170],\n",
      "        [0.0020, 0.5190],\n",
      "        [0.0020, 0.5210],\n",
      "        [0.0020, 0.5230],\n",
      "        [0.0020, 0.5251],\n",
      "        [0.0020, 0.5271],\n",
      "        [0.0020, 0.5291],\n",
      "        [0.0020, 0.5311],\n",
      "        [0.0020, 0.5331],\n",
      "        [0.0020, 0.5351],\n",
      "        [0.0020, 0.5371],\n",
      "        [0.0020, 0.5391],\n",
      "        [0.0020, 0.5411],\n",
      "        [0.0020, 0.5431],\n",
      "        [0.0020, 0.5451],\n",
      "        [0.0020, 0.5471],\n",
      "        [0.0020, 0.5491],\n",
      "        [0.0020, 0.5511],\n",
      "        [0.0020, 0.5531],\n",
      "        [0.0020, 0.5551],\n",
      "        [0.0020, 0.5571],\n",
      "        [0.0020, 0.5591],\n",
      "        [0.0020, 0.5611],\n",
      "        [0.0020, 0.5631],\n",
      "        [0.0020, 0.5651],\n",
      "        [0.0020, 0.5671],\n",
      "        [0.0020, 0.5691],\n",
      "        [0.0020, 0.5711],\n",
      "        [0.0020, 0.5731],\n",
      "        [0.0020, 0.5752],\n",
      "        [0.0020, 0.5772],\n",
      "        [0.0020, 0.5792],\n",
      "        [0.0020, 0.5812],\n",
      "        [0.0020, 0.5832],\n",
      "        [0.0020, 0.5852],\n",
      "        [0.0020, 0.5872],\n",
      "        [0.0020, 0.5892],\n",
      "        [0.0020, 0.5912],\n",
      "        [0.0020, 0.5932],\n",
      "        [0.0020, 0.5952],\n",
      "        [0.0020, 0.5972],\n",
      "        [0.0020, 0.5992],\n",
      "        [0.0020, 0.6012],\n",
      "        [0.0020, 0.6032],\n",
      "        [0.0020, 0.6052],\n",
      "        [0.0020, 0.6072],\n",
      "        [0.0020, 0.6092],\n",
      "        [0.0020, 0.6112],\n",
      "        [0.0020, 0.6132],\n",
      "        [0.0020, 0.6152],\n",
      "        [0.0020, 0.6172],\n",
      "        [0.0020, 0.6192],\n",
      "        [0.0020, 0.6212],\n",
      "        [0.0020, 0.6232],\n",
      "        [0.0020, 0.6253],\n",
      "        [0.0020, 0.6273],\n",
      "        [0.0020, 0.6293],\n",
      "        [0.0020, 0.6313],\n",
      "        [0.0020, 0.6333],\n",
      "        [0.0020, 0.6353],\n",
      "        [0.0020, 0.6373],\n",
      "        [0.0020, 0.6393],\n",
      "        [0.0020, 0.6413],\n",
      "        [0.0020, 0.6433],\n",
      "        [0.0020, 0.6453],\n",
      "        [0.0020, 0.6473],\n",
      "        [0.0020, 0.6493],\n",
      "        [0.0020, 0.6513],\n",
      "        [0.0020, 0.6533],\n",
      "        [0.0020, 0.6553],\n",
      "        [0.0020, 0.6573],\n",
      "        [0.0020, 0.6593],\n",
      "        [0.0020, 0.6613],\n",
      "        [0.0020, 0.6633],\n",
      "        [0.0020, 0.6653],\n",
      "        [0.0020, 0.6673],\n",
      "        [0.0020, 0.6693],\n",
      "        [0.0020, 0.6713],\n",
      "        [0.0020, 0.6733],\n",
      "        [0.0020, 0.6754],\n",
      "        [0.0020, 0.6774],\n",
      "        [0.0020, 0.6794],\n",
      "        [0.0020, 0.6814],\n",
      "        [0.0020, 0.6834],\n",
      "        [0.0020, 0.6854],\n",
      "        [0.0020, 0.6874],\n",
      "        [0.0020, 0.6894],\n",
      "        [0.0020, 0.6914],\n",
      "        [0.0020, 0.6934],\n",
      "        [0.0020, 0.6954],\n",
      "        [0.0020, 0.6974],\n",
      "        [0.0020, 0.6994],\n",
      "        [0.0020, 0.7014],\n",
      "        [0.0020, 0.7034],\n",
      "        [0.0020, 0.7054],\n",
      "        [0.0020, 0.7074],\n",
      "        [0.0020, 0.7094],\n",
      "        [0.0020, 0.7114],\n",
      "        [0.0020, 0.7134],\n",
      "        [0.0020, 0.7154],\n",
      "        [0.0020, 0.7174],\n",
      "        [0.0020, 0.7194],\n",
      "        [0.0020, 0.7214],\n",
      "        [0.0020, 0.7234],\n",
      "        [0.0020, 0.7255],\n",
      "        [0.0020, 0.7275],\n",
      "        [0.0020, 0.7295],\n",
      "        [0.0020, 0.7315],\n",
      "        [0.0020, 0.7335],\n",
      "        [0.0020, 0.7355],\n",
      "        [0.0020, 0.7375],\n",
      "        [0.0020, 0.7395],\n",
      "        [0.0020, 0.7415],\n",
      "        [0.0020, 0.7435],\n",
      "        [0.0020, 0.7455],\n",
      "        [0.0020, 0.7475],\n",
      "        [0.0020, 0.7495],\n",
      "        [0.0020, 0.7515],\n",
      "        [0.0020, 0.7535],\n",
      "        [0.0020, 0.7555],\n",
      "        [0.0020, 0.7575],\n",
      "        [0.0020, 0.7595],\n",
      "        [0.0020, 0.7615],\n",
      "        [0.0020, 0.7635],\n",
      "        [0.0020, 0.7655],\n",
      "        [0.0020, 0.7675],\n",
      "        [0.0020, 0.7695],\n",
      "        [0.0020, 0.7715],\n",
      "        [0.0020, 0.7735],\n",
      "        [0.0020, 0.7756],\n",
      "        [0.0020, 0.7776],\n",
      "        [0.0020, 0.7796],\n",
      "        [0.0020, 0.7816],\n",
      "        [0.0020, 0.7836],\n",
      "        [0.0020, 0.7856],\n",
      "        [0.0020, 0.7876],\n",
      "        [0.0020, 0.7896],\n",
      "        [0.0020, 0.7916],\n",
      "        [0.0020, 0.7936],\n",
      "        [0.0020, 0.7956],\n",
      "        [0.0020, 0.7976],\n",
      "        [0.0020, 0.7996],\n",
      "        [0.0020, 0.8016],\n",
      "        [0.0020, 0.8036],\n",
      "        [0.0020, 0.8056],\n",
      "        [0.0020, 0.8076],\n",
      "        [0.0020, 0.8096],\n",
      "        [0.0020, 0.8116],\n",
      "        [0.0020, 0.8136],\n",
      "        [0.0020, 0.8156],\n",
      "        [0.0020, 0.8176],\n",
      "        [0.0020, 0.8196],\n",
      "        [0.0020, 0.8216],\n",
      "        [0.0020, 0.8236],\n",
      "        [0.0020, 0.8257],\n",
      "        [0.0020, 0.8277],\n",
      "        [0.0020, 0.8297],\n",
      "        [0.0020, 0.8317],\n",
      "        [0.0020, 0.8337],\n",
      "        [0.0020, 0.8357],\n",
      "        [0.0020, 0.8377],\n",
      "        [0.0020, 0.8397],\n",
      "        [0.0020, 0.8417],\n",
      "        [0.0020, 0.8437],\n",
      "        [0.0020, 0.8457],\n",
      "        [0.0020, 0.8477],\n",
      "        [0.0020, 0.8497],\n",
      "        [0.0020, 0.8517],\n",
      "        [0.0020, 0.8537],\n",
      "        [0.0020, 0.8557],\n",
      "        [0.0020, 0.8577],\n",
      "        [0.0020, 0.8597],\n",
      "        [0.0020, 0.8617],\n",
      "        [0.0020, 0.8637],\n",
      "        [0.0020, 0.8657],\n",
      "        [0.0020, 0.8677],\n",
      "        [0.0020, 0.8697],\n",
      "        [0.0020, 0.8717],\n",
      "        [0.0020, 0.8737],\n",
      "        [0.0020, 0.8758],\n",
      "        [0.0020, 0.8778],\n",
      "        [0.0020, 0.8798],\n",
      "        [0.0020, 0.8818],\n",
      "        [0.0020, 0.8838],\n",
      "        [0.0020, 0.8858],\n",
      "        [0.0020, 0.8878],\n",
      "        [0.0020, 0.8898],\n",
      "        [0.0020, 0.8918],\n",
      "        [0.0020, 0.8938],\n",
      "        [0.0020, 0.8958],\n",
      "        [0.0020, 0.8978],\n",
      "        [0.0020, 0.8998],\n",
      "        [0.0020, 0.9018],\n",
      "        [0.0020, 0.9038],\n",
      "        [0.0020, 0.9058],\n",
      "        [0.0020, 0.9078],\n",
      "        [0.0020, 0.9098],\n",
      "        [0.0020, 0.9118],\n",
      "        [0.0020, 0.9138],\n",
      "        [0.0020, 0.9158],\n",
      "        [0.0020, 0.9178],\n",
      "        [0.0020, 0.9198],\n",
      "        [0.0020, 0.9218],\n",
      "        [0.0020, 0.9238],\n",
      "        [0.0020, 0.9259],\n",
      "        [0.0020, 0.9279],\n",
      "        [0.0020, 0.9299],\n",
      "        [0.0020, 0.9319],\n",
      "        [0.0020, 0.9339],\n",
      "        [0.0020, 0.9359],\n",
      "        [0.0020, 0.9379],\n",
      "        [0.0020, 0.9399],\n",
      "        [0.0020, 0.9419],\n",
      "        [0.0020, 0.9439],\n",
      "        [0.0020, 0.9459],\n",
      "        [0.0020, 0.9479],\n",
      "        [0.0020, 0.9499],\n",
      "        [0.0020, 0.9519],\n",
      "        [0.0020, 0.9539],\n",
      "        [0.0020, 0.9559],\n",
      "        [0.0020, 0.9579],\n",
      "        [0.0020, 0.9599],\n",
      "        [0.0020, 0.9619],\n",
      "        [0.0020, 0.9639],\n",
      "        [0.0020, 0.9659],\n",
      "        [0.0020, 0.9679],\n",
      "        [0.0020, 0.9699],\n",
      "        [0.0020, 0.9719],\n",
      "        [0.0020, 0.9739],\n",
      "        [0.0020, 0.9760],\n",
      "        [0.0020, 0.9780],\n",
      "        [0.0020, 0.9800],\n",
      "        [0.0020, 0.9820],\n",
      "        [0.0020, 0.9840],\n",
      "        [0.0020, 0.9860],\n",
      "        [0.0020, 0.9880],\n",
      "        [0.0020, 0.9900],\n",
      "        [0.0020, 0.9920],\n",
      "        [0.0020, 0.9940],\n",
      "        [0.0020, 0.9960],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.0020, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.527681Z",
     "start_time": "2021-01-25T05:48:18.501357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0020, 0.0000],\n",
      "        [0.0020, 0.0020],\n",
      "        [0.0020, 0.0040],\n",
      "        [0.0020, 0.0060],\n",
      "        [0.0020, 0.0080],\n",
      "        [0.0020, 0.0100],\n",
      "        [0.0020, 0.0120],\n",
      "        [0.0020, 0.0140],\n",
      "        [0.0020, 0.0160],\n",
      "        [0.0020, 0.0180],\n",
      "        [0.0020, 0.0200],\n",
      "        [0.0020, 0.0220],\n",
      "        [0.0020, 0.0240],\n",
      "        [0.0020, 0.0261],\n",
      "        [0.0020, 0.0281],\n",
      "        [0.0020, 0.0301],\n",
      "        [0.0020, 0.0321],\n",
      "        [0.0020, 0.0341],\n",
      "        [0.0020, 0.0361],\n",
      "        [0.0020, 0.0381],\n",
      "        [0.0020, 0.0401],\n",
      "        [0.0020, 0.0421],\n",
      "        [0.0020, 0.0441],\n",
      "        [0.0020, 0.0461],\n",
      "        [0.0020, 0.0481],\n",
      "        [0.0020, 0.0501],\n",
      "        [0.0020, 0.0521],\n",
      "        [0.0020, 0.0541],\n",
      "        [0.0020, 0.0561],\n",
      "        [0.0020, 0.0581],\n",
      "        [0.0020, 0.0601],\n",
      "        [0.0020, 0.0621],\n",
      "        [0.0020, 0.0641],\n",
      "        [0.0020, 0.0661],\n",
      "        [0.0020, 0.0681],\n",
      "        [0.0020, 0.0701],\n",
      "        [0.0020, 0.0721],\n",
      "        [0.0020, 0.0741],\n",
      "        [0.0020, 0.0762],\n",
      "        [0.0020, 0.0782],\n",
      "        [0.0020, 0.0802],\n",
      "        [0.0020, 0.0822],\n",
      "        [0.0020, 0.0842],\n",
      "        [0.0020, 0.0862],\n",
      "        [0.0020, 0.0882],\n",
      "        [0.0020, 0.0902],\n",
      "        [0.0020, 0.0922],\n",
      "        [0.0020, 0.0942],\n",
      "        [0.0020, 0.0962],\n",
      "        [0.0020, 0.0982],\n",
      "        [0.0020, 0.1002],\n",
      "        [0.0020, 0.1022],\n",
      "        [0.0020, 0.1042],\n",
      "        [0.0020, 0.1062],\n",
      "        [0.0020, 0.1082],\n",
      "        [0.0020, 0.1102],\n",
      "        [0.0020, 0.1122],\n",
      "        [0.0020, 0.1142],\n",
      "        [0.0020, 0.1162],\n",
      "        [0.0020, 0.1182],\n",
      "        [0.0020, 0.1202],\n",
      "        [0.0020, 0.1222],\n",
      "        [0.0020, 0.1242],\n",
      "        [0.0020, 0.1263],\n",
      "        [0.0020, 0.1283],\n",
      "        [0.0020, 0.1303],\n",
      "        [0.0020, 0.1323],\n",
      "        [0.0020, 0.1343],\n",
      "        [0.0020, 0.1363],\n",
      "        [0.0020, 0.1383],\n",
      "        [0.0020, 0.1403],\n",
      "        [0.0020, 0.1423],\n",
      "        [0.0020, 0.1443],\n",
      "        [0.0020, 0.1463],\n",
      "        [0.0020, 0.1483],\n",
      "        [0.0020, 0.1503],\n",
      "        [0.0020, 0.1523],\n",
      "        [0.0020, 0.1543],\n",
      "        [0.0020, 0.1563],\n",
      "        [0.0020, 0.1583],\n",
      "        [0.0020, 0.1603],\n",
      "        [0.0020, 0.1623],\n",
      "        [0.0020, 0.1643],\n",
      "        [0.0020, 0.1663],\n",
      "        [0.0020, 0.1683],\n",
      "        [0.0020, 0.1703],\n",
      "        [0.0020, 0.1723],\n",
      "        [0.0020, 0.1743],\n",
      "        [0.0020, 0.1764],\n",
      "        [0.0020, 0.1784],\n",
      "        [0.0020, 0.1804],\n",
      "        [0.0020, 0.1824],\n",
      "        [0.0020, 0.1844],\n",
      "        [0.0020, 0.1864],\n",
      "        [0.0020, 0.1884],\n",
      "        [0.0020, 0.1904],\n",
      "        [0.0020, 0.1924],\n",
      "        [0.0020, 0.1944],\n",
      "        [0.0020, 0.1964],\n",
      "        [0.0020, 0.1984],\n",
      "        [0.0020, 0.2004],\n",
      "        [0.0020, 0.2024],\n",
      "        [0.0020, 0.2044],\n",
      "        [0.0020, 0.2064],\n",
      "        [0.0020, 0.2084],\n",
      "        [0.0020, 0.2104],\n",
      "        [0.0020, 0.2124],\n",
      "        [0.0020, 0.2144],\n",
      "        [0.0020, 0.2164],\n",
      "        [0.0020, 0.2184],\n",
      "        [0.0020, 0.2204],\n",
      "        [0.0020, 0.2224],\n",
      "        [0.0020, 0.2244],\n",
      "        [0.0020, 0.2265],\n",
      "        [0.0020, 0.2285],\n",
      "        [0.0020, 0.2305],\n",
      "        [0.0020, 0.2325],\n",
      "        [0.0020, 0.2345],\n",
      "        [0.0020, 0.2365],\n",
      "        [0.0020, 0.2385],\n",
      "        [0.0020, 0.2405],\n",
      "        [0.0020, 0.2425],\n",
      "        [0.0020, 0.2445],\n",
      "        [0.0020, 0.2465],\n",
      "        [0.0020, 0.2485],\n",
      "        [0.0020, 0.2505],\n",
      "        [0.0020, 0.2525],\n",
      "        [0.0020, 0.2545],\n",
      "        [0.0020, 0.2565],\n",
      "        [0.0020, 0.2585],\n",
      "        [0.0020, 0.2605],\n",
      "        [0.0020, 0.2625],\n",
      "        [0.0020, 0.2645],\n",
      "        [0.0020, 0.2665],\n",
      "        [0.0020, 0.2685],\n",
      "        [0.0020, 0.2705],\n",
      "        [0.0020, 0.2725],\n",
      "        [0.0020, 0.2745],\n",
      "        [0.0020, 0.2766],\n",
      "        [0.0020, 0.2786],\n",
      "        [0.0020, 0.2806],\n",
      "        [0.0020, 0.2826],\n",
      "        [0.0020, 0.2846],\n",
      "        [0.0020, 0.2866],\n",
      "        [0.0020, 0.2886],\n",
      "        [0.0020, 0.2906],\n",
      "        [0.0020, 0.2926],\n",
      "        [0.0020, 0.2946],\n",
      "        [0.0020, 0.2966],\n",
      "        [0.0020, 0.2986],\n",
      "        [0.0020, 0.3006],\n",
      "        [0.0020, 0.3026],\n",
      "        [0.0020, 0.3046],\n",
      "        [0.0020, 0.3066],\n",
      "        [0.0020, 0.3086],\n",
      "        [0.0020, 0.3106],\n",
      "        [0.0020, 0.3126],\n",
      "        [0.0020, 0.3146],\n",
      "        [0.0020, 0.3166],\n",
      "        [0.0020, 0.3186],\n",
      "        [0.0020, 0.3206],\n",
      "        [0.0020, 0.3226],\n",
      "        [0.0020, 0.3246],\n",
      "        [0.0020, 0.3267],\n",
      "        [0.0020, 0.3287],\n",
      "        [0.0020, 0.3307],\n",
      "        [0.0020, 0.3327],\n",
      "        [0.0020, 0.3347],\n",
      "        [0.0020, 0.3367],\n",
      "        [0.0020, 0.3387],\n",
      "        [0.0020, 0.3407],\n",
      "        [0.0020, 0.3427],\n",
      "        [0.0020, 0.3447],\n",
      "        [0.0020, 0.3467],\n",
      "        [0.0020, 0.3487],\n",
      "        [0.0020, 0.3507],\n",
      "        [0.0020, 0.3527],\n",
      "        [0.0020, 0.3547],\n",
      "        [0.0020, 0.3567],\n",
      "        [0.0020, 0.3587],\n",
      "        [0.0020, 0.3607],\n",
      "        [0.0020, 0.3627],\n",
      "        [0.0020, 0.3647],\n",
      "        [0.0020, 0.3667],\n",
      "        [0.0020, 0.3687],\n",
      "        [0.0020, 0.3707],\n",
      "        [0.0020, 0.3727],\n",
      "        [0.0020, 0.3747],\n",
      "        [0.0020, 0.3768],\n",
      "        [0.0020, 0.3788],\n",
      "        [0.0020, 0.3808],\n",
      "        [0.0020, 0.3828],\n",
      "        [0.0020, 0.3848],\n",
      "        [0.0020, 0.3868],\n",
      "        [0.0020, 0.3888],\n",
      "        [0.0020, 0.3908],\n",
      "        [0.0020, 0.3928],\n",
      "        [0.0020, 0.3948],\n",
      "        [0.0020, 0.3968],\n",
      "        [0.0020, 0.3988],\n",
      "        [0.0020, 0.4008],\n",
      "        [0.0020, 0.4028],\n",
      "        [0.0020, 0.4048],\n",
      "        [0.0020, 0.4068],\n",
      "        [0.0020, 0.4088],\n",
      "        [0.0020, 0.4108],\n",
      "        [0.0020, 0.4128],\n",
      "        [0.0020, 0.4148],\n",
      "        [0.0020, 0.4168],\n",
      "        [0.0020, 0.4188],\n",
      "        [0.0020, 0.4208],\n",
      "        [0.0020, 0.4228],\n",
      "        [0.0020, 0.4248],\n",
      "        [0.0020, 0.4269],\n",
      "        [0.0020, 0.4289],\n",
      "        [0.0020, 0.4309],\n",
      "        [0.0020, 0.4329],\n",
      "        [0.0020, 0.4349],\n",
      "        [0.0020, 0.4369],\n",
      "        [0.0020, 0.4389],\n",
      "        [0.0020, 0.4409],\n",
      "        [0.0020, 0.4429],\n",
      "        [0.0020, 0.4449],\n",
      "        [0.0020, 0.4469],\n",
      "        [0.0020, 0.4489],\n",
      "        [0.0020, 0.4509],\n",
      "        [0.0020, 0.4529],\n",
      "        [0.0020, 0.4549],\n",
      "        [0.0020, 0.4569],\n",
      "        [0.0020, 0.4589],\n",
      "        [0.0020, 0.4609],\n",
      "        [0.0020, 0.4629],\n",
      "        [0.0020, 0.4649],\n",
      "        [0.0020, 0.4669],\n",
      "        [0.0020, 0.4689],\n",
      "        [0.0020, 0.4709],\n",
      "        [0.0020, 0.4729],\n",
      "        [0.0020, 0.4749],\n",
      "        [0.0020, 0.4770],\n",
      "        [0.0020, 0.4790],\n",
      "        [0.0020, 0.4810],\n",
      "        [0.0020, 0.4830],\n",
      "        [0.0020, 0.4850],\n",
      "        [0.0020, 0.4870],\n",
      "        [0.0020, 0.4890],\n",
      "        [0.0020, 0.4910],\n",
      "        [0.0020, 0.4930],\n",
      "        [0.0020, 0.4950],\n",
      "        [0.0020, 0.4970],\n",
      "        [0.0020, 0.4990],\n",
      "        [0.0020, 0.5010],\n",
      "        [0.0020, 0.5030],\n",
      "        [0.0020, 0.5050],\n",
      "        [0.0020, 0.5070],\n",
      "        [0.0020, 0.5090],\n",
      "        [0.0020, 0.5110],\n",
      "        [0.0020, 0.5130],\n",
      "        [0.0020, 0.5150],\n",
      "        [0.0020, 0.5170],\n",
      "        [0.0020, 0.5190],\n",
      "        [0.0020, 0.5210],\n",
      "        [0.0020, 0.5230],\n",
      "        [0.0020, 0.5251],\n",
      "        [0.0020, 0.5271],\n",
      "        [0.0020, 0.5291],\n",
      "        [0.0020, 0.5311],\n",
      "        [0.0020, 0.5331],\n",
      "        [0.0020, 0.5351],\n",
      "        [0.0020, 0.5371],\n",
      "        [0.0020, 0.5391],\n",
      "        [0.0020, 0.5411],\n",
      "        [0.0020, 0.5431],\n",
      "        [0.0020, 0.5451],\n",
      "        [0.0020, 0.5471],\n",
      "        [0.0020, 0.5491],\n",
      "        [0.0020, 0.5511],\n",
      "        [0.0020, 0.5531],\n",
      "        [0.0020, 0.5551],\n",
      "        [0.0020, 0.5571],\n",
      "        [0.0020, 0.5591],\n",
      "        [0.0020, 0.5611],\n",
      "        [0.0020, 0.5631],\n",
      "        [0.0020, 0.5651],\n",
      "        [0.0020, 0.5671],\n",
      "        [0.0020, 0.5691],\n",
      "        [0.0020, 0.5711],\n",
      "        [0.0020, 0.5731],\n",
      "        [0.0020, 0.5752],\n",
      "        [0.0020, 0.5772],\n",
      "        [0.0020, 0.5792],\n",
      "        [0.0020, 0.5812],\n",
      "        [0.0020, 0.5832],\n",
      "        [0.0020, 0.5852],\n",
      "        [0.0020, 0.5872],\n",
      "        [0.0020, 0.5892],\n",
      "        [0.0020, 0.5912],\n",
      "        [0.0020, 0.5932],\n",
      "        [0.0020, 0.5952],\n",
      "        [0.0020, 0.5972],\n",
      "        [0.0020, 0.5992],\n",
      "        [0.0020, 0.6012],\n",
      "        [0.0020, 0.6032],\n",
      "        [0.0020, 0.6052],\n",
      "        [0.0020, 0.6072],\n",
      "        [0.0020, 0.6092],\n",
      "        [0.0020, 0.6112],\n",
      "        [0.0020, 0.6132],\n",
      "        [0.0020, 0.6152],\n",
      "        [0.0020, 0.6172],\n",
      "        [0.0020, 0.6192],\n",
      "        [0.0020, 0.6212],\n",
      "        [0.0020, 0.6232],\n",
      "        [0.0020, 0.6253],\n",
      "        [0.0020, 0.6273],\n",
      "        [0.0020, 0.6293],\n",
      "        [0.0020, 0.6313],\n",
      "        [0.0020, 0.6333],\n",
      "        [0.0020, 0.6353],\n",
      "        [0.0020, 0.6373],\n",
      "        [0.0020, 0.6393],\n",
      "        [0.0020, 0.6413],\n",
      "        [0.0020, 0.6433],\n",
      "        [0.0020, 0.6453],\n",
      "        [0.0020, 0.6473],\n",
      "        [0.0020, 0.6493],\n",
      "        [0.0020, 0.6513],\n",
      "        [0.0020, 0.6533],\n",
      "        [0.0020, 0.6553],\n",
      "        [0.0020, 0.6573],\n",
      "        [0.0020, 0.6593],\n",
      "        [0.0020, 0.6613],\n",
      "        [0.0020, 0.6633],\n",
      "        [0.0020, 0.6653],\n",
      "        [0.0020, 0.6673],\n",
      "        [0.0020, 0.6693],\n",
      "        [0.0020, 0.6713],\n",
      "        [0.0020, 0.6733],\n",
      "        [0.0020, 0.6754],\n",
      "        [0.0020, 0.6774],\n",
      "        [0.0020, 0.6794],\n",
      "        [0.0020, 0.6814],\n",
      "        [0.0020, 0.6834],\n",
      "        [0.0020, 0.6854],\n",
      "        [0.0020, 0.6874],\n",
      "        [0.0020, 0.6894],\n",
      "        [0.0020, 0.6914],\n",
      "        [0.0020, 0.6934],\n",
      "        [0.0020, 0.6954],\n",
      "        [0.0020, 0.6974],\n",
      "        [0.0020, 0.6994],\n",
      "        [0.0020, 0.7014],\n",
      "        [0.0020, 0.7034],\n",
      "        [0.0020, 0.7054],\n",
      "        [0.0020, 0.7074],\n",
      "        [0.0020, 0.7094],\n",
      "        [0.0020, 0.7114],\n",
      "        [0.0020, 0.7134],\n",
      "        [0.0020, 0.7154],\n",
      "        [0.0020, 0.7174],\n",
      "        [0.0020, 0.7194],\n",
      "        [0.0020, 0.7214],\n",
      "        [0.0020, 0.7234],\n",
      "        [0.0020, 0.7255],\n",
      "        [0.0020, 0.7275],\n",
      "        [0.0020, 0.7295],\n",
      "        [0.0020, 0.7315],\n",
      "        [0.0020, 0.7335],\n",
      "        [0.0020, 0.7355],\n",
      "        [0.0020, 0.7375],\n",
      "        [0.0020, 0.7395],\n",
      "        [0.0020, 0.7415],\n",
      "        [0.0020, 0.7435],\n",
      "        [0.0020, 0.7455],\n",
      "        [0.0020, 0.7475],\n",
      "        [0.0020, 0.7495],\n",
      "        [0.0020, 0.7515],\n",
      "        [0.0020, 0.7535],\n",
      "        [0.0020, 0.7555],\n",
      "        [0.0020, 0.7575],\n",
      "        [0.0020, 0.7595],\n",
      "        [0.0020, 0.7615],\n",
      "        [0.0020, 0.7635],\n",
      "        [0.0020, 0.7655],\n",
      "        [0.0020, 0.7675],\n",
      "        [0.0020, 0.7695],\n",
      "        [0.0020, 0.7715],\n",
      "        [0.0020, 0.7735],\n",
      "        [0.0020, 0.7756],\n",
      "        [0.0020, 0.7776],\n",
      "        [0.0020, 0.7796],\n",
      "        [0.0020, 0.7816],\n",
      "        [0.0020, 0.7836],\n",
      "        [0.0020, 0.7856],\n",
      "        [0.0020, 0.7876],\n",
      "        [0.0020, 0.7896],\n",
      "        [0.0020, 0.7916],\n",
      "        [0.0020, 0.7936],\n",
      "        [0.0020, 0.7956],\n",
      "        [0.0020, 0.7976],\n",
      "        [0.0020, 0.7996],\n",
      "        [0.0020, 0.8016],\n",
      "        [0.0020, 0.8036],\n",
      "        [0.0020, 0.8056],\n",
      "        [0.0020, 0.8076],\n",
      "        [0.0020, 0.8096],\n",
      "        [0.0020, 0.8116],\n",
      "        [0.0020, 0.8136],\n",
      "        [0.0020, 0.8156],\n",
      "        [0.0020, 0.8176],\n",
      "        [0.0020, 0.8196],\n",
      "        [0.0020, 0.8216],\n",
      "        [0.0020, 0.8236],\n",
      "        [0.0020, 0.8257],\n",
      "        [0.0020, 0.8277],\n",
      "        [0.0020, 0.8297],\n",
      "        [0.0020, 0.8317],\n",
      "        [0.0020, 0.8337],\n",
      "        [0.0020, 0.8357],\n",
      "        [0.0020, 0.8377],\n",
      "        [0.0020, 0.8397],\n",
      "        [0.0020, 0.8417],\n",
      "        [0.0020, 0.8437],\n",
      "        [0.0020, 0.8457],\n",
      "        [0.0020, 0.8477],\n",
      "        [0.0020, 0.8497],\n",
      "        [0.0020, 0.8517],\n",
      "        [0.0020, 0.8537],\n",
      "        [0.0020, 0.8557],\n",
      "        [0.0020, 0.8577],\n",
      "        [0.0020, 0.8597],\n",
      "        [0.0020, 0.8617],\n",
      "        [0.0020, 0.8637],\n",
      "        [0.0020, 0.8657],\n",
      "        [0.0020, 0.8677],\n",
      "        [0.0020, 0.8697],\n",
      "        [0.0020, 0.8717],\n",
      "        [0.0020, 0.8737],\n",
      "        [0.0020, 0.8758],\n",
      "        [0.0020, 0.8778],\n",
      "        [0.0020, 0.8798],\n",
      "        [0.0020, 0.8818],\n",
      "        [0.0020, 0.8838],\n",
      "        [0.0020, 0.8858],\n",
      "        [0.0020, 0.8878],\n",
      "        [0.0020, 0.8898],\n",
      "        [0.0020, 0.8918],\n",
      "        [0.0020, 0.8938],\n",
      "        [0.0020, 0.8958],\n",
      "        [0.0020, 0.8978],\n",
      "        [0.0020, 0.8998],\n",
      "        [0.0020, 0.9018],\n",
      "        [0.0020, 0.9038],\n",
      "        [0.0020, 0.9058],\n",
      "        [0.0020, 0.9078],\n",
      "        [0.0020, 0.9098],\n",
      "        [0.0020, 0.9118],\n",
      "        [0.0020, 0.9138],\n",
      "        [0.0020, 0.9158],\n",
      "        [0.0020, 0.9178],\n",
      "        [0.0020, 0.9198],\n",
      "        [0.0020, 0.9218],\n",
      "        [0.0020, 0.9238],\n",
      "        [0.0020, 0.9259],\n",
      "        [0.0020, 0.9279],\n",
      "        [0.0020, 0.9299],\n",
      "        [0.0020, 0.9319],\n",
      "        [0.0020, 0.9339],\n",
      "        [0.0020, 0.9359],\n",
      "        [0.0020, 0.9379],\n",
      "        [0.0020, 0.9399],\n",
      "        [0.0020, 0.9419],\n",
      "        [0.0020, 0.9439],\n",
      "        [0.0020, 0.9459],\n",
      "        [0.0020, 0.9479],\n",
      "        [0.0020, 0.9499],\n",
      "        [0.0020, 0.9519],\n",
      "        [0.0020, 0.9539],\n",
      "        [0.0020, 0.9559],\n",
      "        [0.0020, 0.9579],\n",
      "        [0.0020, 0.9599],\n",
      "        [0.0020, 0.9619],\n",
      "        [0.0020, 0.9639],\n",
      "        [0.0020, 0.9659],\n",
      "        [0.0020, 0.9679],\n",
      "        [0.0020, 0.9699],\n",
      "        [0.0020, 0.9719],\n",
      "        [0.0020, 0.9739],\n",
      "        [0.0020, 0.9760],\n",
      "        [0.0020, 0.9780],\n",
      "        [0.0020, 0.9800],\n",
      "        [0.0020, 0.9820],\n",
      "        [0.0020, 0.9840],\n",
      "        [0.0020, 0.9860],\n",
      "        [0.0020, 0.9880],\n",
      "        [0.0020, 0.9900],\n",
      "        [0.0020, 0.9920],\n",
      "        [0.0020, 0.9940],\n",
      "        [0.0020, 0.9960],\n",
      "        [0.0020, 0.9980],\n",
      "        [0.0020, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(test_data[-1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate how to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.533830Z",
     "start_time": "2021-01-25T05:48:18.529541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.543594Z",
     "start_time": "2021-01-25T05:48:18.536399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 66)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = []\n",
    "for d in train_data:\n",
    "    D.append(np.hstack(d))\n",
    "D = np.vstack(D)\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.550671Z",
     "start_time": "2021-01-25T05:48:18.545784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-22.716675"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.763908Z",
     "start_time": "2021-01-25T05:48:18.552873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_mx = np.max(D,axis=0)\n",
    "x_mn = np.min(D,axis=0)\n",
    "abs_x_mx = np.max(abs(D),axis=0)\n",
    "plt.plot(x_mx)\n",
    "plt.plot(x_mn)\n",
    "plt.plot(abs_x_mx)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.787584Z",
     "start_time": "2021-01-25T05:48:18.766470Z"
    }
   },
   "outputs": [],
   "source": [
    "class LatentVectors(Dataset):\n",
    "    def __init__(self, data,doPreprocess=False,w=1,simLen=200,abs_x_mx=abs_x_mx, memory=6):\n",
    "        self.data = data\n",
    "        self.doPreprocess = doPreprocess\n",
    "        self.simLen = simLen\n",
    "        self.w = w\n",
    "        self.abs_x_mx = abs_x_mx[:-2]\n",
    "        self.abs_p_mx = abs_x_mx[-2:]\n",
    "        self.memory= memory\n",
    "                 \n",
    "    def __len__(self):\n",
    "        return self.simLen*len(self.data)\n",
    "\n",
    "    def preprocess_x(self,x):\n",
    "        if x.shape[0] == self.abs_x_mx.shape[0]:\n",
    "            return x/self.abs_x_mx[:,None]\n",
    "        else:\n",
    "            return x/self.abs_x_mx\n",
    "\n",
    "    def preprocess_p(self,p):\n",
    "        if p.shape[0] == self.abs_p_mx.shape[0]:\n",
    "            return p/self.abs_p_mx[:,None]\n",
    "        else:\n",
    "            return p/self.abs_p_mx\n",
    "\n",
    "    def invPreprocess_x(self,xnew):\n",
    "        x = xnew*self.abs_x_mx\n",
    "        return x\n",
    "\n",
    "    def invPreprocess_p(self,pnew):\n",
    "        p = pnew*self.abs_p_mx\n",
    "        return p\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        q,r = np.divmod(idx,self.simLen)\n",
    "        X, p = self.data[q]\n",
    "        r_idx = np.random.randint(0,self.simLen-self.w)\n",
    "        \n",
    "        x = torch.zeros((latentDim, self.memory))\n",
    "        p_x = torch.zeros((2, self.memory))\n",
    "        \n",
    "        x[:,0] = X[r_idx:r_idx+1]\n",
    "        y = X[r_idx+1:r_idx+self.w+1]\n",
    "        \n",
    "        p_x[:,0] = p[r_idx:r_idx+1]\n",
    "        p_y = p[r_idx+1:r_idx+self.w+1]\n",
    "        \n",
    "        if self.doPreprocess:\n",
    "            x = self.preprocess_x(x)\n",
    "            y = self.preprocess_x(y)\n",
    "            p_x = self.preprocess_p(p_x)\n",
    "            p_y = self.preprocess_p(p_y)\n",
    "        \n",
    "        return x.squeeze(), y, p_x.squeeze(), p_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.806758Z",
     "start_time": "2021-01-25T05:48:18.790088Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64]),\n",
       " torch.Size([499, 64]),\n",
       " torch.Size([2]),\n",
       " torch.Size([499, 2]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataset = LatentVectors(train_data,doPreprocess=True,w=w,simLen=simLen,abs_x_mx=abs_x_mx,\n",
    "                             memory=memory_length)\n",
    "testDataset = LatentVectors(test_data,doPreprocess=True,w=w,simLen=simLen,abs_x_mx=abs_x_mx,memory=memory_length)\n",
    "X,y,p_x,p_y = trainDataset[0]\n",
    "X.shape,y.shape,p_x.shape,p_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.814559Z",
     "start_time": "2021-01-25T05:48:18.808644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500, 500, 500)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataLoader = DataLoader(dataset=trainDataset, batch_size=bz, shuffle=True, drop_last=True)\n",
    "testDataLoader = DataLoader(dataset=testDataset, batch_size=bz)\n",
    "len(trainDataset), len(trainDataLoader), len(testDataset), len(testDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.822671Z",
     "start_time": "2021-01-25T05:48:18.816552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]),\n",
       " torch.Size([1, 499, 64]),\n",
       " torch.Size([1, 2]),\n",
       " torch.Size([1, 499, 2]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y, p_x, p_y = next(iter(trainDataLoader))\n",
    "X.shape, y.shape, p_x.shape, p_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.849118Z",
     "start_time": "2021-01-25T05:48:18.824438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0020],\n",
       "         [1.0000, 0.0040],\n",
       "         [1.0000, 0.0060],\n",
       "         [1.0000, 0.0080],\n",
       "         [1.0000, 0.0100],\n",
       "         [1.0000, 0.0120],\n",
       "         [1.0000, 0.0140],\n",
       "         [1.0000, 0.0160],\n",
       "         [1.0000, 0.0180],\n",
       "         [1.0000, 0.0200],\n",
       "         [1.0000, 0.0220],\n",
       "         [1.0000, 0.0240],\n",
       "         [1.0000, 0.0261],\n",
       "         [1.0000, 0.0281],\n",
       "         [1.0000, 0.0301],\n",
       "         [1.0000, 0.0321],\n",
       "         [1.0000, 0.0341],\n",
       "         [1.0000, 0.0361],\n",
       "         [1.0000, 0.0381],\n",
       "         [1.0000, 0.0401],\n",
       "         [1.0000, 0.0421],\n",
       "         [1.0000, 0.0441],\n",
       "         [1.0000, 0.0461],\n",
       "         [1.0000, 0.0481],\n",
       "         [1.0000, 0.0501],\n",
       "         [1.0000, 0.0521],\n",
       "         [1.0000, 0.0541],\n",
       "         [1.0000, 0.0561],\n",
       "         [1.0000, 0.0581],\n",
       "         [1.0000, 0.0601],\n",
       "         [1.0000, 0.0621],\n",
       "         [1.0000, 0.0641],\n",
       "         [1.0000, 0.0661],\n",
       "         [1.0000, 0.0681],\n",
       "         [1.0000, 0.0701],\n",
       "         [1.0000, 0.0721],\n",
       "         [1.0000, 0.0741],\n",
       "         [1.0000, 0.0762],\n",
       "         [1.0000, 0.0782],\n",
       "         [1.0000, 0.0802],\n",
       "         [1.0000, 0.0822],\n",
       "         [1.0000, 0.0842],\n",
       "         [1.0000, 0.0862],\n",
       "         [1.0000, 0.0882],\n",
       "         [1.0000, 0.0902],\n",
       "         [1.0000, 0.0922],\n",
       "         [1.0000, 0.0942],\n",
       "         [1.0000, 0.0962],\n",
       "         [1.0000, 0.0982],\n",
       "         [1.0000, 0.1002],\n",
       "         [1.0000, 0.1022],\n",
       "         [1.0000, 0.1042],\n",
       "         [1.0000, 0.1062],\n",
       "         [1.0000, 0.1082],\n",
       "         [1.0000, 0.1102],\n",
       "         [1.0000, 0.1122],\n",
       "         [1.0000, 0.1142],\n",
       "         [1.0000, 0.1162],\n",
       "         [1.0000, 0.1182],\n",
       "         [1.0000, 0.1202],\n",
       "         [1.0000, 0.1222],\n",
       "         [1.0000, 0.1242],\n",
       "         [1.0000, 0.1263],\n",
       "         [1.0000, 0.1283],\n",
       "         [1.0000, 0.1303],\n",
       "         [1.0000, 0.1323],\n",
       "         [1.0000, 0.1343],\n",
       "         [1.0000, 0.1363],\n",
       "         [1.0000, 0.1383],\n",
       "         [1.0000, 0.1403],\n",
       "         [1.0000, 0.1423],\n",
       "         [1.0000, 0.1443],\n",
       "         [1.0000, 0.1463],\n",
       "         [1.0000, 0.1483],\n",
       "         [1.0000, 0.1503],\n",
       "         [1.0000, 0.1523],\n",
       "         [1.0000, 0.1543],\n",
       "         [1.0000, 0.1563],\n",
       "         [1.0000, 0.1583],\n",
       "         [1.0000, 0.1603],\n",
       "         [1.0000, 0.1623],\n",
       "         [1.0000, 0.1643],\n",
       "         [1.0000, 0.1663],\n",
       "         [1.0000, 0.1683],\n",
       "         [1.0000, 0.1703],\n",
       "         [1.0000, 0.1723],\n",
       "         [1.0000, 0.1743],\n",
       "         [1.0000, 0.1764],\n",
       "         [1.0000, 0.1784],\n",
       "         [1.0000, 0.1804],\n",
       "         [1.0000, 0.1824],\n",
       "         [1.0000, 0.1844],\n",
       "         [1.0000, 0.1864],\n",
       "         [1.0000, 0.1884],\n",
       "         [1.0000, 0.1904],\n",
       "         [1.0000, 0.1924],\n",
       "         [1.0000, 0.1944],\n",
       "         [1.0000, 0.1964],\n",
       "         [1.0000, 0.1984],\n",
       "         [1.0000, 0.2004],\n",
       "         [1.0000, 0.2024],\n",
       "         [1.0000, 0.2044],\n",
       "         [1.0000, 0.2064],\n",
       "         [1.0000, 0.2084],\n",
       "         [1.0000, 0.2104],\n",
       "         [1.0000, 0.2124],\n",
       "         [1.0000, 0.2144],\n",
       "         [1.0000, 0.2164],\n",
       "         [1.0000, 0.2184],\n",
       "         [1.0000, 0.2204],\n",
       "         [1.0000, 0.2224],\n",
       "         [1.0000, 0.2244],\n",
       "         [1.0000, 0.2265],\n",
       "         [1.0000, 0.2285],\n",
       "         [1.0000, 0.2305],\n",
       "         [1.0000, 0.2325],\n",
       "         [1.0000, 0.2345],\n",
       "         [1.0000, 0.2365],\n",
       "         [1.0000, 0.2385],\n",
       "         [1.0000, 0.2405],\n",
       "         [1.0000, 0.2425],\n",
       "         [1.0000, 0.2445],\n",
       "         [1.0000, 0.2465],\n",
       "         [1.0000, 0.2485],\n",
       "         [1.0000, 0.2505],\n",
       "         [1.0000, 0.2525],\n",
       "         [1.0000, 0.2545],\n",
       "         [1.0000, 0.2565],\n",
       "         [1.0000, 0.2585],\n",
       "         [1.0000, 0.2605],\n",
       "         [1.0000, 0.2625],\n",
       "         [1.0000, 0.2645],\n",
       "         [1.0000, 0.2665],\n",
       "         [1.0000, 0.2685],\n",
       "         [1.0000, 0.2705],\n",
       "         [1.0000, 0.2725],\n",
       "         [1.0000, 0.2745],\n",
       "         [1.0000, 0.2766],\n",
       "         [1.0000, 0.2786],\n",
       "         [1.0000, 0.2806],\n",
       "         [1.0000, 0.2826],\n",
       "         [1.0000, 0.2846],\n",
       "         [1.0000, 0.2866],\n",
       "         [1.0000, 0.2886],\n",
       "         [1.0000, 0.2906],\n",
       "         [1.0000, 0.2926],\n",
       "         [1.0000, 0.2946],\n",
       "         [1.0000, 0.2966],\n",
       "         [1.0000, 0.2986],\n",
       "         [1.0000, 0.3006],\n",
       "         [1.0000, 0.3026],\n",
       "         [1.0000, 0.3046],\n",
       "         [1.0000, 0.3066],\n",
       "         [1.0000, 0.3086],\n",
       "         [1.0000, 0.3106],\n",
       "         [1.0000, 0.3126],\n",
       "         [1.0000, 0.3146],\n",
       "         [1.0000, 0.3166],\n",
       "         [1.0000, 0.3186],\n",
       "         [1.0000, 0.3206],\n",
       "         [1.0000, 0.3226],\n",
       "         [1.0000, 0.3246],\n",
       "         [1.0000, 0.3267],\n",
       "         [1.0000, 0.3287],\n",
       "         [1.0000, 0.3307],\n",
       "         [1.0000, 0.3327],\n",
       "         [1.0000, 0.3347],\n",
       "         [1.0000, 0.3367],\n",
       "         [1.0000, 0.3387],\n",
       "         [1.0000, 0.3407],\n",
       "         [1.0000, 0.3427],\n",
       "         [1.0000, 0.3447],\n",
       "         [1.0000, 0.3467],\n",
       "         [1.0000, 0.3487],\n",
       "         [1.0000, 0.3507],\n",
       "         [1.0000, 0.3527],\n",
       "         [1.0000, 0.3547],\n",
       "         [1.0000, 0.3567],\n",
       "         [1.0000, 0.3587],\n",
       "         [1.0000, 0.3607],\n",
       "         [1.0000, 0.3627],\n",
       "         [1.0000, 0.3647],\n",
       "         [1.0000, 0.3667],\n",
       "         [1.0000, 0.3687],\n",
       "         [1.0000, 0.3707],\n",
       "         [1.0000, 0.3727],\n",
       "         [1.0000, 0.3747],\n",
       "         [1.0000, 0.3768],\n",
       "         [1.0000, 0.3788],\n",
       "         [1.0000, 0.3808],\n",
       "         [1.0000, 0.3828],\n",
       "         [1.0000, 0.3848],\n",
       "         [1.0000, 0.3868],\n",
       "         [1.0000, 0.3888],\n",
       "         [1.0000, 0.3908],\n",
       "         [1.0000, 0.3928],\n",
       "         [1.0000, 0.3948],\n",
       "         [1.0000, 0.3968],\n",
       "         [1.0000, 0.3988],\n",
       "         [1.0000, 0.4008],\n",
       "         [1.0000, 0.4028],\n",
       "         [1.0000, 0.4048],\n",
       "         [1.0000, 0.4068],\n",
       "         [1.0000, 0.4088],\n",
       "         [1.0000, 0.4108],\n",
       "         [1.0000, 0.4128],\n",
       "         [1.0000, 0.4148],\n",
       "         [1.0000, 0.4168],\n",
       "         [1.0000, 0.4188],\n",
       "         [1.0000, 0.4208],\n",
       "         [1.0000, 0.4228],\n",
       "         [1.0000, 0.4248],\n",
       "         [1.0000, 0.4269],\n",
       "         [1.0000, 0.4289],\n",
       "         [1.0000, 0.4309],\n",
       "         [1.0000, 0.4329],\n",
       "         [1.0000, 0.4349],\n",
       "         [1.0000, 0.4369],\n",
       "         [1.0000, 0.4389],\n",
       "         [1.0000, 0.4409],\n",
       "         [1.0000, 0.4429],\n",
       "         [1.0000, 0.4449],\n",
       "         [1.0000, 0.4469],\n",
       "         [1.0000, 0.4489],\n",
       "         [1.0000, 0.4509],\n",
       "         [1.0000, 0.4529],\n",
       "         [1.0000, 0.4549],\n",
       "         [1.0000, 0.4569],\n",
       "         [1.0000, 0.4589],\n",
       "         [1.0000, 0.4609],\n",
       "         [1.0000, 0.4629],\n",
       "         [1.0000, 0.4649],\n",
       "         [1.0000, 0.4669],\n",
       "         [1.0000, 0.4689],\n",
       "         [1.0000, 0.4709],\n",
       "         [1.0000, 0.4729],\n",
       "         [1.0000, 0.4749],\n",
       "         [1.0000, 0.4770],\n",
       "         [1.0000, 0.4790],\n",
       "         [1.0000, 0.4810],\n",
       "         [1.0000, 0.4830],\n",
       "         [1.0000, 0.4850],\n",
       "         [1.0000, 0.4870],\n",
       "         [1.0000, 0.4890],\n",
       "         [1.0000, 0.4910],\n",
       "         [1.0000, 0.4930],\n",
       "         [1.0000, 0.4950],\n",
       "         [1.0000, 0.4970],\n",
       "         [1.0000, 0.4990],\n",
       "         [1.0000, 0.5010],\n",
       "         [1.0000, 0.5030],\n",
       "         [1.0000, 0.5050],\n",
       "         [1.0000, 0.5070],\n",
       "         [1.0000, 0.5090],\n",
       "         [1.0000, 0.5110],\n",
       "         [1.0000, 0.5130],\n",
       "         [1.0000, 0.5150],\n",
       "         [1.0000, 0.5170],\n",
       "         [1.0000, 0.5190],\n",
       "         [1.0000, 0.5210],\n",
       "         [1.0000, 0.5230],\n",
       "         [1.0000, 0.5251],\n",
       "         [1.0000, 0.5271],\n",
       "         [1.0000, 0.5291],\n",
       "         [1.0000, 0.5311],\n",
       "         [1.0000, 0.5331],\n",
       "         [1.0000, 0.5351],\n",
       "         [1.0000, 0.5371],\n",
       "         [1.0000, 0.5391],\n",
       "         [1.0000, 0.5411],\n",
       "         [1.0000, 0.5431],\n",
       "         [1.0000, 0.5451],\n",
       "         [1.0000, 0.5471],\n",
       "         [1.0000, 0.5491],\n",
       "         [1.0000, 0.5511],\n",
       "         [1.0000, 0.5531],\n",
       "         [1.0000, 0.5551],\n",
       "         [1.0000, 0.5571],\n",
       "         [1.0000, 0.5591],\n",
       "         [1.0000, 0.5611],\n",
       "         [1.0000, 0.5631],\n",
       "         [1.0000, 0.5651],\n",
       "         [1.0000, 0.5671],\n",
       "         [1.0000, 0.5691],\n",
       "         [1.0000, 0.5711],\n",
       "         [1.0000, 0.5731],\n",
       "         [1.0000, 0.5752],\n",
       "         [1.0000, 0.5772],\n",
       "         [1.0000, 0.5792],\n",
       "         [1.0000, 0.5812],\n",
       "         [1.0000, 0.5832],\n",
       "         [1.0000, 0.5852],\n",
       "         [1.0000, 0.5872],\n",
       "         [1.0000, 0.5892],\n",
       "         [1.0000, 0.5912],\n",
       "         [1.0000, 0.5932],\n",
       "         [1.0000, 0.5952],\n",
       "         [1.0000, 0.5972],\n",
       "         [1.0000, 0.5992],\n",
       "         [1.0000, 0.6012],\n",
       "         [1.0000, 0.6032],\n",
       "         [1.0000, 0.6052],\n",
       "         [1.0000, 0.6072],\n",
       "         [1.0000, 0.6092],\n",
       "         [1.0000, 0.6112],\n",
       "         [1.0000, 0.6132],\n",
       "         [1.0000, 0.6152],\n",
       "         [1.0000, 0.6172],\n",
       "         [1.0000, 0.6192],\n",
       "         [1.0000, 0.6212],\n",
       "         [1.0000, 0.6232],\n",
       "         [1.0000, 0.6253],\n",
       "         [1.0000, 0.6273],\n",
       "         [1.0000, 0.6293],\n",
       "         [1.0000, 0.6313],\n",
       "         [1.0000, 0.6333],\n",
       "         [1.0000, 0.6353],\n",
       "         [1.0000, 0.6373],\n",
       "         [1.0000, 0.6393],\n",
       "         [1.0000, 0.6413],\n",
       "         [1.0000, 0.6433],\n",
       "         [1.0000, 0.6453],\n",
       "         [1.0000, 0.6473],\n",
       "         [1.0000, 0.6493],\n",
       "         [1.0000, 0.6513],\n",
       "         [1.0000, 0.6533],\n",
       "         [1.0000, 0.6553],\n",
       "         [1.0000, 0.6573],\n",
       "         [1.0000, 0.6593],\n",
       "         [1.0000, 0.6613],\n",
       "         [1.0000, 0.6633],\n",
       "         [1.0000, 0.6653],\n",
       "         [1.0000, 0.6673],\n",
       "         [1.0000, 0.6693],\n",
       "         [1.0000, 0.6713],\n",
       "         [1.0000, 0.6733],\n",
       "         [1.0000, 0.6754],\n",
       "         [1.0000, 0.6774],\n",
       "         [1.0000, 0.6794],\n",
       "         [1.0000, 0.6814],\n",
       "         [1.0000, 0.6834],\n",
       "         [1.0000, 0.6854],\n",
       "         [1.0000, 0.6874],\n",
       "         [1.0000, 0.6894],\n",
       "         [1.0000, 0.6914],\n",
       "         [1.0000, 0.6934],\n",
       "         [1.0000, 0.6954],\n",
       "         [1.0000, 0.6974],\n",
       "         [1.0000, 0.6994],\n",
       "         [1.0000, 0.7014],\n",
       "         [1.0000, 0.7034],\n",
       "         [1.0000, 0.7054],\n",
       "         [1.0000, 0.7074],\n",
       "         [1.0000, 0.7094],\n",
       "         [1.0000, 0.7114],\n",
       "         [1.0000, 0.7134],\n",
       "         [1.0000, 0.7154],\n",
       "         [1.0000, 0.7174],\n",
       "         [1.0000, 0.7194],\n",
       "         [1.0000, 0.7214],\n",
       "         [1.0000, 0.7234],\n",
       "         [1.0000, 0.7255],\n",
       "         [1.0000, 0.7275],\n",
       "         [1.0000, 0.7295],\n",
       "         [1.0000, 0.7315],\n",
       "         [1.0000, 0.7335],\n",
       "         [1.0000, 0.7355],\n",
       "         [1.0000, 0.7375],\n",
       "         [1.0000, 0.7395],\n",
       "         [1.0000, 0.7415],\n",
       "         [1.0000, 0.7435],\n",
       "         [1.0000, 0.7455],\n",
       "         [1.0000, 0.7475],\n",
       "         [1.0000, 0.7495],\n",
       "         [1.0000, 0.7515],\n",
       "         [1.0000, 0.7535],\n",
       "         [1.0000, 0.7555],\n",
       "         [1.0000, 0.7575],\n",
       "         [1.0000, 0.7595],\n",
       "         [1.0000, 0.7615],\n",
       "         [1.0000, 0.7635],\n",
       "         [1.0000, 0.7655],\n",
       "         [1.0000, 0.7675],\n",
       "         [1.0000, 0.7695],\n",
       "         [1.0000, 0.7715],\n",
       "         [1.0000, 0.7735],\n",
       "         [1.0000, 0.7756],\n",
       "         [1.0000, 0.7776],\n",
       "         [1.0000, 0.7796],\n",
       "         [1.0000, 0.7816],\n",
       "         [1.0000, 0.7836],\n",
       "         [1.0000, 0.7856],\n",
       "         [1.0000, 0.7876],\n",
       "         [1.0000, 0.7896],\n",
       "         [1.0000, 0.7916],\n",
       "         [1.0000, 0.7936],\n",
       "         [1.0000, 0.7956],\n",
       "         [1.0000, 0.7976],\n",
       "         [1.0000, 0.7996],\n",
       "         [1.0000, 0.8016],\n",
       "         [1.0000, 0.8036],\n",
       "         [1.0000, 0.8056],\n",
       "         [1.0000, 0.8076],\n",
       "         [1.0000, 0.8096],\n",
       "         [1.0000, 0.8116],\n",
       "         [1.0000, 0.8136],\n",
       "         [1.0000, 0.8156],\n",
       "         [1.0000, 0.8176],\n",
       "         [1.0000, 0.8196],\n",
       "         [1.0000, 0.8216],\n",
       "         [1.0000, 0.8236],\n",
       "         [1.0000, 0.8257],\n",
       "         [1.0000, 0.8277],\n",
       "         [1.0000, 0.8297],\n",
       "         [1.0000, 0.8317],\n",
       "         [1.0000, 0.8337],\n",
       "         [1.0000, 0.8357],\n",
       "         [1.0000, 0.8377],\n",
       "         [1.0000, 0.8397],\n",
       "         [1.0000, 0.8417],\n",
       "         [1.0000, 0.8437],\n",
       "         [1.0000, 0.8457],\n",
       "         [1.0000, 0.8477],\n",
       "         [1.0000, 0.8497],\n",
       "         [1.0000, 0.8517],\n",
       "         [1.0000, 0.8537],\n",
       "         [1.0000, 0.8557],\n",
       "         [1.0000, 0.8577],\n",
       "         [1.0000, 0.8597],\n",
       "         [1.0000, 0.8617],\n",
       "         [1.0000, 0.8637],\n",
       "         [1.0000, 0.8657],\n",
       "         [1.0000, 0.8677],\n",
       "         [1.0000, 0.8697],\n",
       "         [1.0000, 0.8717],\n",
       "         [1.0000, 0.8737],\n",
       "         [1.0000, 0.8758],\n",
       "         [1.0000, 0.8778],\n",
       "         [1.0000, 0.8798],\n",
       "         [1.0000, 0.8818],\n",
       "         [1.0000, 0.8838],\n",
       "         [1.0000, 0.8858],\n",
       "         [1.0000, 0.8878],\n",
       "         [1.0000, 0.8898],\n",
       "         [1.0000, 0.8918],\n",
       "         [1.0000, 0.8938],\n",
       "         [1.0000, 0.8958],\n",
       "         [1.0000, 0.8978],\n",
       "         [1.0000, 0.8998],\n",
       "         [1.0000, 0.9018],\n",
       "         [1.0000, 0.9038],\n",
       "         [1.0000, 0.9058],\n",
       "         [1.0000, 0.9078],\n",
       "         [1.0000, 0.9098],\n",
       "         [1.0000, 0.9118],\n",
       "         [1.0000, 0.9138],\n",
       "         [1.0000, 0.9158],\n",
       "         [1.0000, 0.9178],\n",
       "         [1.0000, 0.9198],\n",
       "         [1.0000, 0.9218],\n",
       "         [1.0000, 0.9238],\n",
       "         [1.0000, 0.9259],\n",
       "         [1.0000, 0.9279],\n",
       "         [1.0000, 0.9299],\n",
       "         [1.0000, 0.9319],\n",
       "         [1.0000, 0.9339],\n",
       "         [1.0000, 0.9359],\n",
       "         [1.0000, 0.9379],\n",
       "         [1.0000, 0.9399],\n",
       "         [1.0000, 0.9419],\n",
       "         [1.0000, 0.9439],\n",
       "         [1.0000, 0.9459],\n",
       "         [1.0000, 0.9479],\n",
       "         [1.0000, 0.9499],\n",
       "         [1.0000, 0.9519],\n",
       "         [1.0000, 0.9539],\n",
       "         [1.0000, 0.9559],\n",
       "         [1.0000, 0.9579],\n",
       "         [1.0000, 0.9599],\n",
       "         [1.0000, 0.9619],\n",
       "         [1.0000, 0.9639],\n",
       "         [1.0000, 0.9659],\n",
       "         [1.0000, 0.9679],\n",
       "         [1.0000, 0.9699],\n",
       "         [1.0000, 0.9719],\n",
       "         [1.0000, 0.9739],\n",
       "         [1.0000, 0.9760],\n",
       "         [1.0000, 0.9780],\n",
       "         [1.0000, 0.9800],\n",
       "         [1.0000, 0.9820],\n",
       "         [1.0000, 0.9840],\n",
       "         [1.0000, 0.9860],\n",
       "         [1.0000, 0.9880],\n",
       "         [1.0000, 0.9900],\n",
       "         [1.0000, 0.9920],\n",
       "         [1.0000, 0.9940],\n",
       "         [1.0000, 0.9960],\n",
       "         [1.0000, 0.9980],\n",
       "         [1.0000, 1.0000]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.858948Z",
     "start_time": "2021-01-25T05:48:18.850736Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, X, hiddenLayerSizes = [1024], activation=nn.ELU()):\n",
    "        super(MLP,self).__init__()\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.inputSize = X.shape[1:]\n",
    "        self.modules = []\n",
    "        self.modules.append(nn.Linear(np.prod(self.inputSize),hiddenLayerSizes[0]))\n",
    "        self.modules.append(self.activation)\n",
    "        for idx,sz in enumerate(hiddenLayerSizes[:-1]):\n",
    "            self.modules.append(nn.Linear(hiddenLayerSizes[idx],hiddenLayerSizes[idx+1]))\n",
    "            self.modules.append(self.activation)\n",
    "                               \n",
    "        self.modules.append(nn.Linear(hiddenLayerSizes[-1],np.prod(self.inputSize)))\n",
    "        self.layers = nn.Sequential(*self.modules)\n",
    "                                \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.864937Z",
     "start_time": "2021-01-25T05:48:18.860362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (activation): ELU(alpha=1.0)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ELU(alpha=1.0)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(X, hiddenLayerSizes=hiddenLayers,activation=activation)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.871484Z",
     "start_time": "2021-01-25T05:48:18.866318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(X.float())\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.875161Z",
     "start_time": "2021-01-25T05:48:18.872767Z"
    }
   },
   "outputs": [],
   "source": [
    "if len(gpu_ids.split(',')) > 1:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.879345Z",
     "start_time": "2021-01-25T05:48:18.876584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 layers require gradients (unfrozen) out of 6 layers\n",
      "33,088 parameters require gradients (unfrozen) out of 33,088 parameters\n"
     ]
    }
   ],
   "source": [
    "printNumModelParams(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.890383Z",
     "start_time": "2021-01-25T05:48:18.880546Z"
    }
   },
   "outputs": [],
   "source": [
    "del SVD_autoencoder\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.896604Z",
     "start_time": "2021-01-25T05:48:18.892129Z"
    }
   },
   "outputs": [],
   "source": [
    "SVD_autoencoder = SVD_Autoencoder(svd_vecs, latentDim, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:18.914305Z",
     "start_time": "2021-01-25T05:48:18.898889Z"
    }
   },
   "outputs": [],
   "source": [
    "# surrogate class\n",
    "\n",
    "class Surrogate(nn.Module):\n",
    "    \n",
    "    def __init__(self, window,\n",
    "                 z_size, p_size,\n",
    "                LIN, encoder, decoder):\n",
    "        super(Surrogate, self).__init__()\n",
    "        self.window = window\n",
    "        self.z_size = z_size # this does not include the size of p\n",
    "        self.p_size = p_size\n",
    "        self.c_size = z_size + p_size # this does include the size of p\n",
    "        self.LIN = LIN\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def encode(self, U):\n",
    "        \n",
    "        self.shape_of_last_frames_encoded = U.shape\n",
    "        \n",
    "        return self.encoder(U)\n",
    "        \n",
    "    def decode(self, encoding):\n",
    "        \n",
    "        self.shape_of_last_frames_encoded = torch.Size([encoding.size(0), 1, 128, 128])\n",
    "        \n",
    "        return self.decoder(encoding, self.shape_of_last_frames_encoded)\n",
    "        \n",
    "    def predict_next_w_encodings(self, encoding, p_y, window):\n",
    "        '''\n",
    "        use the LIN to predict the next w encodings for each \n",
    "        encoded U in the batch\n",
    "        '''\n",
    "            \n",
    "        predicted_encodings = []\n",
    "            \n",
    "        # given a batch of encodings, advance each encoding window time steps.\n",
    "        # save the result at each time step\n",
    "        for i in range(window):\n",
    "            encoding = self.LIN(encoding) + encoding # use LIN to predict delta in encoding\n",
    "            # this was encoding[:,:,-self.p_size:] in 09_manta..., why the extra dimension?\n",
    "            encoding[:,-self.p_size:] = p_y[:, i]\n",
    "            predicted_encodings.append(encoding)\n",
    "            \n",
    "            \n",
    "        return torch.stack(predicted_encodings)\n",
    "    \n",
    "    def forward(self, U, p_x, p_y, window = None):\n",
    "        \n",
    "        if window == None:\n",
    "            window = self.window\n",
    "        assert p_y.size(1) == window\n",
    "            \n",
    "        #encoding = self.encode(U)\n",
    "        encoding = U\n",
    "        encoding[:,-self.p_size:] = p_x\n",
    "        encoding_w = self.predict_next_w_encodings(encoding, p_y, window)\n",
    "        # want to have this agree with U_y, which is [batch_size, window_size, channels, nx, ny]\n",
    "        # right now, it's [window_size, batch_size, c_size], so transpose dimensions 0 and 1\n",
    "        # print(encoding_w.shape)\n",
    "        U = torch.stack([self.decode(encoding_i) for encoding_i in encoding_w])\n",
    "        \n",
    "        return U.transpose(0,1), encoding_w.transpose(0,1)\n",
    "    \n",
    "    \n",
    "surrogate = Surrogate(w, latentDim - 2, 2, model, SVD_autoencoder.encoder, \n",
    "                      SVD_autoencoder.decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:19.118847Z",
     "start_time": "2021-01-25T05:48:18.916094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 499, 1, 128, 128]), torch.Size([1, 499, 64]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U, encoding_hat = surrogate(X.float(), p_x.float(), p_y.float())\n",
    "U.shape, encoding_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:19.123441Z",
     "start_time": "2021-01-25T05:48:19.120161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(encoding_hat[:,:,-2:].detach().cpu(), p_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:19.131484Z",
     "start_time": "2021-01-25T05:48:19.124476Z"
    }
   },
   "outputs": [],
   "source": [
    "surrogate = Surrogate(w, latentDim - 2, 2, model, SVD_autoencoder.encoder, \n",
    "                      SVD_autoencoder.decoder).to(device)\n",
    "if len(gpu_ids.split(',')) > 1:\n",
    "    surrogate = nn.DataParallel(surrogate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:19.137087Z",
     "start_time": "2021-01-25T05:48:19.132455Z"
    }
   },
   "outputs": [],
   "source": [
    "def L2_relative_loss(pred, target):\n",
    "    return torch.norm(pred - target)/torch.norm(target)\n",
    "\n",
    "\n",
    "def L1_loss(pred, target):\n",
    "    return torch.mean(torch.abs(pred - target))\n",
    "\n",
    "\n",
    "def jacobian_loss(pred, target, device='cpu'):\n",
    "    return L1_loss(jacobian(pred, device), jacobian(target, device))\n",
    "\n",
    "\n",
    "def curl_loss(pred, target, device):\n",
    "    return L1_loss(curl(pred, device), curl(target, device))\n",
    "\n",
    "\n",
    "def MSE(pred,target):\n",
    "    return nn.MSELoss()(pred, target)\n",
    "\n",
    "\n",
    "def p_loss(pred, target):\n",
    "    return L(pred[:, -target.shape[1]:], target)\n",
    "\n",
    "\n",
    "def loss(pred, target, device):\n",
    "        \n",
    "    L = MSE(pred, target)\n",
    "        \n",
    "    return L "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:19.141544Z",
     "start_time": "2021-01-25T05:48:19.138258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 499, 64]), torch.Size([1, 499, 2]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,:,-2:] = p_y\n",
    "y.shape, p_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:19.147002Z",
     "start_time": "2021-01-25T05:48:19.142617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5527e+29, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(encoding_hat, y, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:19.150458Z",
     "start_time": "2021-01-25T05:48:19.148133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndoesn't work with our dataloader\\nif findLRs and (len(gpu_ids.split(','))==1): # doesn't work for multigpu???\\n    opt = create_opt(1e-7,model)\\n    find_lr(model,opt,L,device,trainDataLoader)\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "doesn't work with our dataloader\n",
    "if findLRs and (len(gpu_ids.split(','))==1): # doesn't work for multigpu???\n",
    "    opt = create_opt(1e-7,model)\n",
    "    find_lr(model,opt,L,device,trainDataLoader)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:19.154502Z",
     "start_time": "2021-01-25T05:48:19.151566Z"
    }
   },
   "outputs": [],
   "source": [
    "max_lr = .001\n",
    "opt = torch.optim.Adam(model.parameters(),lr=max_lr,weight_decay=weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt,patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:19.158676Z",
     "start_time": "2021-01-25T05:48:19.155613Z"
    }
   },
   "outputs": [],
   "source": [
    "versionName = versionName + '_lr{}'.format(str(max_lr)) + '_1sim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T19:46:05.158867Z",
     "start_time": "2021-01-25T19:46:05.152549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LIN_SVD_PNNL_MLP_GPUs3_w499_latentDim64_hd128_128_bz1_epochs1000_memory1_WD0_reconLossFalse_lr0.001_1sim'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "versionName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:19.172823Z",
     "start_time": "2021-01-25T05:48:19.165499Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainEpoch(myDataLoader, tensorboard_writer, model, opt, p_loss, loss,\n",
    "               metric, lr_scheduler, tensorboard_rate, device,\n",
    "               tensorboard_recorder_step, total_steps):\n",
    "    running_loss = 0.0\n",
    "    running_rmse = 0.0\n",
    "    total_loss = 0.0\n",
    "    running_ploss = 0.0\n",
    "    for i, sampleBatch in enumerate(myDataLoader, start=1):\n",
    "\n",
    "        # --- Main Training ---\n",
    "        \n",
    "        # gpu\n",
    "        Encoding_x, Encoding_y, p_x, p_y = sampleBatch\n",
    "        Encoding_x = Encoding_x.to(device)\n",
    "        p_x = p_x.to(device)\n",
    "        Encoding_y = Encoding_y.to(device)\n",
    "        p_y = p_y.to(device)\n",
    "            \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        opt.zero_grad()\n",
    "\n",
    "        U_hat, encoding_hat = model(Encoding_x, p_x, p_y)\n",
    "        pl = 0\n",
    "        with torch.no_grad():\n",
    "            Encoding_y[:,:,-2:] = p_y \n",
    "        ll = loss(encoding_hat, Encoding_y, device)\n",
    "        combined_loss = pl + ll\n",
    "        combined_loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        # loss\n",
    "        batch_loss = combined_loss.item()\n",
    "        running_loss += batch_loss\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        batch_ploss = pl\n",
    "        running_ploss += batch_ploss\n",
    "\n",
    "\n",
    "\n",
    "        # record lr change\n",
    "        total_steps += 1\n",
    "        tensorboard_writer.add_scalar(tag=\"LR\", scalar_value=opt.param_groups[0]['lr'], global_step=total_steps)\n",
    "        #lr_scheduler.step()\n",
    "\n",
    "        # tensorboard writes\n",
    "        if (i % tensorboard_rate == 0):\n",
    "            tensorboard_recorder_step += 1\n",
    "            avg_running_loss = running_loss/tensorboard_rate\n",
    "            avg_running_rmse = running_rmse/tensorboard_rate\n",
    "            avg_running_ploss = running_ploss/tensorboard_rate\n",
    "            tensorboard_writer.add_scalar(tag=\"Loss\", scalar_value=avg_running_loss, global_step=tensorboard_recorder_step)\n",
    "            tensorboard_writer.add_scalar(tag=\"p_loss\", scalar_value=avg_running_ploss, global_step=tensorboard_recorder_step)\n",
    "            # reset running_loss for the next set of batches. (tensorboard_rate number of batches)\n",
    "            running_loss = 0.0\n",
    "            running_rmse = 0.0\n",
    "            running_ploss = 0.0\n",
    "            tensorboard_writer.flush()\n",
    "\n",
    "    return total_loss/len(myDataLoader), tensorboard_recorder_step, total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:19.178823Z",
     "start_time": "2021-01-25T05:48:19.173960Z"
    }
   },
   "outputs": [],
   "source": [
    "def validEpoch(myDataLoader, tensorboard_writer, model, p_loss, loss, metric,\n",
    "               device, tensorboard_recorder_step):\n",
    "    running_loss = 0.0\n",
    "    running_rmse = 0.0\n",
    "    for i, sampleBatch in enumerate(myDataLoader, start=1):\n",
    "\n",
    "        # --- Metrics Recording ---\n",
    "\n",
    "        # gpu\n",
    "        Encoding_x, Encoding_y, p_x, p_y = sampleBatch\n",
    "        Encoding_x = Encoding_x.to(device)\n",
    "        p_x = p_x.to(device)\n",
    "        Encoding_y = Encoding_y.to(device)\n",
    "        p_y = p_y.to(device)\n",
    "                \n",
    "        perc = len(Encoding_x)/len(myDataLoader.dataset)\n",
    "\n",
    "        # forward, no gradient calculations\n",
    "        with torch.no_grad():\n",
    "            U_hat, encoding_hat = model(Encoding_x, p_x, p_y)\n",
    "            \n",
    "        Encoding_y[:,:,-2:] = p_y \n",
    "\n",
    "        # loss\n",
    "        combined_loss = loss(encoding_hat, Encoding_y, device)\n",
    "        \n",
    "        running_loss += perc*(combined_loss.item())\n",
    "\n",
    "\n",
    "    avg_running_loss = running_loss\n",
    "    avg_running_rmse = running_rmse\n",
    "    tensorboard_writer.add_scalar(tag=\"Loss\", scalar_value=avg_running_loss, global_step=tensorboard_recorder_step)\n",
    "    tensorboard_writer.flush()\n",
    "    \n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T05:48:21.659632Z",
     "start_time": "2021-01-25T05:48:19.179962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints directory already exists :)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(cps)\n",
    "except:\n",
    "    print(\"checkpoints directory already exists :)\")\n",
    "    \n",
    "# create a summary writer.\n",
    "train_writer = SummaryWriter(os.path.join(tensorboard_direc, versionName,'train'))\n",
    "test_writer = SummaryWriter(os.path.join(tensorboard_direc, versionName,'valid'))\n",
    "tensorboard_recorder_step = 0\n",
    "total_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-25T05:48:10.994Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Started Training ----------\n",
      "--- Epoch 1/1000 ---\n"
     ]
    }
   ],
   "source": [
    "writeMessage('---------- Started Training ----------', versionName)\n",
    "bestLoss = np.infty\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "for epoch in tqdm(range(1, epochs+1)):  # loop over the dataset multiple times\n",
    "\n",
    "    writeMessage(\"--- Epoch {0}/{1} ---\".format(epoch, epochs), versionName)\n",
    "\n",
    "    surrogate.train()\n",
    "    trainLoss, tensorboard_recorder_step, total_steps = trainEpoch(trainDataLoader, \n",
    "                                                                   train_writer, surrogate,\n",
    "                                                                   opt, p_loss, loss,\n",
    "                                                                   rmse, lr_scheduler, \n",
    "                                                                   tensorboard_rate, device,\n",
    "                                                                   tensorboard_recorder_step, total_steps)\n",
    "\n",
    "    writeMessage(\"trainLoss: {:.4e}\".format(trainLoss),versionName)\n",
    "    writeMessage(\"LR: {:.4e}\".format(opt.param_groups[0]['lr']),versionName)\n",
    "#         if trainLoss < bestLoss:\n",
    "#             bestLoss = trainLoss\n",
    "#             writeMessage(\"Better trainLoss: {:.4e}, Saving models...\".format(bestLoss),versionName)\n",
    "#             torch.save(surrogate.state_dict(), os.path.join(cps,versionName))\n",
    "\n",
    "    surrogate.eval()\n",
    "    valLoss = validEpoch(testDataLoader, test_writer, surrogate, p_loss, loss, rmse, device, tensorboard_recorder_step)\n",
    "    writeMessage(\"valLoss: {:.4e}\".format(valLoss),versionName)\n",
    "\n",
    "    # checkpoint progress\n",
    "    if valLoss < bestLoss:\n",
    "        bestLoss = valLoss\n",
    "        writeMessage(\"Better valLoss: {:.4e}, Saving models...\".format(bestLoss),versionName)\n",
    "        torch.save(surrogate.state_dict(), os.path.join(cps,versionName))\n",
    "\n",
    "    lr_scheduler.step(valLoss)\n",
    "\n",
    "    if opt.param_groups[0]['lr'] < 5e-8:\n",
    "        break\n",
    "writeMessage('---------- Finished Training ----------', versionName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T22:28:08.626492Z",
     "start_time": "2021-01-25T22:28:08.588634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see note in Roam, this is labeled reconLossFalse, but we made the video and 08_MLP_surr.pkl file with\n",
    "#reconLossTrue, which didn't actually use reconLoss.\n",
    "surrogate.load_state_dict(torch.load(os.path.join(cps,'LIN_SVD_PNNL_MLP_GPUs3_w499_latentDim64_hd128_128_bz1_epochs1000_memory1_WD0_reconLossFalse_lr0.001_1sim')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T19:55:53.704628Z",
     "start_time": "2021-01-25T19:55:53.410337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cps/LIN_SVD_PNNL_MLP_GPUs0_w10_latentDim1024_hd128_128_bz32_epochs1000_memory1_WD0_lr0.001\r\n",
      "cps/LIN_SVD_PNNL_MLP_GPUs0_w10_latentDim1024_hd128_128_bz32_epochs1000_memory1_WD0_weightedLossTrue_lr0.001\r\n",
      "cps/LIN_SVD_PNNL_MLP_GPUs3_w10_latentDim1024_hd128_128_bz32_epochs1000_memory1_WD0_lr0.001\r\n",
      "cps/LIN_SVD_PNNL_MLP_GPUs3_w10_latentDim1024_hd128_128_bz32_epochs1000_memory1_WD0_weightedLossTrue_lr0.001\r\n",
      "cps/LIN_SVD_PNNL_MLP_GPUs3_w150_latentDim1024_hd128_128_bz32_epochs1000_memory1_WD0_lr0.001\r\n",
      "cps/LIN_SVD_PNNL_MLP_GPUs3_w499_latentDim64_hd128_128_bz1_epochs1000_memory1_WD0_reconLossFalse_lr0.001_1sim\r\n",
      "cps/LIN_SVD_PNNL_MLP_GPUs3_w499_latentDim64_hd128_128_bz1_epochs1000_memory1_WD0_reconLossTrue_lr0.001_1sim\r\n"
     ]
    }
   ],
   "source": [
    "!ls cps/*PNNL_MLP*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T22:28:11.794726Z",
     "start_time": "2021-01-25T22:28:11.787342Z"
    }
   },
   "outputs": [],
   "source": [
    "testDataset_fullSim = LatentVectors(test_data,doPreprocess=True,w=simLen-1,\n",
    "                            simLen=simLen,abs_x_mx=abs_x_mx,memory=memory_length)\n",
    "first_frame_testDataset = torch.utils.data.Subset(testDataset_fullSim, range(0, len(testDataset), simLen))\n",
    "simulation_testDataLoader = DataLoader(dataset=first_frame_testDataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T22:28:12.064118Z",
     "start_time": "2021-01-25T22:28:12.053796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]),\n",
       " torch.Size([1, 499, 64]),\n",
       " torch.Size([1, 2]),\n",
       " torch.Size([1, 499, 2]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y, p_x, p_y = next(iter(simulation_testDataLoader))\n",
    "X.shape,Y.shape, p_x.shape, p_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T22:28:12.280575Z",
     "start_time": "2021-01-25T22:28:12.266303Z"
    }
   },
   "outputs": [],
   "source": [
    "SVD_autoencoder_for_recon_without_physics_vars = SVD_Autoencoder(svd_vecs, latentDim-2, False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T22:28:13.164460Z",
     "start_time": "2021-01-25T22:28:12.605518Z"
    }
   },
   "outputs": [],
   "source": [
    "surrogate.eval()\n",
    "U_hats = []\n",
    "Us = []\n",
    "for i, sampleBatch in enumerate(simulation_testDataLoader, start=1):\n",
    "\n",
    "    # gpu\n",
    "    Encoding_x, Encoding_y, p_x, p_y = sampleBatch\n",
    "    Encoding_x = Encoding_x.to(device)\n",
    "    p_x = p_x.to(device)\n",
    "    Encoding_y = Encoding_y.to(device)\n",
    "    p_y = p_y.to(device)\n",
    "    with torch.no_grad():\n",
    "        Encoding_y = testDataset_fullSim.invPreprocess_x(Encoding_y.clone().cpu()).to(device)\n",
    "        Us.append([SVD_autoencoder_for_recon_without_physics_vars.decoder(e,\n",
    "                       torch.Size((1,1,128,128))).detach().cpu() for e in Encoding_y[:,:,:-2].transpose(0,1)])\n",
    "        \n",
    "        \n",
    "        U_hat, encoding_hat = surrogate(Encoding_x, p_x, p_y, window=simLen-1)\n",
    "        encoding_hat = testDataset_fullSim.invPreprocess_x(encoding_hat.clone().cpu()).to(device)\n",
    "        \n",
    "        U_hat = [SVD_autoencoder_for_recon_without_physics_vars.decoder(e,\n",
    "                    torch.Size((1,1,128,128))).detach().cpu() for e in encoding_hat[:,:,:-2].transpose(0,1)]\n",
    "                    \n",
    "        U_hats.append(U_hat)\n",
    "        \n",
    "        \n",
    "Real_U = torch.stack(*Us).transpose(0,1)\n",
    "#Real_X_img = convertSimToImage(Real_X)\n",
    "\n",
    "Surr_U = torch.stack(*U_hats).transpose(0,1)\n",
    "#Surr_X_img = convertSimToImage(Surr_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T22:28:13.169397Z",
     "start_time": "2021-01-25T22:28:13.166197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 499, 1, 128, 128]), torch.Size([1, 499, 1, 128, 128]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Real_U.shape, Surr_U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T22:28:13.953217Z",
     "start_time": "2021-01-25T22:28:13.468005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative_Error: 4.9489e-01\n",
      "Relative_Error: 1.0032e+00\n",
      "Relative_Error: 1.5342e+00\n",
      "Relative_Error: 2.0919e+00\n",
      "Relative_Error: 2.6747e+00\n",
      "Relative_Error: 3.2826e+00\n",
      "Relative_Error: 3.8922e+00\n",
      "Relative_Error: 4.4489e+00\n",
      "Relative_Error: 4.9310e+00\n",
      "Relative_Error: 5.3430e+00\n",
      "Relative_Error: 5.7022e+00\n",
      "Relative_Error: 6.0399e+00\n",
      "Relative_Error: 6.3829e+00\n",
      "Relative_Error: 6.7598e+00\n",
      "Relative_Error: 7.1896e+00\n",
      "Relative_Error: 7.6804e+00\n",
      "Relative_Error: 8.2370e+00\n",
      "Relative_Error: 8.8879e+00\n",
      "Relative_Error: 9.6477e+00\n",
      "Relative_Error: 1.0514e+01\n",
      "Relative_Error: 1.1483e+01\n",
      "Relative_Error: 1.2571e+01\n",
      "Relative_Error: 1.3815e+01\n",
      "Relative_Error: 1.5234e+01\n",
      "Relative_Error: 1.6783e+01\n",
      "Relative_Error: 1.8536e+01\n",
      "Relative_Error: 2.0476e+01\n",
      "Relative_Error: 2.2609e+01\n",
      "Relative_Error: 2.4922e+01\n",
      "Relative_Error: 2.7441e+01\n",
      "Relative_Error: 3.0172e+01\n",
      "Relative_Error: 3.3145e+01\n",
      "Relative_Error: 3.6383e+01\n",
      "Relative_Error: 3.9870e+01\n",
      "Relative_Error: 4.3655e+01\n",
      "Relative_Error: 4.7784e+01\n",
      "Relative_Error: 5.2299e+01\n",
      "Relative_Error: 5.7219e+01\n",
      "Relative_Error: 6.2597e+01\n",
      "Relative_Error: 6.8536e+01\n",
      "Relative_Error: 7.5059e+01\n",
      "Relative_Error: 8.2190e+01\n",
      "Relative_Error: 8.9979e+01\n",
      "Relative_Error: 9.8427e+01\n",
      "Relative_Error: 1.0768e+02\n",
      "Relative_Error: 1.1753e+02\n",
      "Relative_Error: 1.2816e+02\n",
      "Relative_Error: 1.3951e+02\n",
      "Relative_Error: 1.5169e+02\n",
      "Relative_Error: 1.6474e+02\n",
      "Relative_Error: 1.7873e+02\n",
      "Relative_Error: 1.9379e+02\n",
      "Relative_Error: 2.0966e+02\n",
      "Relative_Error: 2.2618e+02\n",
      "Relative_Error: 2.4342e+02\n",
      "Relative_Error: 2.6193e+02\n",
      "Relative_Error: 2.8129e+02\n",
      "Relative_Error: 3.0207e+02\n",
      "Relative_Error: 3.2349e+02\n",
      "Relative_Error: 3.4576e+02\n",
      "Relative_Error: 3.6926e+02\n",
      "Relative_Error: 3.9423e+02\n",
      "Relative_Error: 4.2113e+02\n",
      "Relative_Error: 4.4947e+02\n",
      "Relative_Error: 4.8015e+02\n",
      "Relative_Error: 5.1278e+02\n",
      "Relative_Error: 5.4776e+02\n",
      "Relative_Error: 5.8497e+02\n",
      "Relative_Error: 6.2404e+02\n",
      "Relative_Error: 6.6573e+02\n",
      "Relative_Error: 7.1254e+02\n",
      "Relative_Error: 7.6357e+02\n",
      "Relative_Error: 8.2086e+02\n",
      "Relative_Error: 8.8387e+02\n",
      "Relative_Error: 9.5350e+02\n",
      "Relative_Error: 1.0316e+03\n",
      "Relative_Error: 1.1179e+03\n",
      "Relative_Error: 1.2079e+03\n",
      "Relative_Error: 1.3054e+03\n",
      "Relative_Error: 1.4117e+03\n",
      "Relative_Error: 1.5290e+03\n",
      "Relative_Error: 1.6549e+03\n",
      "Relative_Error: 1.7901e+03\n",
      "Relative_Error: 1.9341e+03\n",
      "Relative_Error: 2.0861e+03\n",
      "Relative_Error: 2.2607e+03\n",
      "Relative_Error: 2.4669e+03\n",
      "Relative_Error: 2.7015e+03\n",
      "Relative_Error: 2.9644e+03\n",
      "Relative_Error: 3.2995e+03\n",
      "Relative_Error: 3.6638e+03\n",
      "Relative_Error: 4.0749e+03\n",
      "Relative_Error: 4.5092e+03\n",
      "Relative_Error: 5.0178e+03\n",
      "Relative_Error: 5.6095e+03\n",
      "Relative_Error: 6.2074e+03\n",
      "Relative_Error: 6.7568e+03\n",
      "Relative_Error: 7.3261e+03\n",
      "Relative_Error: 7.6215e+03\n",
      "Relative_Error: 7.8558e+03\n",
      "Relative_Error: 8.2647e+03\n",
      "Relative_Error: 8.8125e+03\n",
      "Relative_Error: 9.2216e+03\n",
      "Relative_Error: 9.7704e+03\n",
      "Relative_Error: 1.0458e+04\n",
      "Relative_Error: 1.1107e+04\n",
      "Relative_Error: 1.1812e+04\n",
      "Relative_Error: 1.2455e+04\n",
      "Relative_Error: 1.3221e+04\n",
      "Relative_Error: 1.4087e+04\n",
      "Relative_Error: 1.4990e+04\n",
      "Relative_Error: 1.6040e+04\n",
      "Relative_Error: 1.7150e+04\n",
      "Relative_Error: 1.8364e+04\n",
      "Relative_Error: 1.9713e+04\n",
      "Relative_Error: 2.1188e+04\n",
      "Relative_Error: 2.2826e+04\n",
      "Relative_Error: 2.4593e+04\n",
      "Relative_Error: 2.6502e+04\n",
      "Relative_Error: 2.8557e+04\n",
      "Relative_Error: 3.0756e+04\n",
      "Relative_Error: 3.3180e+04\n",
      "Relative_Error: 3.5804e+04\n",
      "Relative_Error: 3.8663e+04\n",
      "Relative_Error: 4.1721e+04\n",
      "Relative_Error: 4.5025e+04\n",
      "Relative_Error: 4.8552e+04\n",
      "Relative_Error: 5.2376e+04\n",
      "Relative_Error: 5.6537e+04\n",
      "Relative_Error: 6.1031e+04\n",
      "Relative_Error: 6.5840e+04\n",
      "Relative_Error: 7.1050e+04\n",
      "Relative_Error: 7.6735e+04\n",
      "Relative_Error: 8.2866e+04\n",
      "Relative_Error: 8.9367e+04\n",
      "Relative_Error: 9.6207e+04\n",
      "Relative_Error: 1.0398e+05\n",
      "Relative_Error: 1.1227e+05\n",
      "Relative_Error: 1.2139e+05\n",
      "Relative_Error: 1.3120e+05\n",
      "Relative_Error: 1.4147e+05\n",
      "Relative_Error: 1.5271e+05\n",
      "Relative_Error: 1.6494e+05\n",
      "Relative_Error: 1.7843e+05\n",
      "Relative_Error: 1.9319e+05\n",
      "Relative_Error: 2.0919e+05\n",
      "Relative_Error: 2.2631e+05\n",
      "Relative_Error: 2.4541e+05\n",
      "Relative_Error: 2.6488e+05\n",
      "Relative_Error: 2.8596e+05\n",
      "Relative_Error: 3.0812e+05\n",
      "Relative_Error: 3.3217e+05\n",
      "Relative_Error: 3.5795e+05\n",
      "Relative_Error: 3.8677e+05\n",
      "Relative_Error: 4.1684e+05\n",
      "Relative_Error: 4.4995e+05\n",
      "Relative_Error: 4.8505e+05\n",
      "Relative_Error: 5.2463e+05\n",
      "Relative_Error: 5.6880e+05\n",
      "Relative_Error: 6.1900e+05\n",
      "Relative_Error: 6.7152e+05\n",
      "Relative_Error: 7.3436e+05\n",
      "Relative_Error: 7.9665e+05\n",
      "Relative_Error: 8.6694e+05\n",
      "Relative_Error: 9.3630e+05\n",
      "Relative_Error: 9.9942e+05\n",
      "Relative_Error: 1.0746e+06\n",
      "Relative_Error: 1.1393e+06\n",
      "Relative_Error: 1.2116e+06\n",
      "Relative_Error: 1.2883e+06\n",
      "Relative_Error: 1.3785e+06\n",
      "Relative_Error: 1.4598e+06\n",
      "Relative_Error: 1.5434e+06\n",
      "Relative_Error: 1.6456e+06\n",
      "Relative_Error: 1.7397e+06\n",
      "Relative_Error: 1.8427e+06\n",
      "Relative_Error: 1.9604e+06\n",
      "Relative_Error: 2.0839e+06\n",
      "Relative_Error: 2.2297e+06\n",
      "Relative_Error: 2.3678e+06\n",
      "Relative_Error: 2.5108e+06\n",
      "Relative_Error: 2.6858e+06\n",
      "Relative_Error: 2.8571e+06\n",
      "Relative_Error: 3.0451e+06\n",
      "Relative_Error: 3.2402e+06\n",
      "Relative_Error: 3.4223e+06\n",
      "Relative_Error: 3.6579e+06\n",
      "Relative_Error: 3.8864e+06\n",
      "Relative_Error: 4.1345e+06\n",
      "Relative_Error: 4.3909e+06\n",
      "Relative_Error: 4.6787e+06\n",
      "Relative_Error: 5.0053e+06\n",
      "Relative_Error: 5.3744e+06\n",
      "Relative_Error: 5.7559e+06\n",
      "Relative_Error: 6.1648e+06\n",
      "Relative_Error: 6.6015e+06\n",
      "Relative_Error: 7.0553e+06\n",
      "Relative_Error: 7.5432e+06\n",
      "Relative_Error: 8.0610e+06\n",
      "Relative_Error: 8.5913e+06\n",
      "Relative_Error: 9.1940e+06\n",
      "Relative_Error: 9.8229e+06\n",
      "Relative_Error: 1.0509e+07\n",
      "Relative_Error: 1.1230e+07\n",
      "Relative_Error: 1.2011e+07\n",
      "Relative_Error: 1.2858e+07\n",
      "Relative_Error: 1.3770e+07\n",
      "Relative_Error: 1.4729e+07\n",
      "Relative_Error: 1.5729e+07\n",
      "Relative_Error: 1.6755e+07\n",
      "Relative_Error: 1.7900e+07\n",
      "Relative_Error: 1.9168e+07\n",
      "Relative_Error: 2.0526e+07\n",
      "Relative_Error: 2.1992e+07\n",
      "Relative_Error: 2.3500e+07\n",
      "Relative_Error: 2.5145e+07\n",
      "Relative_Error: 2.6942e+07\n",
      "Relative_Error: 2.8866e+07\n",
      "Relative_Error: 3.0911e+07\n",
      "Relative_Error: 3.3142e+07\n",
      "Relative_Error: 3.5544e+07\n",
      "Relative_Error: 3.8101e+07\n",
      "Relative_Error: 4.0957e+07\n",
      "Relative_Error: 4.4036e+07\n",
      "Relative_Error: 4.7403e+07\n",
      "Relative_Error: 5.1142e+07\n",
      "Relative_Error: 5.5180e+07\n",
      "Relative_Error: 5.9700e+07\n",
      "Relative_Error: 6.4472e+07\n",
      "Relative_Error: 7.0110e+07\n",
      "Relative_Error: 7.5706e+07\n",
      "Relative_Error: 8.1314e+07\n",
      "Relative_Error: 8.8123e+07\n",
      "Relative_Error: 9.4185e+07\n",
      "Relative_Error: 1.0195e+08\n",
      "Relative_Error: 1.1022e+08\n",
      "Relative_Error: 1.1791e+08\n",
      "Relative_Error: 1.2466e+08\n",
      "Relative_Error: 1.3352e+08\n",
      "Relative_Error: 1.4275e+08\n",
      "Relative_Error: 1.5324e+08\n",
      "Relative_Error: 1.6735e+08\n",
      "Relative_Error: 1.8033e+08\n",
      "Relative_Error: 1.9453e+08\n",
      "Relative_Error: 2.0648e+08\n",
      "Relative_Error: 2.2069e+08\n",
      "Relative_Error: 2.3563e+08\n",
      "Relative_Error: 2.5265e+08\n",
      "Relative_Error: 2.7069e+08\n",
      "Relative_Error: 2.9000e+08\n",
      "Relative_Error: 3.1014e+08\n",
      "Relative_Error: 3.3276e+08\n",
      "Relative_Error: 3.5733e+08\n",
      "Relative_Error: 3.8385e+08\n",
      "Relative_Error: 4.1374e+08\n",
      "Relative_Error: 4.4457e+08\n",
      "Relative_Error: 4.7664e+08\n",
      "Relative_Error: 5.1143e+08\n",
      "Relative_Error: 5.4951e+08\n",
      "Relative_Error: 5.9181e+08\n",
      "Relative_Error: 6.3466e+08\n",
      "Relative_Error: 6.8274e+08\n",
      "Relative_Error: 7.3234e+08\n",
      "Relative_Error: 7.8543e+08\n",
      "Relative_Error: 8.4375e+08\n",
      "Relative_Error: 9.0799e+08\n",
      "Relative_Error: 9.7619e+08\n",
      "Relative_Error: 1.0473e+09\n",
      "Relative_Error: 1.1201e+09\n",
      "Relative_Error: 1.2010e+09\n",
      "Relative_Error: 1.2869e+09\n",
      "Relative_Error: 1.3791e+09\n",
      "Relative_Error: 1.4770e+09\n",
      "Relative_Error: 1.5810e+09\n",
      "Relative_Error: 1.6962e+09\n",
      "Relative_Error: 1.8229e+09\n",
      "Relative_Error: 1.9538e+09\n",
      "Relative_Error: 2.0942e+09\n",
      "Relative_Error: 2.2444e+09\n",
      "Relative_Error: 2.4077e+09\n",
      "Relative_Error: 2.5809e+09\n",
      "Relative_Error: 2.7647e+09\n",
      "Relative_Error: 2.9597e+09\n",
      "Relative_Error: 3.1702e+09\n",
      "Relative_Error: 3.3939e+09\n",
      "Relative_Error: 3.6384e+09\n",
      "Relative_Error: 3.9005e+09\n",
      "Relative_Error: 4.1649e+09\n",
      "Relative_Error: 4.4587e+09\n",
      "Relative_Error: 4.7834e+09\n",
      "Relative_Error: 5.1253e+09\n",
      "Relative_Error: 5.4964e+09\n",
      "Relative_Error: 5.8838e+09\n",
      "Relative_Error: 6.2906e+09\n",
      "Relative_Error: 6.7472e+09\n",
      "Relative_Error: 7.2273e+09\n",
      "Relative_Error: 7.7358e+09\n",
      "Relative_Error: 8.2932e+09\n",
      "Relative_Error: 8.8785e+09\n",
      "Relative_Error: 9.5389e+09\n",
      "Relative_Error: 1.0219e+10\n",
      "Relative_Error: 1.0950e+10\n",
      "Relative_Error: 1.1864e+10\n",
      "Relative_Error: 1.2722e+10\n",
      "Relative_Error: 1.3517e+10\n",
      "Relative_Error: 1.4394e+10\n",
      "Relative_Error: 1.5203e+10\n",
      "Relative_Error: 1.6342e+10\n",
      "Relative_Error: 1.7515e+10\n",
      "Relative_Error: 1.8759e+10\n",
      "Relative_Error: 1.9992e+10\n",
      "Relative_Error: 2.1252e+10\n",
      "Relative_Error: 2.2469e+10\n",
      "Relative_Error: 2.3866e+10\n",
      "Relative_Error: 2.5330e+10\n",
      "Relative_Error: 2.6971e+10\n",
      "Relative_Error: 2.8518e+10\n",
      "Relative_Error: 3.0223e+10\n",
      "Relative_Error: 3.2104e+10\n",
      "Relative_Error: 3.4159e+10\n",
      "Relative_Error: 3.6238e+10\n",
      "Relative_Error: 3.8484e+10\n",
      "Relative_Error: 4.0863e+10\n",
      "Relative_Error: 4.3497e+10\n",
      "Relative_Error: 4.6439e+10\n",
      "Relative_Error: 4.9513e+10\n",
      "Relative_Error: 5.2743e+10\n",
      "Relative_Error: 5.6247e+10\n",
      "Relative_Error: 6.0135e+10\n",
      "Relative_Error: 6.4201e+10\n",
      "Relative_Error: 6.8489e+10\n",
      "Relative_Error: 7.2941e+10\n",
      "Relative_Error: 7.8498e+10\n",
      "Relative_Error: 8.3827e+10\n",
      "Relative_Error: 8.9557e+10\n",
      "Relative_Error: 9.5753e+10\n",
      "Relative_Error: 1.0246e+11\n",
      "Relative_Error: 1.0964e+11\n",
      "Relative_Error: 1.1746e+11\n",
      "Relative_Error: 1.2601e+11\n",
      "Relative_Error: 1.3517e+11\n",
      "Relative_Error: 1.4495e+11\n",
      "Relative_Error: 1.5553e+11\n",
      "Relative_Error: 1.6682e+11\n",
      "Relative_Error: 1.7896e+11\n",
      "Relative_Error: 1.9259e+11\n",
      "Relative_Error: 2.0663e+11\n",
      "Relative_Error: 2.2207e+11\n",
      "Relative_Error: 2.3887e+11\n",
      "Relative_Error: 2.5648e+11\n",
      "Relative_Error: 2.7584e+11\n",
      "Relative_Error: 2.9684e+11\n",
      "Relative_Error: 3.1936e+11\n",
      "Relative_Error: 3.4326e+11\n",
      "Relative_Error: 3.6930e+11\n",
      "Relative_Error: 3.9783e+11\n",
      "Relative_Error: 4.2841e+11\n",
      "Relative_Error: 4.6177e+11\n",
      "Relative_Error: 4.9680e+11\n",
      "Relative_Error: 5.3495e+11\n",
      "Relative_Error: 5.7620e+11\n",
      "Relative_Error: 6.2100e+11\n",
      "Relative_Error: 6.6790e+11\n",
      "Relative_Error: 7.1681e+11\n",
      "Relative_Error: 7.7153e+11\n",
      "Relative_Error: 8.3208e+11\n",
      "Relative_Error: 8.9955e+11\n",
      "Relative_Error: 9.7389e+11\n",
      "Relative_Error: 1.0530e+12\n",
      "Relative_Error: 1.1354e+12\n",
      "Relative_Error: 1.2239e+12\n",
      "Relative_Error: 1.3202e+12\n",
      "Relative_Error: 1.4067e+12\n",
      "Relative_Error: 1.5142e+12\n",
      "Relative_Error: 1.6249e+12\n",
      "Relative_Error: 1.7414e+12\n",
      "Relative_Error: 1.8728e+12\n",
      "Relative_Error: 2.0023e+12\n",
      "Relative_Error: 2.1435e+12\n",
      "Relative_Error: 2.2945e+12\n",
      "Relative_Error: 2.4747e+12\n",
      "Relative_Error: 2.6709e+12\n",
      "Relative_Error: 2.8531e+12\n",
      "Relative_Error: 3.0578e+12\n",
      "Relative_Error: 3.2821e+12\n",
      "Relative_Error: 3.5042e+12\n",
      "Relative_Error: 3.7359e+12\n",
      "Relative_Error: 3.9554e+12\n",
      "Relative_Error: 4.2050e+12\n",
      "Relative_Error: 4.4899e+12\n",
      "Relative_Error: 4.7590e+12\n",
      "Relative_Error: 5.0911e+12\n",
      "Relative_Error: 5.4250e+12\n",
      "Relative_Error: 5.7926e+12\n",
      "Relative_Error: 6.1830e+12\n",
      "Relative_Error: 6.6029e+12\n",
      "Relative_Error: 7.0556e+12\n",
      "Relative_Error: 7.5393e+12\n",
      "Relative_Error: 8.0552e+12\n",
      "Relative_Error: 8.6132e+12\n",
      "Relative_Error: 9.1993e+12\n",
      "Relative_Error: 9.8145e+12\n",
      "Relative_Error: 1.0463e+13\n",
      "Relative_Error: 1.1179e+13\n",
      "Relative_Error: 1.1902e+13\n",
      "Relative_Error: 1.2661e+13\n",
      "Relative_Error: 1.3489e+13\n",
      "Relative_Error: 1.4397e+13\n",
      "Relative_Error: 1.5366e+13\n",
      "Relative_Error: 1.6395e+13\n",
      "Relative_Error: 1.7504e+13\n",
      "Relative_Error: 1.8684e+13\n",
      "Relative_Error: 1.9952e+13\n",
      "Relative_Error: 2.1288e+13\n",
      "Relative_Error: 2.2670e+13\n",
      "Relative_Error: 2.4168e+13\n",
      "Relative_Error: 2.5792e+13\n",
      "Relative_Error: 2.7476e+13\n",
      "Relative_Error: 2.9302e+13\n",
      "Relative_Error: 3.1229e+13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative_Error: 3.3313e+13\n",
      "Relative_Error: 3.5545e+13\n",
      "Relative_Error: 3.7910e+13\n",
      "Relative_Error: 4.0529e+13\n",
      "Relative_Error: 4.3269e+13\n",
      "Relative_Error: 4.6158e+13\n",
      "Relative_Error: 4.9164e+13\n",
      "Relative_Error: 5.2341e+13\n",
      "Relative_Error: 5.5745e+13\n",
      "Relative_Error: 5.9491e+13\n",
      "Relative_Error: 6.3553e+13\n",
      "Relative_Error: 6.7851e+13\n",
      "Relative_Error: 7.2404e+13\n",
      "Relative_Error: 7.7274e+13\n",
      "Relative_Error: 8.2432e+13\n",
      "Relative_Error: 8.8298e+13\n",
      "Relative_Error: 9.4547e+13\n",
      "Relative_Error: 1.0130e+14\n",
      "Relative_Error: 1.0927e+14\n",
      "Relative_Error: 1.1721e+14\n",
      "Relative_Error: 1.2608e+14\n",
      "Relative_Error: 1.3496e+14\n",
      "Relative_Error: 1.4287e+14\n",
      "Relative_Error: 1.5087e+14\n",
      "Relative_Error: 1.6061e+14\n",
      "Relative_Error: 1.7182e+14\n",
      "Relative_Error: 1.8507e+14\n",
      "Relative_Error: 1.9862e+14\n",
      "Relative_Error: 2.1292e+14\n",
      "Relative_Error: 2.2799e+14\n",
      "Relative_Error: 2.4302e+14\n",
      "Relative_Error: 2.5998e+14\n",
      "Relative_Error: 2.7792e+14\n",
      "Relative_Error: 2.9470e+14\n",
      "Relative_Error: 3.1590e+14\n",
      "Relative_Error: 3.3758e+14\n",
      "Relative_Error: 3.6031e+14\n",
      "Relative_Error: 3.8585e+14\n",
      "Relative_Error: 4.1592e+14\n",
      "Relative_Error: 4.4662e+14\n",
      "Relative_Error: 4.7480e+14\n",
      "Relative_Error: 5.1106e+14\n",
      "Relative_Error: 5.4792e+14\n",
      "Relative_Error: 5.8512e+14\n",
      "Relative_Error: 6.2498e+14\n",
      "Relative_Error: 6.7111e+14\n",
      "Relative_Error: 7.2101e+14\n",
      "Relative_Error: 7.7535e+14\n",
      "Relative_Error: 8.3448e+14\n",
      "Relative_Error: 8.9588e+14\n",
      "Relative_Error: 9.5976e+14\n",
      "Relative_Error: 1.0310e+15\n",
      "Relative_Error: 1.1118e+15\n",
      "Relative_Error: 1.1972e+15\n",
      "Relative_Error: 1.2913e+15\n",
      "Relative_Error: 1.3879e+15\n",
      "Relative_Error: 1.4890e+15\n",
      "Relative_Error: 1.6012e+15\n",
      "Relative_Error: 1.7170e+15\n",
      "Relative_Error: 1.8377e+15\n",
      "Relative_Error: 1.9740e+15\n",
      "Relative_Error: 2.1175e+15\n",
      "Relative_Error: 2.2716e+15\n",
      "Relative_Error: 2.4389e+15\n",
      "Relative_Error: 2.6221e+15\n",
      "Relative_Error: 2.8224e+15\n",
      "Relative_Error: 3.0352e+15\n",
      "Relative_Error: 3.2622e+15\n",
      "Relative_Error: 3.5095e+15\n",
      "Relative_Error: 3.7730e+15\n",
      "Relative_Error: 4.0515e+15\n",
      "Relative_Error: 4.3619e+15\n",
      "Relative_Error: 4.6731e+15\n",
      "Relative_Error: 5.0100e+15\n",
      "Relative_Error: 5.3633e+15\n",
      "Relative_Error: 5.7688e+15\n",
      "Relative_Error: 6.1949e+15\n",
      "Relative_Error: 6.6633e+15\n",
      "Relative_Error: 7.1686e+15\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip(*Us,*U_hats):\n",
    "    rel_error = torch.norm(a - b)/torch.norm(a)\n",
    "    writeMessage(\"Relative_Error: {:.4e}\".format(rel_error),versionName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T22:28:14.193871Z",
     "start_time": "2021-01-25T22:28:14.086886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "sim = -1\n",
    "rel_error_by_sim_and_frame = []\n",
    "for batch_real, batch_surr in zip(Real_U,Surr_U):\n",
    "    sim+=1\n",
    "    rel_error_by_sim_and_frame.append([])\n",
    "    for frame_real, frame_surr in zip(batch_real, batch_surr):\n",
    "        assert frame_real.size()==torch.Size((1,128,128))\n",
    "        rel_error_by_sim_and_frame[sim].append( torch.norm(frame_surr - frame_real)/torch.norm(frame_real))\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-25T22:28:15.290914Z",
     "start_time": "2021-01-25T22:28:14.881294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(np.vstack(rel_error_by_sim_and_frame).T)\n",
    "plt.legend([i for i in range(len(testSimFiles))])\n",
    "plt.show()\n",
    "plt.plot(np.vstack(rel_error_by_sim_and_frame)[:,:50].T)\n",
    "plt.legend([i for i in range(len(testSimFiles))])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-25T05:48:11.015Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Surr_U_img = [torch.rot90(convertSimToImage(s),1,dims=[2,3]) for row in [Surr_U] for s in row]\n",
    "Real_U_img = [torch.rot90(convertSimToImage(s),1,dims=[2,3]) for row in [Real_U] for s in row]\n",
    "triptych = torch.cat([Surr_U_img[0], Real_U_img[sim]], dim=3)\n",
    "triptych=triptych.transpose(1,3)\n",
    "triptych=triptych.transpose(1,2)\n",
    "triptych.shape\n",
    "import imageio\n",
    "#imageio.mimwrite('test.mp4', triptych , fps = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-01-25T05:48:11.017Z"
    }
   },
   "outputs": [],
   "source": [
    "#pkl_save(Surr_U_img, '08_MLP_surr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
