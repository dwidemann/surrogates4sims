{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End to End PNNL Surrogate Model Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important parameters:\n",
    "\n",
    "channel = 1 or 2 # do others later\n",
    "\n",
    "gridsize = 128 or 512 \n",
    "\n",
    "w = 10 # anything from 1 to 499 (simLen) is okay. \n",
    "\n",
    "latentDim = 16 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "# --- Must haves ---\n",
    "import os, sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from surrogates4sims.pnnlDatasets import CCSI_2D\n",
    "\n",
    "from surrogates4sims.utils import create_opt, create_one_cycle, find_lr, printNumModelParams, \\\n",
    "                                    rmse, writeMessage, plotSampleWprediction, plotSampleWpredictionByChannel, \\\n",
    "                                    plotSample, curl, jacobian, stream2uv, create_movie, convertSimToImage, \\\n",
    "                                    pkl_save, pkl_load, create_1_channel_movie\n",
    "\n",
    "from surrogates4sims.models import Generator, Encoder, AE_no_P, AE_xhat_z, AE_xhat_zV2\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pnnl_end2end_plateau_train_GPUs2_channel1_gridsize128_latentDim16'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data \n",
    "eval_only=False\n",
    "DEBUG = False\n",
    "# model name, for tensorboard recording and checkpointing purposes.\n",
    "versionName = \"pnnl_end2end_plateau_train\"\n",
    "\n",
    "# GPU Numbers to use. Comma seprate them for multi-GPUs.\n",
    "gpu_ids = \"2\"\n",
    "versionName = versionName + '_GPUs{}'.format(gpu_ids.replace(',',''))\n",
    "# path to load model weights.\n",
    "pretrained_path = None\n",
    "\n",
    "# rate at which to record metrics. (number of batches to average over when recording metrics, e.g. \"every 5 batches\")\n",
    "tensorboard_rate = 5\n",
    "\n",
    "# number of epochs to train. This is defined here so we can use the OneCycle LR Scheduler.\n",
    "epochs = 1000\n",
    "\n",
    "# Data Directory\n",
    "channel = 1\n",
    "gridsize = 128\n",
    "dataDirec = '/data/ccsi/pnnl_liquid_inlet/channel_{}/gridsize_{}'.format(channel,gridsize)\n",
    "preprocess = False # keep this as false until using the long runtime loader\n",
    "testSplit = .2 # don't change this for now. \n",
    "AE = False\n",
    "numWorkers = 2\n",
    "physicsDim = 2 # inlet velocity and time sample\n",
    "\n",
    "# checkpoint directory\n",
    "cps = 'cps'\n",
    "tensorboard_direc = \"tb\"\n",
    "\n",
    "findLRs = False  \n",
    "\n",
    "# LIN parameters\n",
    "hiddenLayers = [128,128]\n",
    "activation = nn.ELU()\n",
    "\n",
    "# hyper-params\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "bz = 8\n",
    "numSamplesToKeep = np.infty #if not debugging\n",
    "latentDim = 16\n",
    "window_size = 5\n",
    "filters = 128\n",
    "num_conv = 4 # breaks when less than 2\n",
    "simLen = 500\n",
    "stack = True\n",
    "simVizIndex = 0 # sim in the test set to visualize\n",
    "createStreamFcn = False\n",
    "doJacobian = False\n",
    "repeat = 0\n",
    "skip_connection = False\n",
    "patience = 1\n",
    "if DEBUG:\n",
    "    epochs = 10000\n",
    "    numSamplesToKeep = 2 # 1 simulation\n",
    "    \n",
    "versionName = versionName + '_channel{}_gridsize{}_latentDim{}'.format(channel, gridsize, latentDim)\n",
    "versionName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 29 20:03:50 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 23%   20C    P8     9W / 250W |      1MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            On   | 00000000:03:00.0 Off |                  N/A |\n",
      "| 29%   52C    P2   106W / 250W |   3208MiB / 12196MiB |     87%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN Xp            On   | 00000000:81:00.0 Off |                  N/A |\n",
      "| 25%   35C    P8    10W / 250W |  11835MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN Xp            On   | 00000000:82:00.0 Off |                  N/A |\n",
      "| 30%   54C    P2   101W / 250W |   1157MiB / 12196MiB |     87%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    1      5788      C   /home/bartoldson1/anaconda3/bin/python      2697MiB |\n",
      "|    1      6021      C   ...emann1/anaconda3/envs/torch2/bin/python   499MiB |\n",
      "|    2      5320      C   ...emann1/anaconda3/envs/torch2/bin/python 11823MiB |\n",
      "|    3      5788      C   /home/bartoldson1/anaconda3/bin/python      1145MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "if device.type == 'cuda':\n",
    "    print(cuda.is_available())\n",
    "    print(cuda.device_count())\n",
    "    print(cuda.current_device())\n",
    "    print(cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 29 20:03:50 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  TITAN Xp            On   | 00000000:02:00.0 Off |                  N/A |\r\n",
      "| 23%   20C    P8     8W / 250W |      1MiB / 12196MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  TITAN Xp            On   | 00000000:03:00.0 Off |                  N/A |\r\n",
      "| 29%   52C    P2   153W / 250W |   3208MiB / 12196MiB |     85%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  TITAN Xp            On   | 00000000:81:00.0 Off |                  N/A |\r\n",
      "| 25%   35C    P2    60W / 250W |  11835MiB / 12196MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  TITAN Xp            On   | 00000000:82:00.0 Off |                  N/A |\r\n",
      "| 30%   54C    P2   183W / 250W |   1157MiB / 12196MiB |     83%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1      5788      C   /home/bartoldson1/anaconda3/bin/python      2697MiB |\r\n",
      "|    1      6021      C   ...emann1/anaconda3/envs/torch2/bin/python   499MiB |\r\n",
      "|    2      5320      C   ...emann1/anaconda3/envs/torch2/bin/python 11823MiB |\r\n",
      "|    3      5788      C   /home/bartoldson1/anaconda3/bin/python      1145MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(5, device=device.type)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets & Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 40)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = glob(os.path.join(dataDirec,'*.pkl'))\n",
    "numSims = len(sims)\n",
    "idx = int(testSplit*numSims)\n",
    "testInds = np.linspace(1,numSims-2,idx).astype('int')\n",
    "trainInds = list(set(np.arange(0,numSims)).difference(set(testInds)))\n",
    "# perm = np.random.permutation(numSims)\n",
    "# testInds = perm[:idx]\n",
    "# trainInds = perm[idx:]\n",
    "testSimFiles = [sims[idx] for idx in testInds]\n",
    "trainSimFiles = [sims[idx] for idx in trainInds]\n",
    "len(testSimFiles), len(trainSimFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change the CCSI_2D class in 01_pnnl with this one later\n",
    "from torch.utils.data import Dataset\n",
    "class CCSI_2D(Dataset):\n",
    "    def __init__(self, \n",
    "                 dataFiles,\n",
    "                 txtFile = '/data/ccsi/pnnl_liquid_inlet/liquid_inlet_velocity.txt',\n",
    "                 channel=1,\n",
    "                 gridSize=128,\n",
    "                 simLen = 500,\n",
    "                 w = 10, # this is the length of the Y output to predict\n",
    "                 AE = False, # this only return x,x, i.e. no y.\n",
    "                 numToKeep=np.infty,doPreprocess=False): \n",
    "        \n",
    "        self.dataFiles = dataFiles\n",
    "        if numToKeep < len(self.dataFiles):\n",
    "            self.dataFiles = self.dataFiles[:numToKeep]\n",
    "\n",
    "        self.channel = channel\n",
    "        self.gridSize = gridSize\n",
    "        self.numToKeep = numToKeep\n",
    "        self.simLen = 500\n",
    "        self.t = np.linspace(0,1,simLen).astype('float32')\n",
    "        self.w = w\n",
    "        self.AE = AE\n",
    "        self.doPreprocess = doPreprocess\n",
    "        \n",
    "        # Get the inlet velocity\n",
    "        with open(txtFile) as fid:\n",
    "            txt = fid.read().splitlines()\n",
    "        inletVelocity = np.array(list(map(float,txt[1:]))).astype('float32')\n",
    "        self.inletMx = np.max(inletVelocity)\n",
    "        self.inletMn = np.min(inletVelocity)\n",
    "        \n",
    "        data = []\n",
    "        for fn in self.dataFiles:\n",
    "            idx = int(fn.split('/')[-1].replace('.pkl','')) - 1\n",
    "            D = pkl_load(fn)\n",
    "            data.append((D,inletVelocity[idx]))\n",
    "               \n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.simLen*self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if len(self.data) == 1:\n",
    "            q = 0\n",
    "            r_idx = idx\n",
    "        else:\n",
    "            q,r = np.divmod(idx,self.simLen)\n",
    "            r_idx = np.random.randint(0,self.simLen-self.w)\n",
    "            \n",
    "        X,p = self.data[q]\n",
    "        x = X[r_idx:r_idx+1]\n",
    "        #print(x.shape)\n",
    "        y = X[r_idx+1:r_idx+self.w+1]\n",
    "        #print(y.shape)\n",
    "        if self.doPreprocess:\n",
    "            x = self.preprocessFcn(x)\n",
    "            y = self.preprocessFcn(y)\n",
    "        \n",
    "        y = np.expand_dims(y,1)\n",
    "        p_x = np.hstack([p,self.t[r_idx]])\n",
    "        p_y = np.vstack([p*np.ones((self.w,)),self.t[r_idx+1:r_idx+self.w+1]]).T\n",
    "        X = x.astype('float32')\n",
    "        Y = y.astype('float32')\n",
    "        if self.AE:\n",
    "            return X,X # this allows LR_finder to work\n",
    "        else:\n",
    "            return X, Y, p_x, p_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 20000)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDataset = CCSI_2D(testSimFiles,doPreprocess=preprocess,numToKeep=numSamplesToKeep,channel=channel,AE=AE,\n",
    "                      w=window_size)\n",
    "trainDataset = CCSI_2D(trainSimFiles,doPreprocess=preprocess,numToKeep=numSamplesToKeep,channel=channel,AE=AE,\n",
    "                      w=window_size)\n",
    "len(testDataset), len(trainDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 625)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataLoader = DataLoader(dataset=trainDataset, batch_size=bz, shuffle=True, drop_last=True, \n",
    "                             num_workers=numWorkers, pin_memory=True)\n",
    "testDataLoader = DataLoader(dataset=testDataset, batch_size=bz, num_workers=numWorkers, pin_memory=True)\n",
    "len(trainDataLoader), len(testDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 128, 128]) torch.Size([8, 5, 1, 128, 128]) torch.Size([8, 2]) torch.Size([8, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "X,Y,p_x, p_y = next(iter(trainDataLoader))\n",
    "print(X.shape,Y.shape,p_x.shape, p_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 8, 8]\n"
     ]
    }
   ],
   "source": [
    "X = X.to(device)\n",
    "AE_model = AE_xhat_zV2(X, filters, latentDim, num_conv, repeat, \n",
    "                 skip_connection, stack, conv_k=3, last_k=3, \n",
    "                 act=nn.LeakyReLU(), return_z=True, stream=createStreamFcn, device=device)\n",
    "\n",
    "if len(gpu_ids.split(',')) > 1:\n",
    "    AE_model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 layers require gradients (unfrozen) out of 154 layers\n",
      "8,761,361 parameters require gradients (unfrozen) out of 8,761,361 parameters\n"
     ]
    }
   ],
   "source": [
    "printNumModelParams(AE_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 1, 128, 128]), torch.Size([8, 16]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xhat,z = AE_model(X)\n",
    "Xhat.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AE_model.load_state_dict(torch.load(os.path.join('/home/widemann1/surrogates4sims/cps',\n",
    "# 'plateau_train_GPUs2_latentDim16_filters128_bz16_numConv4_streamFalse_jacobianFalse_epochs1000_stackTrue_lr0.0001')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIN Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, X, hiddenLayerSizes = [1024], activation=nn.ELU()):\n",
    "        super(MLP,self).__init__()\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.inputSize = X.shape[1:]\n",
    "        self.modules = []\n",
    "        self.modules.append(nn.Linear(np.prod(self.inputSize),hiddenLayerSizes[0]))\n",
    "        self.modules.append(self.activation)\n",
    "        for idx,sz in enumerate(hiddenLayerSizes[:-1]):\n",
    "            self.modules.append(nn.Linear(hiddenLayerSizes[idx],hiddenLayerSizes[idx+1]))\n",
    "            self.modules.append(self.activation)\n",
    "                               \n",
    "        self.modules.append(nn.Linear(hiddenLayerSizes[-1],np.prod(self.inputSize)))\n",
    "        self.layers = nn.Sequential(*self.modules)\n",
    "                                \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (activation): ELU(alpha=1.0)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=16, out_features=128, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ELU(alpha=1.0)\n",
       "    (4): Linear(in_features=128, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIN_model = MLP(z, hiddenLayerSizes=hiddenLayers, activation=activation)\n",
    "LIN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surrogate class\n",
    "class Surrogate(nn.Module):\n",
    "    \n",
    "    def __init__(self, window,\n",
    "                 z_size, p_size,\n",
    "                LIN, encoder, decoder):\n",
    "        super(Surrogate, self).__init__()\n",
    "        self.window = window\n",
    "        self.z_size = z_size # this does not include the size of p\n",
    "        self.p_size = p_size\n",
    "        self.c_size = z_size + p_size # this does include the size of p\n",
    "        self.LIN = LIN\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def encode(self, U):\n",
    "        \n",
    "        return self.encoder(U)\n",
    "        \n",
    "    def decode(self, encoding):\n",
    "        \n",
    "        return self.decoder(encoding)\n",
    "        \n",
    "    def predict_next_w_encodings(self, encoding, p_y, window):\n",
    "        '''\n",
    "        use the LIN to predict the next w encodings for each \n",
    "        encoded U in the batch\n",
    "        '''\n",
    "            \n",
    "        predicted_encodings = []\n",
    "            \n",
    "        # given a batch of encodings, advance each encoding window time steps.\n",
    "        # save the result at each time step\n",
    "        for i in range(window):\n",
    "            encoding = self.LIN(encoding) + encoding # use LIN to predict delta in encoding\n",
    "            # this was encoding[:,:,-self.p_size:] in 09_manta..., why the extra dimension?\n",
    "            encoding[:,-self.p_size:] = p_y[:, i]\n",
    "            predicted_encodings.append(encoding)\n",
    "            \n",
    "            \n",
    "        return torch.stack(predicted_encodings)\n",
    "    \n",
    "    def forward(self, U, p_x, p_y, window = None):\n",
    "        \n",
    "        if window == None:\n",
    "            window = self.window\n",
    "        assert p_y.size(1) == window\n",
    "            \n",
    "        encoding = self.encode(U)\n",
    "        encoding[:,-self.p_size:] = p_x # added this on 10/27/2020\n",
    "        encoding_w = self.predict_next_w_encodings(encoding, p_y, window)\n",
    "        # want to have this agree with U_y, which is [batch_size, window_size, channels, nx, ny]\n",
    "        # right now, it's [window_size, batch_size, c_size], so transpose dimensions 0 and 1\n",
    "        #print(encoding_w.shape)\n",
    "        U = torch.stack([self.decode(encoding_i) for encoding_i in encoding_w])\n",
    "        return U.transpose(0,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = Surrogate(window_size, latentDim - physicsDim, physicsDim, LIN_model, AE_model.encoder, AE_model.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate = surrogate.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = surrogate.encode(X)\n",
    "encoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 128, 128])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoding = surrogate.decode(encoding)\n",
    "decoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert surrogate.c_size == latentDim\n",
    "assert surrogate.p_size == physicsDim\n",
    "assert encoding.shape[-1] == surrogate.c_size\n",
    "assert decoding.shape == X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5, 1, 128, 128])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xhat = surrogate.forward(X, p_x, p_y)\n",
    "Xhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del surrogate, encoding, decoding, X, Y\n",
    "\n",
    "surrogate = Surrogate(window_size, latentDim - physicsDim, physicsDim, LIN_model, \n",
    "                      AE_model.encoder, AE_model.generator).to(device)\n",
    "\n",
    "if len(gpu_ids.split(',')) > 1:\n",
    "    surrogate = nn.DataParallel(surrogate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = .0001\n",
    "start_lr = 5*max_lr/10\n",
    "#opt = create_opt(max_lr,model)\n",
    "#lr_scheduler = create_one_cycle(opt,max_lr,epochs,trainDataLoader)\n",
    "opt = torch.optim.Adam(surrogate.parameters(),lr=max_lr,betas=(.5,.999))\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt,patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_loss(pred, target):\n",
    "    return torch.mean(torch.abs(pred - target))\n",
    "\n",
    "\n",
    "def jacobian_loss(pred, target, device='cpu'):\n",
    "    return L1_loss(jacobian(pred, device), jacobian(target, device))\n",
    "\n",
    "\n",
    "def curl_loss(pred, target, device):\n",
    "    return L1_loss(curl(pred, device), curl(target, device))\n",
    "\n",
    "\n",
    "L = nn.MSELoss()\n",
    "\n",
    "\n",
    "def p_loss(pred, target):\n",
    "    return L(pred[:, -target.shape[1]:], target)\n",
    "\n",
    "\n",
    "def loss(pred, target, device):\n",
    "    \n",
    "    if createStreamFcn:\n",
    "        pred = stream2uv(pred, device)\n",
    "        \n",
    "    L1 = L1_loss(pred, target)\n",
    "    Lj = 0\n",
    "    if doJacobian:\n",
    "        Lj = jacobian_loss(pred, target, device)\n",
    "        \n",
    "    return L1 + Lj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpoch(myDataLoader, tensorboard_writer, model, opt, p_loss, loss,\n",
    "               metric, lr_scheduler, tensorboard_rate, device,\n",
    "               tensorboard_recorder_step, total_steps):\n",
    "    running_loss = 0.0\n",
    "    running_rmse = 0.0\n",
    "    total_loss = 0.0\n",
    "    running_ploss = 0.0\n",
    "    for i, sampleBatch in enumerate(myDataLoader, start=1):\n",
    "\n",
    "        # --- Main Training ---\n",
    "        \n",
    "        # gpu\n",
    "        U_x, U_y, p_x, p_y = sampleBatch\n",
    "        U_x = U_x.to(device)\n",
    "        p_x = p_x.to(device)\n",
    "        U_y = U_y.to(device)\n",
    "        p_y = p_y.to(device)\n",
    "            \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        opt.zero_grad()\n",
    "\n",
    "        U_hat = model(U_x, p_x, p_y)\n",
    "        pl = 0\n",
    "        ll = loss(U_hat, U_y, device)\n",
    "        combined_loss = pl + ll\n",
    "        combined_loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        # loss\n",
    "        batch_loss = combined_loss.item()\n",
    "        running_loss += batch_loss\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        batch_ploss = pl\n",
    "        running_ploss += batch_ploss\n",
    "\n",
    "        # --- Metrics Recording ---\n",
    "\n",
    "        # metrics\n",
    "        r = metric(U_hat, U_y)\n",
    "        running_rmse += r\n",
    "\n",
    "        # record lr change\n",
    "        total_steps += 1\n",
    "        tensorboard_writer.add_scalar(tag=\"LR\", scalar_value=opt.param_groups[0]['lr'], global_step=total_steps)\n",
    "        #lr_scheduler.step()\n",
    "\n",
    "        # tensorboard writes\n",
    "        if (i % tensorboard_rate == 0):\n",
    "            tensorboard_recorder_step += 1\n",
    "            avg_running_loss = running_loss/tensorboard_rate\n",
    "            avg_running_rmse = running_rmse/tensorboard_rate\n",
    "            avg_running_ploss = running_ploss/tensorboard_rate\n",
    "            tensorboard_writer.add_scalar(tag=\"Loss\", scalar_value=avg_running_loss, global_step=tensorboard_recorder_step)\n",
    "            tensorboard_writer.add_scalar(tag=\"p_loss\", scalar_value=avg_running_ploss, global_step=tensorboard_recorder_step)\n",
    "            tensorboard_writer.add_scalar(tag=metric.__name__, scalar_value=avg_running_rmse, global_step=tensorboard_recorder_step)\n",
    "            # reset running_loss for the next set of batches. (tensorboard_rate number of batches)\n",
    "            running_loss = 0.0\n",
    "            running_rmse = 0.0\n",
    "            running_ploss = 0.0\n",
    "            tensorboard_writer.flush()\n",
    "\n",
    "    return total_loss/len(myDataLoader), tensorboard_recorder_step, total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validEpoch(myDataLoader, tensorboard_writer, model, p_loss, loss, metric,\n",
    "               device, tensorboard_recorder_step):\n",
    "    running_loss = 0.0\n",
    "    running_rmse = 0.0\n",
    "    for i, sampleBatch in enumerate(myDataLoader, start=1):\n",
    "\n",
    "        # --- Metrics Recording ---\n",
    "\n",
    "        # gpu\n",
    "        U_x, U_y, p_x, p_y = sampleBatch\n",
    "        U_x = U_x.to(device) # only squeeze away the window dimension (because batch size = 1)\n",
    "        p_x = p_x.to(device) # only squeeze away the window dimension (because batch size = 1)\n",
    "        U_y = U_y.to(device)\n",
    "        p_y = p_y.to(device)\n",
    "        \n",
    "        perc = len(U_x)/len(myDataLoader.dataset)\n",
    "\n",
    "        # forward, no gradient calculations\n",
    "        with torch.no_grad():\n",
    "            U_hat = model(U_x, p_x, p_y, window = window_size)\n",
    "\n",
    "        # loss\n",
    "        combined_loss = loss(U_hat, U_y, device)\n",
    "        \n",
    "        running_loss += perc*(combined_loss.item())\n",
    "\n",
    "        # metrics\n",
    "        r = metric(U_hat, U_y)\n",
    "        running_rmse += perc*r\n",
    "\n",
    "    avg_running_loss = running_loss\n",
    "    avg_running_rmse = running_rmse\n",
    "    tensorboard_writer.add_scalar(tag=\"Loss\", scalar_value=avg_running_loss, global_step=tensorboard_recorder_step)\n",
    "    tensorboard_writer.add_scalar(tag=metric.__name__, scalar_value=avg_running_rmse, global_step=tensorboard_recorder_step)\n",
    "    tensorboard_writer.flush()\n",
    "    \n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints directory already exists :)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(cps)\n",
    "except:\n",
    "    print(\"checkpoints directory already exists :)\")\n",
    "    \n",
    "# create a summary writer.\n",
    "train_writer = SummaryWriter(os.path.join(tensorboard_direc, versionName,'train'))\n",
    "test_writer = SummaryWriter(os.path.join(tensorboard_direc, versionName,'valid'))\n",
    "tensorboard_recorder_step = 0\n",
    "total_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Started Training ----------\n",
      "--- Epoch 1/1000 ---\n",
      "trainLoss: 6.9081e-02\n",
      "LR: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 1/1000 [15:14<253:52:02, 914.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.2116e-02\n",
      "Better valLoss: 6.2116e-02, Saving models...\n",
      "--- Epoch 2/1000 ---\n",
      "trainLoss: 6.3304e-02\n",
      "LR: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 2/1000 [30:34<254:00:00, 916.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.0629e-02\n",
      "Better valLoss: 6.0629e-02, Saving models...\n",
      "--- Epoch 3/1000 ---\n",
      "trainLoss: 6.1575e-02\n",
      "LR: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 3/1000 [45:53<253:57:58, 917.03s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.0476e-02\n",
      "Better valLoss: 6.0476e-02, Saving models...\n",
      "--- Epoch 4/1000 ---\n",
      "trainLoss: 6.0795e-02\n",
      "LR: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 4/1000 [1:01:12<253:55:43, 917.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1229e-02\n",
      "--- Epoch 5/1000 ---\n",
      "trainLoss: 6.0317e-02\n",
      "LR: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 5/1000 [1:16:31<253:44:13, 918.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.2150e-02\n",
      "--- Epoch 6/1000 ---\n",
      "trainLoss: 6.0427e-02\n",
      "LR: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 6/1000 [1:31:49<253:30:31, 918.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.6611e-02\n",
      "--- Epoch 7/1000 ---\n",
      "trainLoss: 6.1088e-02\n",
      "LR: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 7/1000 [1:47:07<253:14:27, 918.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.3687e-02\n",
      "--- Epoch 8/1000 ---\n",
      "trainLoss: 5.6602e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 8/1000 [2:02:26<253:02:29, 918.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.2280e-02\n",
      "--- Epoch 9/1000 ---\n",
      "trainLoss: 5.5889e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 9/1000 [2:17:43<252:38:38, 917.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1556e-02\n",
      "--- Epoch 10/1000 ---\n",
      "trainLoss: 5.5533e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 10/1000 [2:33:01<252:27:46, 918.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1708e-02\n",
      "--- Epoch 11/1000 ---\n",
      "trainLoss: 5.5134e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 11/1000 [2:48:20<252:16:04, 918.27s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1597e-02\n",
      "--- Epoch 12/1000 ---\n",
      "trainLoss: 5.4646e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 12/1000 [3:03:42<252:19:58, 919.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1685e-02\n",
      "--- Epoch 13/1000 ---\n",
      "trainLoss: 5.4444e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|▏         | 13/1000 [3:19:13<252:58:21, 922.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1534e-02\n",
      "--- Epoch 14/1000 ---\n",
      "trainLoss: 5.4087e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|▏         | 14/1000 [3:34:43<253:22:04, 925.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1365e-02\n",
      "--- Epoch 15/1000 ---\n",
      "trainLoss: 5.3776e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 15/1000 [3:50:13<253:30:45, 926.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1650e-02\n",
      "--- Epoch 16/1000 ---\n",
      "trainLoss: 5.3464e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 16/1000 [4:05:44<253:36:37, 927.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1395e-02\n",
      "--- Epoch 17/1000 ---\n",
      "trainLoss: 5.3136e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 17/1000 [4:21:14<253:29:15, 928.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1444e-02\n",
      "--- Epoch 18/1000 ---\n",
      "trainLoss: 5.2866e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 18/1000 [4:36:42<253:16:32, 928.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1289e-02\n",
      "--- Epoch 19/1000 ---\n",
      "trainLoss: 5.2556e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 19/1000 [4:52:14<253:15:40, 929.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1336e-02\n",
      "--- Epoch 20/1000 ---\n",
      "trainLoss: 5.2254e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 20/1000 [5:07:46<253:12:04, 930.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1342e-02\n",
      "--- Epoch 21/1000 ---\n",
      "trainLoss: 5.2029e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 21/1000 [5:23:13<252:40:34, 929.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1342e-02\n",
      "--- Epoch 22/1000 ---\n",
      "trainLoss: 5.1746e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 22/1000 [5:38:42<252:24:26, 929.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1392e-02\n",
      "--- Epoch 23/1000 ---\n",
      "trainLoss: 5.1505e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 23/1000 [5:54:10<252:06:26, 928.95s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1375e-02\n",
      "--- Epoch 24/1000 ---\n",
      "trainLoss: 5.1168e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 24/1000 [6:09:40<251:54:32, 929.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1312e-02\n",
      "--- Epoch 25/1000 ---\n",
      "trainLoss: 5.1037e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▎         | 25/1000 [6:25:08<251:32:53, 928.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1460e-02\n",
      "--- Epoch 26/1000 ---\n",
      "trainLoss: 5.0715e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 26/1000 [6:40:37<251:19:18, 928.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1553e-02\n",
      "--- Epoch 27/1000 ---\n",
      "trainLoss: 5.0507e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 27/1000 [6:56:04<250:54:29, 928.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1449e-02\n",
      "--- Epoch 28/1000 ---\n",
      "trainLoss: 5.0234e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 28/1000 [7:11:32<250:36:56, 928.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1584e-02\n",
      "--- Epoch 29/1000 ---\n",
      "trainLoss: 5.0147e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 29/1000 [7:27:00<250:23:28, 928.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1377e-02\n",
      "--- Epoch 30/1000 ---\n",
      "trainLoss: 4.9900e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 30/1000 [7:42:31<250:18:12, 928.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1495e-02\n",
      "--- Epoch 31/1000 ---\n",
      "trainLoss: 4.9643e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 31/1000 [7:58:01<250:10:33, 929.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1497e-02\n",
      "--- Epoch 32/1000 ---\n",
      "trainLoss: 4.9430e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 32/1000 [8:13:29<249:43:20, 928.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1541e-02\n",
      "--- Epoch 33/1000 ---\n",
      "trainLoss: 4.9107e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 33/1000 [8:28:54<249:14:07, 927.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1691e-02\n",
      "--- Epoch 34/1000 ---\n",
      "trainLoss: 4.9089e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 34/1000 [8:44:22<248:57:35, 927.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1704e-02\n",
      "--- Epoch 35/1000 ---\n",
      "trainLoss: 4.8869e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▎         | 35/1000 [8:59:52<248:52:13, 928.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1683e-02\n",
      "--- Epoch 36/1000 ---\n",
      "trainLoss: 4.8714e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▎         | 36/1000 [9:15:17<248:22:16, 927.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1638e-02\n",
      "--- Epoch 37/1000 ---\n",
      "trainLoss: 4.8488e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▎         | 37/1000 [9:30:47<248:17:05, 928.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1660e-02\n",
      "--- Epoch 38/1000 ---\n",
      "trainLoss: 4.8318e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 38/1000 [9:46:16<248:06:30, 928.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1627e-02\n",
      "--- Epoch 39/1000 ---\n",
      "trainLoss: 4.8187e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 39/1000 [10:01:48<248:04:47, 929.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1790e-02\n",
      "--- Epoch 40/1000 ---\n",
      "trainLoss: 4.7964e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 40/1000 [10:17:17<247:49:26, 929.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1849e-02\n",
      "--- Epoch 41/1000 ---\n",
      "trainLoss: 4.7830e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 41/1000 [10:32:45<247:30:04, 929.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1872e-02\n",
      "--- Epoch 42/1000 ---\n",
      "trainLoss: 4.7658e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 42/1000 [10:48:17<247:24:36, 929.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1798e-02\n",
      "--- Epoch 43/1000 ---\n",
      "trainLoss: 4.7534e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 43/1000 [11:03:43<246:54:42, 928.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1886e-02\n",
      "--- Epoch 44/1000 ---\n",
      "trainLoss: 4.7337e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 44/1000 [11:19:14<246:47:07, 929.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.2006e-02\n",
      "--- Epoch 45/1000 ---\n",
      "trainLoss: 4.7217e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 45/1000 [11:34:44<246:38:06, 929.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1887e-02\n",
      "--- Epoch 46/1000 ---\n",
      "trainLoss: 4.7098e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 46/1000 [11:50:16<246:31:22, 930.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1721e-02\n",
      "--- Epoch 47/1000 ---\n",
      "trainLoss: 4.6961e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 47/1000 [12:05:47<246:20:21, 930.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1832e-02\n",
      "--- Epoch 48/1000 ---\n",
      "trainLoss: 4.6794e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 48/1000 [12:21:14<245:45:55, 929.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.2191e-02\n",
      "--- Epoch 49/1000 ---\n",
      "trainLoss: 4.6612e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 49/1000 [12:36:43<245:30:19, 929.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1939e-02\n",
      "--- Epoch 50/1000 ---\n",
      "trainLoss: 4.6480e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 50/1000 [12:52:09<244:55:58, 928.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.1997e-02\n",
      "--- Epoch 51/1000 ---\n",
      "trainLoss: 4.6350e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 51/1000 [13:07:38<244:45:46, 928.50s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.2077e-02\n",
      "--- Epoch 52/1000 ---\n",
      "trainLoss: 4.6242e-02\n",
      "LR: 1.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 52/1000 [13:23:06<244:29:10, 928.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valLoss: 6.2153e-02\n",
      "--- Epoch 53/1000 ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-b90c80405622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                                        \u001b[0mrmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                                        \u001b[0mtensorboard_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                                                        tensorboard_recorder_step, total_steps)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mwriteMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainLoss: {:.4e}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mversionName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-14493d80322e>\u001b[0m in \u001b[0;36mtrainEpoch\u001b[0;34m(myDataLoader, tensorboard_writer, model, opt, p_loss, loss, metric, lr_scheduler, tensorboard_rate, device, tensorboard_recorder_step, total_steps)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcombined_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mcombined_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch2/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch2/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "writeMessage('---------- Started Training ----------', versionName)\n",
    "bestLoss = np.infty\n",
    "\n",
    "if not eval_only:\n",
    "    for epoch in tqdm(range(1, epochs+1)):  # loop over the dataset multiple times\n",
    "\n",
    "        writeMessage(\"--- Epoch {0}/{1} ---\".format(epoch, epochs), versionName)\n",
    "\n",
    "        surrogate.train()\n",
    "        trainLoss, tensorboard_recorder_step, total_steps = trainEpoch(trainDataLoader, \n",
    "                                                                       train_writer, surrogate,\n",
    "                                                                       opt, p_loss, loss,\n",
    "                                                                       rmse, lr_scheduler, \n",
    "                                                                       tensorboard_rate, device,\n",
    "                                                                       tensorboard_recorder_step, total_steps)\n",
    "\n",
    "        writeMessage(\"trainLoss: {:.4e}\".format(trainLoss),versionName)\n",
    "        writeMessage(\"LR: {:.4e}\".format(opt.param_groups[0]['lr']),versionName)\n",
    "#         if trainLoss < bestLoss:\n",
    "#             bestLoss = trainLoss\n",
    "#             writeMessage(\"Better trainLoss: {:.4e}, Saving models...\".format(bestLoss),versionName)\n",
    "#             torch.save(surrogate.state_dict(), os.path.join(cps,versionName))\n",
    "\n",
    "        surrogate.eval()\n",
    "        valLoss = validEpoch(testDataLoader, test_writer, surrogate, p_loss, loss, rmse, device, tensorboard_recorder_step)\n",
    "        writeMessage(\"valLoss: {:.4e}\".format(valLoss),versionName)\n",
    "\n",
    "        # checkpoint progress\n",
    "        if valLoss < bestLoss:\n",
    "            bestLoss = valLoss\n",
    "            writeMessage(\"Better valLoss: {:.4e}, Saving models...\".format(bestLoss),versionName)\n",
    "            torch.save(surrogate.state_dict(), os.path.join(cps,versionName))\n",
    "\n",
    "        lr_scheduler.step(trainLoss)\n",
    "\n",
    "        if opt.param_groups[0]['lr'] < 5e-8:\n",
    "            break\n",
    "    writeMessage('---------- Finished Training ----------', versionName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.load_state_dict(torch.load(os.path.join(cps,versionName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset_fullSim = CCSI_2D(testSimFiles,doPreprocess=preprocess,numToKeep=numSamplesToKeep,channel=channel,AE=AE,\n",
    "                      w=simLen-1)\n",
    "first_frame_testDataset = torch.utils.data.Subset(testDataset_fullSim, range(0, len(testDataset), simLen))\n",
    "simulation_testDataLoader = DataLoader(dataset=first_frame_testDataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 128, 128]),\n",
       " torch.Size([1, 499, 1, 128, 128]),\n",
       " torch.Size([1, 2]),\n",
       " torch.Size([1, 499, 2]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Y, p_x, p_y = next(iter(simulation_testDataLoader))\n",
    "X.shape,Y.shape, p_x.shape, p_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate.eval()\n",
    "U_hats = []\n",
    "Us = []\n",
    "for i, sampleBatch in enumerate(simulation_testDataLoader, start=1):\n",
    "\n",
    "    # gpu\n",
    "    U_x, U_y, p_x, p_y = sampleBatch\n",
    "    U_x = U_x.to(device)\n",
    "    p_x = p_x.to(device)\n",
    "    U_y = U_y.to(device)\n",
    "    p_y = p_y.to(device)\n",
    "    with torch.no_grad():\n",
    "        Us.append(U_y.detach().cpu())\n",
    "        \n",
    "        U_hat = surrogate(U_x, p_x, p_y, window=simLen-1)\n",
    "                    \n",
    "        U_hats.append(U_hat.detach().cpu())\n",
    "        \n",
    "        \n",
    "Real_U = torch.stack(Us)\n",
    "#Real_X_img = convertSimToImage(Real_X)\n",
    "\n",
    "Surr_U = torch.stack(U_hats)\n",
    "#Surr_X_img = convertSimToImage(Surr_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative_Error: 9.7969e-01\n",
      "Relative_Error: 9.7679e-01\n",
      "Relative_Error: 9.7701e-01\n",
      "Relative_Error: 9.7978e-01\n",
      "Relative_Error: 9.7920e-01\n",
      "Relative_Error: 9.7219e-01\n",
      "Relative_Error: 9.7175e-01\n",
      "Relative_Error: 9.7451e-01\n",
      "Relative_Error: 9.7328e-01\n",
      "Relative_Error: 9.7342e-01\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip(Us,U_hats):\n",
    "    rel_error = torch.norm(a - b)/torch.norm(a)\n",
    "    writeMessage(\"Relative_Error: {:.4e}\".format(rel_error),versionName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_error = torch.norm(Real_U - Surr_U)/torch.norm(Real_U)\n",
    "writeMessage(\"Relative_Error: {:.4e}\".format(rel_error),versionName)\n",
    "test_writer.add_scalar(tag=\"Relative_Error\", scalar_value=rel_error, global_step=tensorboard_recorder_step)\n",
    "test_writer.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
