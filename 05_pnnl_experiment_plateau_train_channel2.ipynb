{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code trains an encoder/decoder for 1 channel of the pnnl datasets.\n",
    "\n",
    "Make sure the channel is set:\n",
    "\n",
    "channel = 1,2 = velocity_y, volume_frac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:08.175588Z",
     "start_time": "2020-11-06T22:09:05.614316Z"
    }
   },
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "# --- Must haves ---\n",
    "import os, sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.cuda as cuda\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from surrogates4sims.pnnlDatasets import CCSI_2D\n",
    "\n",
    "from surrogates4sims.utils import create_opt, create_one_cycle, find_lr, printNumModelParams, \\\n",
    "                                    rmse, writeMessage, plotSampleWprediction, plotSampleWpredictionByChannel, \\\n",
    "                                    plotSample, curl, jacobian, stream2uv, convertSimToImage, pkl_save, pkl_load, \\\n",
    "                                    create_1_channel_movie\n",
    "\n",
    "from surrogates4sims.models import Generator, Encoder, AE_no_P, AE_xhat_z, AE_xhat_zV2\n",
    "\n",
    "from surrogates4sims.train import trainEpoch, validEpoch\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:08.188981Z",
     "start_time": "2020-11-06T22:09:08.177729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pnnl_plateau_train_GPUs23_channel2_gridsize128_latentDim256_filters128_bz32_numConv4_jacobianFalse_norm_layerIdentity_sigmoid_outTrue_epochs1000_stackTrue'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEBUG = False\n",
    "# model name, for tensorboard recording and checkpointing purposes.\n",
    "versionName = \"pnnl_plateau_train\"\n",
    "\n",
    "# GPU Numbers to use. Comma seprate them for multi-GPUs.\n",
    "gpu_ids = \"2,3\"\n",
    "versionName = versionName + '_GPUs{}'.format(gpu_ids.replace(',',''))\n",
    "# path to load model weights.\n",
    "pretrained_path = None\n",
    "\n",
    "# rate at which to record metrics. (number of batches to average over when recording metrics, e.g. \"every 5 batches\")\n",
    "tensorboard_rate = 5\n",
    "\n",
    "# number of epochs to train. This is defined here so we can use the OneCycle LR Scheduler.\n",
    "epochs = 1000\n",
    "\n",
    "# Data Directory\n",
    "channel = 2\n",
    "gridsize = 128\n",
    "dataDirec = '/data/ccsi/pnnl_liquid_inlet/channel_{}/gridsize_{}'.format(channel,gridsize)\n",
    "preprocess = False # keep this as false until using the long runtime loader\n",
    "testSplit = .2\n",
    "AE = False\n",
    "numWorkers = 2\n",
    "\n",
    "# checkpoint directory\n",
    "cps = 'cps'\n",
    "tensorboard_direc = \"tb\"\n",
    "\n",
    "findLRs = True  \n",
    "\n",
    "# hyper-params\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "bz = 32\n",
    "use_sigmoid_output_layer = True\n",
    "window_size = 0 #important to set this to zero to prevent creation of window_size elements of Y for each X\n",
    "numSamplesToKeep = np.infty #if not debugging\n",
    "latentDim = 256\n",
    "filters = 128\n",
    "num_conv = 4 # breaks when less than 2\n",
    "simLen = 500\n",
    "stack = True\n",
    "doJacobian = False\n",
    "createStreamFcn = False\n",
    "repeat = 0\n",
    "skip_connection = False\n",
    "norm_layer = [nn.Identity, nn.BatchNorm2d, 'etc.'][0] # pick a norm layer to use for the autoencoder\n",
    "patience = 2\n",
    "if DEBUG:\n",
    "    epochs = 2\n",
    "    numSamplesToKeep = 2\n",
    "    \n",
    "versionName = versionName + '_channel{}_gridsize{}_latentDim{}_filters{}_bz{}_numConv{}_jacobian{}_norm_layer{}_sigmoid_out{}_epochs{}_stack{}'.format(\n",
    "    channel,gridsize,latentDim,filters,bz,num_conv,doJacobian,\n",
    "    repr(norm_layer).split('.')[-1][:-2],use_sigmoid_output_layer,epochs,stack)\n",
    "versionName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Personal GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:08.391194Z",
     "start_time": "2020-11-06T22:09:08.192163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov  6 14:09:08 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 47%   74C    P2   237W / 250W |   9785MiB / 12196MiB |     98%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            On   | 00000000:03:00.0 Off |                  N/A |\n",
      "| 23%   22C    P8     8W / 250W |    573MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN Xp            On   | 00000000:81:00.0 Off |                  N/A |\n",
      "| 23%   20C    P8     8W / 250W |      1MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN Xp            On   | 00000000:82:00.0 Off |                  N/A |\n",
      "| 23%   20C    P8     9W / 250W |      1MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     21682      C   /home/bartoldson1/anaconda3/bin/python      9773MiB |\n",
      "|    1     15508      C   /home/bartoldson1/anaconda3/bin/python       561MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:08.399443Z",
     "start_time": "2020-11-06T22:09:08.395000Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:08.486999Z",
     "start_time": "2020-11-06T22:09:08.401946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:08.500318Z",
     "start_time": "2020-11-06T22:09:08.489212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "0\n",
      "TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "if device.type == 'cuda':\n",
    "    print(cuda.is_available())\n",
    "    print(cuda.device_count())\n",
    "    print(cuda.current_device())\n",
    "    print(cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:11.249453Z",
     "start_time": "2020-11-06T22:09:08.502208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Nov  6 14:09:11 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 47%   74C    P2   242W / 250W |   9785MiB / 12196MiB |     97%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            On   | 00000000:03:00.0 Off |                  N/A |\n",
      "| 23%   22C    P8     9W / 250W |    573MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN Xp            On   | 00000000:81:00.0 Off |                  N/A |\n",
      "| 23%   23C    P2    59W / 250W |    573MiB / 12196MiB |      2%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN Xp            On   | 00000000:82:00.0 Off |                  N/A |\n",
      "| 23%   20C    P8     8W / 250W |     12MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     21682      C   /home/bartoldson1/anaconda3/bin/python      9773MiB |\n",
      "|    1     15508      C   /home/bartoldson1/anaconda3/bin/python       561MiB |\n",
      "|    2     21073      C   /home/bartoldson1/anaconda3/bin/python       561MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(5, device=device.type)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets & Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:11.271313Z",
     "start_time": "2020-11-06T22:09:11.253743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 40)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims = glob(os.path.join(dataDirec,'*.pkl'))\n",
    "numSims = len(sims)\n",
    "idx = int(testSplit*numSims)\n",
    "testInds = np.linspace(1,numSims-2,idx).astype('int')\n",
    "trainInds = list(set(np.arange(0,numSims)).difference(set(testInds)))\n",
    "# perm = np.random.permutation(numSims)\n",
    "# testInds = perm[:idx]\n",
    "# trainInds = perm[idx:]\n",
    "testSimFiles = [sims[idx] for idx in testInds]\n",
    "trainSimFiles = [sims[idx] for idx in trainInds]\n",
    "len(testSimFiles), len(trainSimFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:12.020051Z",
     "start_time": "2020-11-06T22:09:11.273707Z"
    }
   },
   "outputs": [],
   "source": [
    "testDataset = CCSI_2D(testSimFiles,doPreprocess=preprocess,numToKeep=numSamplesToKeep,channel=channel,AE=AE,\n",
    "                      w=window_size)\n",
    "trainDataset = CCSI_2D(trainSimFiles,doPreprocess=preprocess,numToKeep=numSamplesToKeep,channel=channel,AE=AE,\n",
    "                      w=window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:12.026256Z",
     "start_time": "2020-11-06T22:09:12.021811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(625, 157)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDataLoader = DataLoader(dataset=trainDataset, batch_size=bz, shuffle=True, drop_last=True, num_workers=numWorkers)\n",
    "testDataLoader = DataLoader(dataset=testDataset, batch_size=bz, num_workers=numWorkers)\n",
    "len(trainDataLoader), len(testDataLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the models need to take data to be built. It's kinda weird. I may look into fix this later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:12.154783Z",
     "start_time": "2020-11-06T22:09:12.027699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 128, 128]),\n",
       " torch.Size([32, 0, 1, 128, 128]),\n",
       " torch.Size([32, 2]),\n",
       " torch.Size([32, 0, 2]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y, p_x, p_y = next(iter(trainDataLoader))\n",
    "X, Y, p_x, p_y = X.to(device), Y.to(device), p_x.to(device), p_y.to(device)\n",
    "X.shape, Y.shape, p_x.shape, p_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:12.694770Z",
     "start_time": "2020-11-06T22:09:12.156304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128, 8, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartoldson1/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    }
   ],
   "source": [
    "model = AE_xhat_zV2(X, filters, latentDim, num_conv, repeat, \n",
    "                 skip_connection, stack, conv_k=3, last_k=3, \n",
    "                 act=nn.LeakyReLU(), return_z=True, stream=createStreamFcn, device=device, norm=norm_layer,\n",
    "                   sigmoid_out=use_sigmoid_output_layer)\n",
    "\n",
    "if len(gpu_ids.split(',')) > 1:\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:12.700996Z",
     "start_time": "2020-11-06T22:09:12.696856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 layers require gradients (unfrozen) out of 90 layers\n",
      "13,668,609 parameters require gradients (unfrozen) out of 13,668,609 parameters\n"
     ]
    }
   ],
   "source": [
    "printNumModelParams(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:15.619479Z",
     "start_time": "2020-11-06T22:09:12.702574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 128, 128]), torch.Size([32, 256]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xhat,z = model(X, p_x)\n",
    "Xhat.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:15.641193Z",
     "start_time": "2020-11-06T22:09:15.623256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(z[:,-2:].detach().cpu(),p_x.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:15.659069Z",
     "start_time": "2020-11-06T22:09:15.644150Z"
    }
   },
   "outputs": [],
   "source": [
    "def L2_relative_loss(pred, target):\n",
    "    return torch.norm(pred - target)/torch.norm(target)\n",
    "\n",
    "\n",
    "def L1_loss(pred, target):\n",
    "    return torch.mean(torch.abs(pred - target))\n",
    "\n",
    "\n",
    "def jacobian_loss(pred, target, device='cpu'):\n",
    "    return L1_loss(jacobian(pred, device), jacobian(target, device))\n",
    "\n",
    "\n",
    "def curl_loss(pred, target, device):\n",
    "    return L1_loss(curl(pred, device), curl(target, device))\n",
    "\n",
    "\n",
    "L = nn.MSELoss()\n",
    "\n",
    "\n",
    "def p_loss(pred, target):\n",
    "    return L(pred[:, -target.shape[1]:], target)\n",
    "\n",
    "\n",
    "def loss(pred, target, device):\n",
    "    \n",
    "    if createStreamFcn:\n",
    "        pred = stream2uv(pred, device)\n",
    "        \n",
    "    L = L2_relative_loss(pred, target)\n",
    "    Lj = 0\n",
    "    if doJacobian:\n",
    "        Lj = jacobian_loss(pred, target, device)\n",
    "        \n",
    "    return L + Lj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:15.676167Z",
     "start_time": "2020-11-06T22:09:15.661506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 128, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = stream2uv(Xhat,device)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:15.688069Z",
     "start_time": "2020-11-06T22:09:15.678775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4142, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(pred,X,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:15.695544Z",
     "start_time": "2020-11-06T22:09:15.690586Z"
    }
   },
   "outputs": [],
   "source": [
    "if findLRs and (len(gpu_ids.split(','))==1): # doesn't work for multigpu???\n",
    "    model.return_z = False\n",
    "    opt = create_opt(1e-7,model)\n",
    "    find_lr(model,opt,L,device,trainDataLoader)\n",
    "    model.return_z = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:15.705129Z",
     "start_time": "2020-11-06T22:09:15.697990Z"
    }
   },
   "outputs": [],
   "source": [
    "max_lr = .0001\n",
    "start_lr = 5*max_lr/10\n",
    "#opt = create_opt(max_lr,model)\n",
    "#lr_scheduler = create_one_cycle(opt,max_lr,epochs,trainDataLoader)\n",
    "opt = torch.optim.Adam(model.parameters(),lr=max_lr,betas=(.5,.999))\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt,patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:15.711098Z",
     "start_time": "2020-11-06T22:09:15.707187Z"
    }
   },
   "outputs": [],
   "source": [
    "versionName = versionName + '_lr{}'.format(str(max_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:15.724986Z",
     "start_time": "2020-11-06T22:09:15.713534Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainEpoch(myDataLoader, tensorboard_writer, model, opt, p_loss, loss,\n",
    "               metric, lr_scheduler, tensorboard_rate, device,\n",
    "               tensorboard_recorder_step, total_steps):\n",
    "    running_loss = 0.0\n",
    "    running_rmse = 0.0\n",
    "    total_loss = 0.0\n",
    "    running_ploss = 0.0\n",
    "    for i, sampleBatch in enumerate(myDataLoader, start=1):\n",
    "\n",
    "        # --- Main Training ---\n",
    "        \n",
    "        # gpu\n",
    "        X, Y, p_x, p_y = sampleBatch\n",
    "        X = X.to(device)\n",
    "        p_x = p_x.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        opt.zero_grad()\n",
    "\n",
    "        X_hat, z = model(X, p_x)\n",
    "        #pl = p_loss(z,p)\n",
    "        ll = loss(X_hat,X,device)\n",
    "        combined_loss = ll #pl + ll\n",
    "        combined_loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        # loss\n",
    "        batch_loss = combined_loss.item()\n",
    "        running_loss += batch_loss\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        #batch_ploss = pl.item()\n",
    "        #running_ploss += batch_ploss\n",
    "\n",
    "        # --- Metrics Recording ---\n",
    "\n",
    "        # metrics\n",
    "        r = metric(X_hat, X)\n",
    "        running_rmse += r\n",
    "\n",
    "        # record lr change\n",
    "        total_steps += 1\n",
    "        tensorboard_writer.add_scalar(tag=\"LR\", scalar_value=opt.param_groups[0]['lr'], global_step=total_steps)\n",
    "        #lr_scheduler.step()\n",
    "\n",
    "        # tensorboard writes\n",
    "        if (i % tensorboard_rate == 0):\n",
    "            tensorboard_recorder_step += 1\n",
    "            avg_running_loss = running_loss/tensorboard_rate\n",
    "            avg_running_rmse = running_rmse/tensorboard_rate\n",
    "            #avg_running_ploss = running_ploss/tensorboard_rate\n",
    "            tensorboard_writer.add_scalar(tag=\"Loss\", scalar_value=avg_running_loss, global_step=tensorboard_recorder_step)\n",
    "            #tensorboard_writer.add_scalar(tag=\"p_loss\", scalar_value=avg_running_ploss, global_step=tensorboard_recorder_step)\n",
    "            tensorboard_writer.add_scalar(tag=metric.__name__, scalar_value=avg_running_rmse, global_step=tensorboard_recorder_step)\n",
    "            # reset running_loss for the next set of batches. (tensorboard_rate number of batches)\n",
    "            running_loss = 0.0\n",
    "            running_rmse = 0.0\n",
    "            #running_ploss = 0.0\n",
    "\n",
    "    return total_loss/len(myDataLoader), tensorboard_recorder_step, total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:15.738748Z",
     "start_time": "2020-11-06T22:09:15.726781Z"
    }
   },
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "def validEpoch(myDataLoader, tensorboard_writer, model, p_loss, loss, metric,\n",
    "               device, tensorboard_recorder_step):\n",
    "    running_loss = 0.0\n",
    "    running_rmse = 0.0\n",
    "    for i, sampleBatch in enumerate(myDataLoader, start=1):\n",
    "\n",
    "        # --- Metrics Recording ---\n",
    "\n",
    "        # gpu\n",
    "        X, Y, p_x, p_y = sampleBatch\n",
    "        X = X.to(device)\n",
    "        p_x = p_x.to(device)\n",
    "        \n",
    "        perc = len(X)/len(myDataLoader.dataset)\n",
    "\n",
    "        # forward, no gradient calculations\n",
    "        with torch.no_grad():\n",
    "            X_hat, z = model(X, p_x)\n",
    "\n",
    "        # loss\n",
    "        #combined_loss = p_loss(z,p) + loss(X_hat,X,device)\n",
    "        combined_loss = loss(X_hat,X,device)\n",
    "        \n",
    "        running_loss += perc*(combined_loss.item())\n",
    "\n",
    "        # metrics\n",
    "        r = metric(X_hat, X)\n",
    "        running_rmse += perc*r\n",
    "\n",
    "    avg_running_loss = running_loss\n",
    "    avg_running_rmse = running_rmse\n",
    "    tensorboard_writer.add_scalar(tag=\"Loss\", scalar_value=avg_running_loss, global_step=tensorboard_recorder_step)\n",
    "    tensorboard_writer.add_scalar(tag=metric.__name__, scalar_value=avg_running_rmse, global_step=tensorboard_recorder_step)\n",
    "\n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:15.749888Z",
     "start_time": "2020-11-06T22:09:15.741300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints directory already exists :)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.mkdir(cps)\n",
    "except:\n",
    "    print(\"checkpoints directory already exists :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T22:09:19.071350Z",
     "start_time": "2020-11-06T22:09:15.752304Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a summary writer.\n",
    "train_writer = SummaryWriter(os.path.join(tensorboard_direc, versionName,'train'))\n",
    "test_writer = SummaryWriter(os.path.join(tensorboard_direc, versionName,'valid'))\n",
    "tensorboard_recorder_step = 0\n",
    "total_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-06T22:09:12.666Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Started Training ----------\n",
      "--- Epoch 1/1000 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bartoldson1/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainLoss: 6.3254e-01\n",
      "LR: 1.0000e-04\n",
      "valLoss: 5.0910e-01\n",
      "Better valLoss: 5.0910e-01, Saving models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/1000 [03:04<51:12:24, 184.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 2/1000 ---\n"
     ]
    }
   ],
   "source": [
    "writeMessage('---------- Started Training ----------', versionName)\n",
    "bestLoss = np.infty\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):  # loop over the dataset multiple times\n",
    "    \n",
    "    writeMessage(\"--- Epoch {0}/{1} ---\".format(epoch, epochs), versionName)\n",
    "    \n",
    "    model.train()\n",
    "    trainLoss, tensorboard_recorder_step, total_steps = trainEpoch(trainDataLoader, \n",
    "                                                                   train_writer, model, opt, p_loss, loss,\n",
    "                                                                   rmse, lr_scheduler, \n",
    "                                                                   tensorboard_rate, device,\n",
    "                                                                   tensorboard_recorder_step, total_steps)\n",
    "    \n",
    "    writeMessage(\"trainLoss: {:.4e}\".format(trainLoss),versionName)\n",
    "    writeMessage(\"LR: {:.4e}\".format(opt.param_groups[0]['lr']),versionName)\n",
    "#     if trainLoss < bestLoss:\n",
    "#         bestLoss = trainLoss\n",
    "#         writeMessage(\"Better trainLoss: {:.4e}, Saving models...\".format(bestLoss),versionName)\n",
    "#         torch.save(model.state_dict(), os.path.join(cps,versionName))\n",
    "        \n",
    "    model.eval()\n",
    "    valLoss = validEpoch(testDataLoader, test_writer, model, p_loss, loss, rmse, device, tensorboard_recorder_step)\n",
    "    writeMessage(\"valLoss: {:.4e}\".format(valLoss),versionName)\n",
    "    \n",
    "    # checkpoint progress\n",
    "    if valLoss < bestLoss:\n",
    "        bestLoss = valLoss\n",
    "        writeMessage(\"Better valLoss: {:.4e}, Saving models...\".format(bestLoss),versionName)\n",
    "        torch.save(model.state_dict(), os.path.join(cps,versionName))\n",
    "\n",
    "    lr_scheduler.step(valLoss)\n",
    "    \n",
    "    if opt.param_groups[0]['lr'] < 5e-8:\n",
    "        break\n",
    "writeMessage('---------- Finished Training ----------', versionName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare: Generated vs. Simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-06T22:09:12.668Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(cps,versionName)))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-06T22:09:12.670Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "X, Y, p_x, p_y = next(iter(testDataLoader))\n",
    "X, Y, p_x, p_y = X.to(device), Y.to(device), p_x.to(device), p_y.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_hat, p = model(X, p_x)\n",
    "\n",
    "if createStreamFcn:\n",
    "    X_hat = stream2uv(X_hat,device)\n",
    "    \n",
    "X.shape, p_x.shape, X_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-06T22:09:12.674Z"
    }
   },
   "outputs": [],
   "source": [
    "RMSE = []\n",
    "relErr = []\n",
    "frameRe = []\n",
    "print('RMSE \\t Rel Err')\n",
    "for idx in range(len(testSimFiles)):\n",
    "    # testDataset = CCSI_2D([testSimFiles[idx]],doPreprocess=preprocess,channel=channel,AE=False)\n",
    "    # simDataLoader = DataLoader(dataset=testDataset, batch_size=1)\n",
    "    # for X,Y in simDataLoader:\n",
    "    #     p = X[1]\n",
    "    #     t = X[2]\n",
    "    #     print(X[0].shape, p, t)\n",
    "\n",
    "    testDataset = CCSI_2D([testSimFiles[idx]],doPreprocess=preprocess,channel=channel,AE=AE,w=0)\n",
    "    simDataLoader = DataLoader(dataset=testDataset, batch_size=1)\n",
    "    XX = []\n",
    "    Real_X = []\n",
    "    model.eval()\n",
    "    for i, sampleBatch in enumerate(simDataLoader,start=1):\n",
    "        with torch.no_grad():\n",
    "            X, Y, p_x, p_y = sampleBatch\n",
    "            X, Y, p_x, p_y = X.to(device), Y.to(device), p_x.to(device), p_y.to(device)\n",
    "            Real_X.append(X)\n",
    "\n",
    "            X_hat,_ = model(X, p_x)\n",
    "\n",
    "            if createStreamFcn:\n",
    "                X_hat = stream2uv(X_hat,device)\n",
    "\n",
    "            XX.append(X_hat)\n",
    "\n",
    "            #X = X.detach().cpu().squeeze()\n",
    "            #X_hat = X_hat.detach().cpu().squeeze()\n",
    "            #plotSampleWprediction(X, X_hat)\n",
    "\n",
    "    Real_X = torch.cat(Real_X,axis=0).to('cpu')\n",
    "    Real_X_img = torch.rot90(convertSimToImage(Real_X),1,dims=[2,3])\n",
    "\n",
    "    Surr_X = torch.cat(XX,axis=0).to('cpu')\n",
    "    Surr_X_img = torch.rot90(convertSimToImage(Surr_X),1,dims=[2,3])\n",
    "    Real_X_img.shape, Surr_X_img.shape\n",
    "    \n",
    "    r = rmse(Real_X,Surr_X)\n",
    "    RMSE.append(r)\n",
    "    \n",
    "    rel_error = torch.norm(Real_X - Surr_X)/torch.norm(Real_X)\n",
    "    print('{}\\t{}'.format(r, rel_error))\n",
    "    relErr.append(rel_error)\n",
    "    \n",
    "    re = []\n",
    "    for x,y in zip(Real_X, Surr_X):\n",
    "        x = x.squeeze()\n",
    "        y = y.squeeze()\n",
    "        e = torch.norm(x - y)/torch.norm(x)\n",
    "        re.append(e)\n",
    "    frameRe.append(re)\n",
    "    #plt.plot(re)\n",
    "    \n",
    "print(np.mean(relErr))\n",
    "frameRe = np.vstack(frameRe)\n",
    "plt.plot(frameRe.T)\n",
    "plt.legend([i for i in range(len(testSimFiles))])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-06T22:09:12.677Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.animation as manimati\n",
    "from matplotlib import animation, rc\n",
    "def create_1_channel_movie(im,outfile='sim.mp4',title='surrogate            simulation'):\n",
    "    ti = 0\n",
    "    u_mx = 255 #np.max(np.abs(Xrgb))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.title(title)\n",
    "    cmap = plt.cm.ocean\n",
    "    img = ax.imshow(im[0].squeeze(), cmap=cmap, vmin=0, vmax=u_mx)\n",
    "    #plt.show()\n",
    "    \n",
    "    # initialization function: plot the background of each frame\n",
    "    def init():\n",
    "        img = ax.imshow(im[0].squeeze(), cmap=cmap, vmin=0, vmax=u_mx)\n",
    "        return (fig,)\n",
    "\n",
    "    # animation function. This is called sequentially\n",
    "    def animate(i):\n",
    "        img = ax.imshow(im[i].squeeze(), cmap=cmap, vmin=0, vmax=u_mx)\n",
    "        return (fig,)\n",
    "\n",
    "\n",
    "    # call the animator. blit=True means only re-draw the parts that have changed.\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                   frames=len(im), interval=20, blit=True)\n",
    "    anim.save(outfile, fps=30, extra_args=['-vcodec', 'libx264'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-06T22:09:12.679Z"
    }
   },
   "outputs": [],
   "source": [
    "Xrgb = torch.cat([Surr_X_img, Real_X_img], dim=3)\n",
    "Xrgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-06T22:09:12.682Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    gif = True\n",
    "    outGif = '{}.gif'.format(versionName)\n",
    "    create_1_channel_movie(Xrgb.detach().numpy(),outfile=outGif)\n",
    "except:\n",
    "    gif = False\n",
    "    outGif = '{}.mp4'.format(versionName)\n",
    "    create_1_channel_movie(Xrgb.detach().numpy(),outfile=outGif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-06T22:09:12.684Z"
    }
   },
   "outputs": [],
   "source": [
    "outGif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-06T22:09:12.688Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, Video\n",
    "if gif:\n",
    "    Image(filename=outGif)\n",
    "else:\n",
    "    Video(outGif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-06T22:09:12.692Z"
    }
   },
   "outputs": [],
   "source": [
    "Video(outGif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-06T22:09:12.695Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.hist(Surr_X.flatten(),bins=100)\n",
    "plt.hist(Real_X.flatten(),bins=100)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
