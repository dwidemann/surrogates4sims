{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util functions for Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_lr_finder import LRFinder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.gridspec as gridspec\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import matplotlib.animation as manimati\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "import pickle\n",
    "\n",
    "def silu(input):\n",
    "    '''\n",
    "    Applies the Sigmoid Linear Unit (SiLU) function element-wise:\n",
    "\n",
    "        SiLU(x) = x * sigmoid(x)\n",
    "    '''\n",
    "    return input * torch.sigmoid(input) # use torch.sigmoid to make sure that we created the most efficient implemetation based on builtin PyTorch functions\n",
    "\n",
    "class SiLU(nn.Module):\n",
    "    '''\n",
    "    Applies the Sigmoid Linear Unit (SiLU) function element-wise:\n",
    "\n",
    "        SiLU(x) = x * sigmoid(x)\n",
    "\n",
    "    Shape:\n",
    "        - Input: (N, *) where * means, any number of additional\n",
    "          dimensions\n",
    "        - Output: (N, *), same shape as the input\n",
    "\n",
    "    References:\n",
    "        -  Related paper:\n",
    "        https://arxiv.org/pdf/1606.08415.pdf\n",
    "\n",
    "    Examples:\n",
    "        >>> m = silu()\n",
    "        >>> input = torch.randn(2)\n",
    "        >>> output = m(input)\n",
    "\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "\n",
    "    def forward(self, x):\n",
    "        return silu(x) \n",
    "\n",
    "def create_opt(lr,model):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    return opt\n",
    "\n",
    "def create_one_cycle(opt,max_lr,epochs,dataLoader):\n",
    "    return torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=opt,\n",
    "        max_lr=max_lr,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=len(dataLoader))\n",
    "\n",
    "def find_lr(model,opt,loss_func,device,dataLoader):\n",
    "    lr_finder = LRFinder(model=model, optimizer=opt, criterion=loss_func, device=device)\n",
    "    lr_finder.range_test(dataLoader, end_lr=100, num_iter=200)\n",
    "    lr_finder.plot()\n",
    "    # reset model & opt to their original weights\n",
    "    lr_finder.reset()\n",
    "    \n",
    "def printNumModelParams(model):\n",
    "    layers_req_grad = 0\n",
    "    tot_layers = 0\n",
    "\n",
    "    params_req_grad = 0\n",
    "    tot_params = 0\n",
    "\n",
    "    for param in model.named_parameters():\n",
    "        #print(param[0])\n",
    "        if (param[1].requires_grad):\n",
    "            layers_req_grad += 1\n",
    "            params_req_grad += param[1].nelement()\n",
    "        tot_layers += 1\n",
    "        tot_params += param[1].nelement()\n",
    "    print(\"{0:,} layers require gradients (unfrozen) out of {1:,} layers\".format(layers_req_grad, tot_layers))\n",
    "    print(\"{0:,} parameters require gradients (unfrozen) out of {1:,} parameters\".format(params_req_grad, tot_params))\n",
    "    \n",
    "def calcAccuracy(preds, labels):\n",
    "    softedPreds = torch.softmax(preds,dim=1)\n",
    "    classPreds = softedPreds.argmax(dim=1)\n",
    "    totCorrect = (classPreds == labels).sum().item()\n",
    "    totNum = labels.nelement()\n",
    "    return totCorrect/totNum\n",
    "\n",
    "def rmse(preds, labels):\n",
    "    d = (preds - labels)**2\n",
    "    d = d.mean()\n",
    "    r = d.sqrt()\n",
    "    return r\n",
    "\n",
    "def writeMessage(msg, versionName):\n",
    "    # Write to file.\n",
    "    print(msg)\n",
    "    myFile = open(versionName+\".txt\", \"a\")\n",
    "    myFile.write(msg)\n",
    "    myFile.write(\"\\n\")\n",
    "    myFile.close()\n",
    "    \n",
    "def plotSample(X):\n",
    "        plt.figure(figsize=(20,20))\n",
    "        \n",
    "        plt.subplot(211)\n",
    "        title = 'Channel 0'\n",
    "        plt.title(title)\n",
    "        plt.imshow(X[0])\n",
    "        plt.colorbar()\n",
    "        \n",
    "        plt.subplot(212)\n",
    "        title = 'Channel 1'\n",
    "        plt.title(title)\n",
    "        plt.imshow(X[1])\n",
    "        plt.colorbar()\n",
    "    \n",
    "def plotSampleWpredictionByChannel(sample, prediction):\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    fig.set_size_inches(20,20, forward=True)\n",
    "\n",
    "    axs[0, 0].imshow(sample[0])\n",
    "    axs[0, 0].set_title('Simulated Channel 0')\n",
    "    axs[0, 1].imshow(prediction[0])\n",
    "    axs[0, 1].set_title('Predicted Channel 0]')\n",
    "    axs[1, 0].imshow(sample[1])\n",
    "    axs[1, 0].set_title('Simulated Channel 1')\n",
    "    axs[1, 1].imshow(prediction[1])\n",
    "    axs[1, 1].set_title('Predicted Channel 1')\n",
    "    #plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    # for ax in axs.flat:\n",
    "    #     ax.set(xlabel='x-label', ylabel='y-label')\n",
    "\n",
    "    # # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    # for ax in axs.flat:\n",
    "    #     ax.label_outer()\n",
    "\n",
    "def plotSampleWprediction(sample,prediction):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    A = np.vstack([sample[0], sample[1]])\n",
    "    B = np.vstack([prediction[0], prediction[1]])\n",
    "    C = np.hstack([A,B])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(C)\n",
    "    plt.colorbar()\n",
    "\n",
    "    \n",
    "def curl(X,device='cpu'):\n",
    "    f1 = X[:,0,:,:]\n",
    "    f2 = X[:,1,:,:]\n",
    "    df1_dy = f1[:,1:,:] - f1[:,:-1,:]\n",
    "    df1_dy = torch.cat([df1_dy,torch.zeros((df1_dy.shape[0],1,f1.shape[2])).to(device)], axis=1) \n",
    "    df2_dx = f2[:,:,1:] - f2[:,:,:-1]\n",
    "    df2_dx = torch.cat([df2_dx,torch.zeros((f2.shape[0],f2.shape[1],1)).to(device)], axis=2)\n",
    "    c = df1_dy - df2_dx\n",
    "    c = c[:,None,:,:]\n",
    "    return c\n",
    "\n",
    "def jacobian(X,device='cpu'):\n",
    "    f1 = X[:,0,:,:]\n",
    "    f2 = X[:,1,:,:]\n",
    "    \n",
    "    df1_dx = f1[:,:,1:] - f1[:,:,:-1]\n",
    "    df1_dx = torch.cat([df1_dx,torch.zeros((f2.shape[0],f2.shape[1],1)).to(device)], axis=2)\n",
    "    \n",
    "    df1_dy = f1[:,1:,:] - f1[:,:-1,:]\n",
    "    df1_dy = torch.cat([df1_dy,torch.zeros((df1_dy.shape[0],1,f1.shape[2])).to(device)], axis=1) \n",
    "    \n",
    "    df2_dx = f2[:,:,1:] - f2[:,:,:-1]\n",
    "    df2_dx = torch.cat([df2_dx,torch.zeros((f2.shape[0],f2.shape[1],1)).to(device)], axis=2)\n",
    "\n",
    "    df2_dy = f2[:,1:,:] - f2[:,:-1,:]\n",
    "    df2_dy = torch.cat([df2_dy,torch.zeros((df1_dy.shape[0],1,f1.shape[2])).to(device)], axis=1) \n",
    "  \n",
    "    return torch.stack([df1_dx, df1_dy, df2_dx, df2_dy], axis=1)\n",
    "\n",
    "# http://farside.ph.utexas.edu/teaching/336L/Fluidhtml/node69.html\n",
    "# When creating the stream function, the second channel of X is not going to be used. \n",
    "# It's there so we don't have to change the AE model code. \n",
    "def stream2uv(X,device='cpu'):\n",
    "    u = X[:,0,1:,:] - X[:,0,:-1,:]\n",
    "    w = torch.unsqueeze(u[:,-1,:],axis=1)\n",
    "    u = torch.cat([u,w],axis=1)\n",
    "    v = X[:,0,:,1:] - X[:,0,:,:-1]\n",
    "    w = torch.unsqueeze(u[:,:,-1],axis=2)\n",
    "    v = torch.cat([v,w],axis=2)\n",
    "    return torch.stack([u,v], axis=1)\n",
    "\n",
    "\n",
    "def show(img,flip=False):\n",
    "    npimg = img.numpy()\n",
    "    if flip:\n",
    "        npimg = np.flip(npimg)\n",
    "    plt.figure(figsize=(40,20))\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    \n",
    "def convertSimToImage(X): \n",
    "    # X = [frames,channels,h,w]\n",
    "    mid = 128\n",
    "    M = 255\n",
    "    mx = X.max()\n",
    "    mn = X.min()\n",
    "    X = (X - mn)/(mx - mn)\n",
    "\n",
    "    #C = np.uint8(M*B)\n",
    "    C = (M*X).type(torch.uint8)\n",
    "\n",
    "    if C.shape[1] == 2:\n",
    "        out_shape = C.shape\n",
    "        Xrgb = torch.zeros((out_shape[0],3,out_shape[2],out_shape[3])).type(torch.uint8)\n",
    "        filler = mid*torch.ones(C.shape[2:]).type(torch.uint8)\n",
    "        filler = filler.unsqueeze(axis=0)\n",
    "        for idx, frame in enumerate(C):\n",
    "            #Xrgb[idx] = torch.cat([frame[0].unsqueeze(axis=0),filler,frame[1].unsqueeze(axis=0)],axis=0)\n",
    "            Xrgb[idx] = torch.cat([frame,filler],axis=0)\n",
    "            #Xrgb[idx] = torch.cat([filler,frame],axis=0)\n",
    "    else:\n",
    "        Xrgb = C\n",
    "    return Xrgb\n",
    "\n",
    "\n",
    "def create_movie(Xrgb,outfile='sim.mp4'):\n",
    "    ti = 0\n",
    "    title = 'sim'\n",
    "    u_mx = 255 #np.max(np.abs(Xrgb))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.title(title)\n",
    "    cmap = plt.cm.ocean\n",
    "    img = ax.imshow(np.transpose(Xrgb[0], (1,2,0)), cmap=cmap, vmin=0, vmax=u_mx)\n",
    "    #plt.show()\n",
    "    \n",
    "    # initialization function: plot the background of each frame\n",
    "    def init():\n",
    "        img = ax.imshow(np.transpose(np.flip(Xrgb[0]), (1,2,0)), cmap=cmap, vmin=0, vmax=u_mx)\n",
    "        return (fig,)\n",
    "\n",
    "    # animation function. This is called sequentially\n",
    "    def animate(i):\n",
    "        img = ax.imshow(np.transpose(np.flip(Xrgb[i]), (1,2,0)), cmap=cmap, vmin=0, vmax=u_mx)\n",
    "        return (fig,)\n",
    "\n",
    "\n",
    "    # call the animator. blit=True means only re-draw the parts that have changed.\n",
    "    anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                                   frames=len(Xrgb), interval=20, blit=True)\n",
    "    anim.save(outfile, fps=30, extra_args=['-vcodec', 'libx264'])\n",
    "    \n",
    "\n",
    "def pkl_save(D,fn):\n",
    "    with open(fn,'wb') as fid:\n",
    "        pickle.dump(D,fid)\n",
    "\n",
    "def pkl_load(fn):\n",
    "    with open(fn,'rb') as fid:\n",
    "        D = pickle.load(fid)\n",
    "        return D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Fluid's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This curl makes no sense to me. I think the derivative should be taken across channels\n",
    "# def curl(x, data_format='NHWC'):\n",
    "#     if data_format == 'NCHW': x = nchw_to_nhwc(x)\n",
    "\n",
    "#     u = x[:,1:,:,0] - x[:,:-1,:,0] # ds/dy\n",
    "#     v = x[:,:,:-1,0] - x[:,:,1:,0] # -ds/dx,\n",
    "#     u = tf.concat([u, tf.expand_dims(u[:,-1,:], axis=1)], axis=1)\n",
    "#     v = tf.concat([v, tf.expand_dims(v[:,:,-1], axis=2)], axis=2)\n",
    "#     c = tf.stack([u,v], axis=-1)\n",
    "\n",
    "#     if data_format == 'NCHW': c = nhwc_to_nchw(c)\n",
    "#     return c\n",
    "\n",
    "# def jacobian(x, data_format='NHCW'):\n",
    "#     if data_format == 'NCHW':\n",
    "#         x = nchw_to_nhwc(x)\n",
    "\n",
    "#     dudx = x[:,:,1:,0] - x[:,:,:-1,0]\n",
    "#     dudy = x[:,1:,:,0] - x[:,:-1,:,0]\n",
    "#     dvdx = x[:,:,1:,1] - x[:,:,:-1,1]\n",
    "#     dvdy = x[:,1:,:,1] - x[:,:-1,:,1]\n",
    "    \n",
    "#     dudx = tf.concat([dudx,tf.expand_dims(dudx[:,:,-1], axis=2)], axis=2)\n",
    "#     dvdx = tf.concat([dvdx,tf.expand_dims(dvdx[:,:,-1], axis=2)], axis=2)\n",
    "#     dudy = tf.concat([dudy,tf.expand_dims(dudy[:,-1,:], axis=1)], axis=1)\n",
    "#     dvdy = tf.concat([dvdy,tf.expand_dims(dvdy[:,-1,:], axis=1)], axis=1)\n",
    "\n",
    "#     j = tf.stack([dudx,dudy,dvdx,dvdy], axis=-1)\n",
    "#     w = tf.expand_dims(dvdx - dudy, axis=-1) # vorticity (for visualization)\n",
    "\n",
    "#     if data_format == 'NCHW':\n",
    "#         j = nhwc_to_nchw(j)\n",
    "#         w = nhwc_to_nchw(w)\n",
    "#     return j, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and How to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=100, n_features=28*28, n_informative=400, n_redundant=2, n_repeated=0, n_classes=2)\n",
    "X = X.astype('float32')\n",
    "X = torch.tensor(X).reshape(100,1,28,28).type(torch.float32)\n",
    "y = torch.tensor(y)\n",
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = torch.LongTensor(targets)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 4.5080e-01,  5.8122e-01, -6.5560e-01, -3.9072e-01,  2.0177e-01,\n",
       "            7.6985e-01,  1.1727e+00,  1.8524e+01,  2.5810e-01, -1.6648e+01,\n",
       "           -1.6201e+01,  1.9995e-01,  2.5225e+01,  1.7693e-01, -8.9749e-01,\n",
       "            4.2682e-01, -1.8444e+00,  2.1024e+00,  3.5770e-01,  2.3846e-01,\n",
       "           -3.0043e+00, -6.1409e-01, -5.6685e+00,  4.5927e+00, -1.3857e+01,\n",
       "            6.3421e+00, -1.7266e+01,  5.3794e+00],\n",
       "          [ 1.1012e+01,  1.2134e+00,  9.6571e-01,  1.4821e+01,  1.2435e+00,\n",
       "            1.0125e-02, -7.6497e-01, -1.6214e+00,  1.2660e+01, -8.7501e+00,\n",
       "            1.8245e+00,  8.6400e+00,  1.0887e+01, -1.6755e+00, -2.7765e-01,\n",
       "           -2.1815e+01, -2.8381e+00,  1.5722e+01,  1.0457e+01,  2.1155e+00,\n",
       "            6.7007e+00,  8.0044e+00, -1.7037e+00, -1.3783e+01,  6.7658e-01,\n",
       "            5.4921e-01, -1.5484e+00, -1.4696e+01],\n",
       "          [-7.7276e+00,  1.0670e+00, -2.6884e+01,  6.9988e-02,  7.3225e-01,\n",
       "           -4.9642e+00, -2.3999e+01,  7.7308e+00,  3.1441e+00, -1.2728e+00,\n",
       "           -9.2016e+00, -1.2493e+00,  4.6402e-01, -5.6779e-01, -1.1805e+01,\n",
       "            5.3883e-01, -3.1971e+00, -8.8581e+00, -1.5369e+00, -5.5633e+00,\n",
       "           -8.3769e+00,  4.8208e+00, -4.0041e-01, -1.0253e+01, -1.4058e+00,\n",
       "            1.0217e+01,  3.5702e+00,  1.8603e+00],\n",
       "          [ 3.1552e-02,  4.0133e+00, -1.9761e+01,  1.2362e+01, -8.5780e-01,\n",
       "            1.7728e+00,  7.0628e+00,  2.3995e-01,  3.8468e+00,  1.7392e+01,\n",
       "           -3.2586e+01, -8.2970e+00,  1.4891e-01,  4.7198e+00,  7.1423e+00,\n",
       "           -2.8215e+00,  1.0766e+00,  1.5504e-01,  1.2312e+00,  1.5705e+01,\n",
       "           -7.1986e-01, -1.9108e+01, -1.1846e+00, -1.5748e-01, -6.0438e-01,\n",
       "           -5.0344e+00, -1.3826e+00,  5.9196e-02],\n",
       "          [ 7.0476e-01, -8.7413e-01, -2.2928e+00,  1.4810e+00,  1.4973e+00,\n",
       "            1.2134e+01, -9.3262e-01,  2.6919e+00,  4.2134e-01,  1.5301e+00,\n",
       "            2.2304e+01,  1.7426e+00, -1.0699e+00,  8.1475e+00,  4.1880e+00,\n",
       "           -1.8417e+00,  1.3212e+01, -3.2883e+00,  3.5813e+00, -1.3227e+00,\n",
       "            7.6347e-01,  1.8936e+00, -3.5443e+00, -8.6462e+00, -7.8563e+00,\n",
       "            5.6676e+00,  1.0803e-02, -3.0670e+00],\n",
       "          [ 1.7543e+01,  4.8622e+00, -9.7474e-01,  6.6033e+00,  3.1206e+00,\n",
       "            3.6523e+00, -1.2538e+00, -1.4629e+00,  2.9870e+01, -1.2249e+01,\n",
       "            7.4358e-01,  1.5129e+01,  4.0260e-02,  5.7039e+00,  4.1702e-01,\n",
       "            3.0316e+00,  6.3205e-01,  1.1278e+01,  4.5690e+00,  5.5890e-01,\n",
       "            1.0973e+00, -2.7574e-01,  4.9904e-01, -2.4941e-01,  1.8400e+01,\n",
       "           -1.1581e+00, -5.1141e-01, -1.9552e+00],\n",
       "          [-3.9017e-01, -1.5525e+01,  7.4491e-01,  7.7034e+00,  8.9587e+00,\n",
       "            6.2443e-01, -2.2830e-01,  4.9368e-02, -1.5465e-01, -1.2295e+00,\n",
       "            8.5926e+00, -3.3808e-01, -4.3123e-01, -7.1405e-01,  3.3123e-01,\n",
       "            3.4312e-01,  1.2540e+01,  1.6288e+01, -8.4111e-01, -2.7141e+00,\n",
       "           -2.3136e-01,  1.5286e+01, -1.2439e+02, -1.2760e+01, -2.4798e+00,\n",
       "           -1.3309e+00, -4.0143e-01, -6.9182e+00],\n",
       "          [ 1.8132e+01, -7.1891e-01,  1.0575e+01, -1.5088e-01, -1.4456e+01,\n",
       "            4.9691e-01, -3.1704e-01, -2.6207e+00,  1.7399e-01, -3.9632e+00,\n",
       "            1.5698e+01,  2.7029e-02,  1.2078e+00, -7.9505e-01, -3.6668e-02,\n",
       "            1.4670e+01,  3.2625e+00,  6.9629e-01, -1.1390e+01, -7.5718e+00,\n",
       "            2.9420e-01, -7.1736e+00,  3.5118e-01,  8.5801e-01, -3.5582e+00,\n",
       "            6.2412e+00,  6.7273e-01,  1.2843e+00],\n",
       "          [ 2.9871e+01,  1.2145e+01,  1.3898e+00,  2.1366e+00, -8.0480e+00,\n",
       "            3.9113e-01, -9.7463e+00,  1.4135e+00,  1.4887e+00, -8.8482e-02,\n",
       "           -2.0839e+01, -4.5249e-01, -1.6029e+01, -1.0823e+00, -1.1274e+01,\n",
       "            5.0680e-01,  8.0896e+00,  1.1514e-01,  6.9756e+00, -9.0358e+00,\n",
       "           -1.3278e-01, -2.1739e+00,  2.7128e+01, -1.5497e+00, -1.7091e+00,\n",
       "           -1.0306e+01, -2.8569e+00, -1.0474e+00],\n",
       "          [-8.0764e-01,  9.2215e-01, -9.1170e+00,  2.6905e+00,  1.4886e+01,\n",
       "            3.2862e+00, -1.1632e+00,  1.1186e+00, -2.9603e+01, -1.8223e+01,\n",
       "           -1.0962e+01,  1.5943e+01, -6.6678e+00,  1.0183e+01,  7.4228e+00,\n",
       "           -2.1471e+00,  5.9776e+00, -6.3827e-01, -1.4399e+01,  1.2024e+00,\n",
       "           -8.5840e+00, -1.3757e-01, -6.4789e-01,  1.3179e+01, -8.2114e+00,\n",
       "            1.4257e+01, -1.0731e+00, -1.8146e+01],\n",
       "          [ 3.2213e-02, -6.9592e+00, -4.0544e+00,  2.8996e-01, -3.7883e+00,\n",
       "           -1.8187e-01, -5.9734e+00,  1.5081e+00, -1.0815e+01,  2.5339e+01,\n",
       "            8.9249e+00,  7.1483e-01, -8.6555e-02,  1.1925e+00, -1.6447e+00,\n",
       "           -5.3819e-01, -1.4110e+00, -4.9377e-01,  1.4879e+00, -4.9254e-01,\n",
       "            4.9807e-01, -6.6476e-01,  1.0862e+01,  2.3442e+01,  6.2575e-01,\n",
       "            3.9182e-01,  9.6451e+00, -9.1786e-01],\n",
       "          [ 1.7024e+00, -1.6119e+01, -3.0596e-01, -7.5925e-01, -3.2033e+00,\n",
       "           -1.9803e-01, -1.6482e+00, -1.0654e+01, -1.3418e-02,  7.9321e-01,\n",
       "           -2.7633e+00, -1.1777e+01, -1.4312e+00,  1.0255e+01, -1.6113e+00,\n",
       "           -1.2592e+01,  1.3339e+00,  1.5115e+00,  1.5735e+01, -9.0228e-01,\n",
       "           -1.2976e+01,  2.9110e-01,  1.2982e+01,  1.0932e+01,  5.2019e-01,\n",
       "           -4.4339e+00, -1.1276e-01,  1.4404e+00],\n",
       "          [-2.7661e-01, -8.9380e+00,  2.2724e+01, -2.3592e-01, -6.0494e-01,\n",
       "            4.1091e+01, -3.1513e+00, -4.4004e+00, -2.7323e-01, -1.4831e+01,\n",
       "           -3.5527e-01,  2.7001e+01,  2.4749e-01, -1.6991e+00, -1.3254e+01,\n",
       "           -9.5538e+00,  2.3409e+00,  4.8892e+00, -9.1626e-02, -5.3661e-01,\n",
       "           -9.5751e-02, -1.7104e+00, -1.9000e+00, -1.2493e+00, -1.4570e+00,\n",
       "           -5.8853e+00,  3.5982e+00, -1.8221e+00],\n",
       "          [-8.2148e+00, -3.6122e+00,  1.1129e+00, -1.8209e-01, -5.5764e-01,\n",
       "            3.3080e+00, -4.7272e-01, -7.5350e-01, -1.3018e+00, -9.9312e+00,\n",
       "           -6.7521e+00,  9.9108e-01, -2.7224e-02,  3.3576e-01,  8.4427e-01,\n",
       "            1.4337e+01, -2.8358e-01,  1.2303e+01, -1.0833e+01, -8.2071e-01,\n",
       "            1.1209e+01,  1.9909e+00, -4.6485e-01, -5.4808e-01, -2.3085e-01,\n",
       "           -8.8032e-01, -9.4994e+00,  7.2477e-01],\n",
       "          [-5.1900e-01, -2.4559e-01, -8.8409e+00,  5.1758e+00, -7.8612e+00,\n",
       "            7.0984e+00,  5.5574e-01, -2.6899e+00,  7.5325e-01, -8.6264e-02,\n",
       "           -1.3472e+01, -1.8993e+00, -1.9036e-01, -1.7890e+01,  1.0849e+00,\n",
       "            3.3985e-01,  1.4421e+00,  1.7869e-01, -1.6578e+01, -7.0324e-01,\n",
       "           -1.8697e+00,  1.1769e+01, -5.8906e+00, -7.5388e-02,  1.0833e+00,\n",
       "            2.0482e+00,  8.7617e+00, -6.8668e-01],\n",
       "          [ 8.7108e+00,  1.5687e+01, -6.8437e+00, -2.3596e+00,  3.8118e+00,\n",
       "            1.6454e+01, -2.5317e+00, -5.3801e+00, -8.4059e-01, -6.5948e-01,\n",
       "            2.8015e-01,  1.8293e+01, -4.3102e-01,  1.8528e+01,  2.2660e+00,\n",
       "           -2.0797e+00,  2.1221e+01, -6.6508e-01,  1.7673e+01, -3.6427e-01,\n",
       "           -8.2518e+00, -4.6830e-01,  6.8835e+00,  6.6558e-01, -1.1812e+01,\n",
       "           -2.3662e-01, -4.5696e+00,  1.4187e+00],\n",
       "          [ 1.0691e+01, -8.8013e-02, -5.1396e-01,  8.3721e-01, -9.9071e+00,\n",
       "           -1.2292e+01, -1.0931e+00, -2.4074e+00,  6.6755e-01, -2.4595e+01,\n",
       "            1.9601e+00,  7.7520e-01, -1.1411e+01, -1.6421e+01, -1.4186e+00,\n",
       "           -1.2388e+01, -1.1552e+01, -1.4379e+01,  1.1558e+01, -7.0134e-02,\n",
       "            1.1839e+01,  6.8792e+00, -4.9383e+00, -4.0129e-01, -2.1077e-01,\n",
       "            8.7796e-01,  5.7042e-01, -8.9490e-03],\n",
       "          [ 6.5792e+00,  9.8188e+00, -1.9082e-01, -1.4482e-02, -1.2422e+01,\n",
       "           -3.0761e-01,  1.3015e+01, -1.2362e-01,  2.4014e+00, -8.2232e+00,\n",
       "           -3.0157e+00,  7.4352e+00,  6.2537e-01, -3.5504e+00, -1.9831e+00,\n",
       "           -7.2017e-01, -3.9755e+00,  2.4038e+00,  3.4391e-01,  9.8101e+00,\n",
       "           -2.8105e-01,  2.5189e+00, -1.9166e-01,  1.5513e+01,  1.4566e+01,\n",
       "           -1.1267e+00, -2.0106e+01, -1.1480e+01],\n",
       "          [-1.2648e+01, -6.5667e+00,  7.7001e-01,  1.6556e+00,  1.8904e+01,\n",
       "           -1.3864e+00,  6.1193e-02, -8.3408e-01,  2.0096e+00,  1.9826e+01,\n",
       "            2.4101e+00, -1.9559e-01,  1.1358e+00, -2.3600e+00,  4.1052e+00,\n",
       "            1.0892e+00, -9.3091e-01,  6.4609e+00,  3.5226e-01, -1.7393e+00,\n",
       "           -5.9740e+00,  5.0513e-01, -3.2739e+00,  4.7544e-01, -3.5804e+00,\n",
       "           -2.0151e+01, -6.0488e-01,  8.9156e-01],\n",
       "          [ 1.5268e-01, -4.0874e-01, -1.4811e-01, -1.6218e+01, -1.4911e+00,\n",
       "           -1.8092e-01,  6.7462e-01,  6.3439e+00,  1.6023e-01, -9.0351e+00,\n",
       "           -9.9777e+00, -2.6236e-01,  1.0401e+01,  2.1613e+00,  6.0016e-02,\n",
       "            4.7158e+00,  1.2214e+00,  1.1473e-01, -2.4081e+01, -9.5894e-01,\n",
       "           -1.1562e+00, -1.3310e+00, -1.0982e+01, -8.3849e-01,  1.1800e+00,\n",
       "            7.4255e+00, -4.3622e-01, -5.6978e-01],\n",
       "          [-1.5785e+01,  1.0525e+00, -7.5371e-01, -2.8695e+00, -8.6630e+00,\n",
       "           -7.9105e+00, -9.4011e-01,  7.8004e+00,  2.1771e-01,  2.0282e+01,\n",
       "           -1.3527e-02,  2.8310e-01, -1.4349e+00, -8.6877e-01, -8.9906e+00,\n",
       "            6.0239e+00,  6.3459e+00,  3.9950e+00, -7.3369e+00, -4.3184e+00,\n",
       "           -4.7634e-01, -1.9783e+00,  1.3130e+01,  8.2071e+00, -1.5135e+00,\n",
       "            1.0136e+01,  1.7858e-01, -2.7547e-01],\n",
       "          [ 7.3635e+00, -3.3903e-01, -1.5809e+01, -1.4599e+01,  2.0276e+01,\n",
       "            1.7213e+00, -8.8267e+00,  6.9207e+00,  4.2958e+00,  1.7307e+01,\n",
       "           -6.6100e-01,  3.7767e+00,  1.9599e-01,  4.9805e-01, -6.2374e+00,\n",
       "           -2.2831e+01,  8.7223e-01,  3.8901e-01, -1.3764e+01,  2.0123e+00,\n",
       "           -2.6352e+01, -9.7879e-03, -1.2518e+01, -1.2102e+00,  4.4807e+00,\n",
       "            1.1870e+00, -7.4181e-01,  6.1817e-01],\n",
       "          [-7.9668e+00, -7.1396e-01, -1.5256e+01,  6.8625e+00, -9.7724e+00,\n",
       "           -3.5642e+00, -1.9365e-02, -1.7068e-02,  8.8906e-01, -6.5165e-01,\n",
       "            1.1888e+01, -5.9445e-01,  9.4430e-02,  9.8535e+00, -2.5656e+00,\n",
       "            6.7060e+00, -1.4136e+01, -4.9709e+00, -2.2753e-02,  1.5133e+00,\n",
       "           -3.5296e-01, -7.1383e-02, -1.3665e+01, -1.4912e+00, -3.4007e-01,\n",
       "           -1.4332e+00, -3.2213e-01,  1.5980e+01],\n",
       "          [-8.2278e-01,  8.0523e-01, -1.6558e+00,  7.8339e+00,  8.2703e-01,\n",
       "            9.8805e-01, -1.0759e-01,  1.8233e+00, -2.3384e+01, -8.4998e+00,\n",
       "           -9.0889e-01,  5.8960e-01, -1.4199e+01,  8.5397e-01, -5.8616e-01,\n",
       "           -2.1297e-01,  2.1588e+01,  7.7815e+00, -3.0983e+01,  5.9626e-01,\n",
       "            2.1708e+01,  4.0493e-01, -8.7939e+00,  2.2308e+01, -7.9558e-01,\n",
       "           -1.8813e+00,  1.6888e+00, -2.9760e+01],\n",
       "          [ 8.8481e-01,  1.7684e+00,  8.7255e-01,  1.1715e+00,  1.0459e+00,\n",
       "            1.1698e+00, -6.4936e+00, -2.1972e-02,  3.4694e-01, -5.3150e+00,\n",
       "            1.4040e+01, -1.5507e+01, -2.9552e-01, -5.3090e+00,  1.3158e+01,\n",
       "            1.3069e+01,  7.1309e-01,  2.3404e+00, -1.8747e+01, -8.1245e-01,\n",
       "           -2.2162e+00, -7.8939e-01,  2.0772e+01,  8.5938e+00,  5.9353e+00,\n",
       "           -1.5873e+00, -4.8828e+00, -2.5116e+00],\n",
       "          [-2.3814e+00, -9.6728e-01, -7.9345e-01,  7.5844e-02,  1.9375e-01,\n",
       "           -4.5425e-01,  8.2472e-01,  2.4018e-02, -1.6708e+01, -1.1059e+00,\n",
       "            6.6349e-03,  1.6756e+00, -4.5204e+00, -5.0269e-01,  2.0550e+01,\n",
       "            9.1963e-01, -7.4271e-02, -3.0939e-01, -3.1538e-04,  7.4910e-01,\n",
       "           -2.0258e+00,  1.9221e+00,  5.1107e-01,  1.6133e-01,  1.0664e+01,\n",
       "           -8.1404e+00, -7.3267e+00,  1.4401e+00],\n",
       "          [-2.1979e+00,  1.5563e+00, -4.4126e-01,  1.3142e+01, -9.2897e+00,\n",
       "           -4.8188e-02,  7.8345e-01, -8.2427e+00, -5.2898e+00, -2.4209e-01,\n",
       "            9.7870e-01, -1.1366e+01,  5.8711e-02, -4.0772e-01, -2.0689e+01,\n",
       "           -2.0402e+01, -1.4156e-01, -4.4054e-01,  1.9195e-02, -4.8959e+00,\n",
       "            1.2378e+01, -1.1698e+01, -9.0518e+00,  1.7382e+00, -1.8923e-01,\n",
       "           -1.3351e+00, -1.6772e+01,  3.5893e+00],\n",
       "          [-1.7965e+00, -8.2728e-01, -2.6687e-01, -1.8738e+00, -4.7060e+00,\n",
       "           -3.7742e-01, -6.0777e-01, -1.2539e-01,  1.1979e+00, -7.6919e+00,\n",
       "            9.1551e+00, -5.6329e-01,  8.5086e-01,  5.8422e-01, -9.6022e+00,\n",
       "            1.3559e+00,  1.3969e+01,  2.0264e-01,  6.4430e-01,  5.5087e-01,\n",
       "           -1.4971e+00,  1.9786e+00, -1.8780e-01, -5.2304e+00,  8.5770e+00,\n",
       "            1.5055e+01, -1.9948e+00, -9.2844e+00]]]), tensor(1))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MyDataset(X,y)\n",
    "dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader = DataLoader(dataset,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 1e-3\n",
    "epochs = 100\n",
    "opt = create_opt(max_lr,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_sched = create_one_cycle(opt,max_lr,epochs,dataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 28, 28])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataLoader))\n",
    "batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(batch[0])\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2888, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(out,batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 layers require gradients (unfrozen) out of 8 layers\n",
      "3,199,106 parameters require gradients (unfrozen) out of 3,199,106 parameters\n"
     ]
    }
   ],
   "source": [
    "printNumModelParams(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 4, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bz = 8\n",
    "h = 4\n",
    "w = 3\n",
    "c = 2\n",
    "x = torch.rand(bz,c,h,w )\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 4, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= curl(x)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "J = jacobian(x)\n",
    "print(J.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 4, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = curl(x,device)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "J = jacobian(x,device)\n",
    "print(J.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2, 28, 28])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream2uv(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2, 28, 28])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream2uv(X,device).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream2uv(X) - stream2uv(X,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
